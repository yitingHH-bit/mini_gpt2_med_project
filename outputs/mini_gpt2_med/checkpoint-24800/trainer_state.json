{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 7.936,
  "eval_steps": 500,
  "global_step": 24800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0064,
      "grad_norm": 4.903834342956543,
      "learning_rate": 0.00029978399999999993,
      "loss": 6.0681,
      "step": 20
    },
    {
      "epoch": 0.0128,
      "grad_norm": 5.0286126136779785,
      "learning_rate": 0.000299544,
      "loss": 5.4816,
      "step": 40
    },
    {
      "epoch": 0.0192,
      "grad_norm": 5.765176296234131,
      "learning_rate": 0.00029930399999999997,
      "loss": 4.8907,
      "step": 60
    },
    {
      "epoch": 0.0256,
      "grad_norm": 4.9913010597229,
      "learning_rate": 0.000299064,
      "loss": 4.3719,
      "step": 80
    },
    {
      "epoch": 0.032,
      "grad_norm": 4.803281784057617,
      "learning_rate": 0.00029882399999999994,
      "loss": 3.8039,
      "step": 100
    },
    {
      "epoch": 0.0384,
      "grad_norm": 4.12471342086792,
      "learning_rate": 0.000298584,
      "loss": 3.3584,
      "step": 120
    },
    {
      "epoch": 0.0448,
      "grad_norm": 3.6765542030334473,
      "learning_rate": 0.000298344,
      "loss": 2.9344,
      "step": 140
    },
    {
      "epoch": 0.0512,
      "grad_norm": 2.544633150100708,
      "learning_rate": 0.000298104,
      "loss": 2.5477,
      "step": 160
    },
    {
      "epoch": 0.0576,
      "grad_norm": 1.5227147340774536,
      "learning_rate": 0.00029786399999999995,
      "loss": 2.1715,
      "step": 180
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.8922984600067139,
      "learning_rate": 0.00029762399999999997,
      "loss": 1.9548,
      "step": 200
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.581048846244812,
      "learning_rate": 0.000297384,
      "loss": 1.8054,
      "step": 220
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.5378469824790955,
      "learning_rate": 0.000297144,
      "loss": 1.671,
      "step": 240
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.49512773752212524,
      "learning_rate": 0.00029690399999999996,
      "loss": 1.5633,
      "step": 260
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.4519866704940796,
      "learning_rate": 0.000296664,
      "loss": 1.456,
      "step": 280
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.3863416910171509,
      "learning_rate": 0.00029642399999999994,
      "loss": 1.4086,
      "step": 300
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.3606245517730713,
      "learning_rate": 0.000296184,
      "loss": 1.3835,
      "step": 320
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.32968011498451233,
      "learning_rate": 0.00029594399999999997,
      "loss": 1.3369,
      "step": 340
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.3287256360054016,
      "learning_rate": 0.000295704,
      "loss": 1.182,
      "step": 360
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.3122658431529999,
      "learning_rate": 0.00029546399999999995,
      "loss": 1.1801,
      "step": 380
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.4692147374153137,
      "learning_rate": 0.00029522399999999996,
      "loss": 1.1979,
      "step": 400
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.37670138478279114,
      "learning_rate": 0.000294984,
      "loss": 1.2201,
      "step": 420
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.3804420232772827,
      "learning_rate": 0.000294744,
      "loss": 1.1119,
      "step": 440
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.33184680342674255,
      "learning_rate": 0.00029450399999999996,
      "loss": 1.0643,
      "step": 460
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.33054637908935547,
      "learning_rate": 0.000294264,
      "loss": 1.044,
      "step": 480
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3971782624721527,
      "learning_rate": 0.00029402399999999993,
      "loss": 1.0754,
      "step": 500
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.4258401393890381,
      "learning_rate": 0.000293784,
      "loss": 1.0182,
      "step": 520
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.33099594712257385,
      "learning_rate": 0.00029354399999999997,
      "loss": 0.9356,
      "step": 540
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.3765801787376404,
      "learning_rate": 0.000293304,
      "loss": 0.9129,
      "step": 560
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.44469165802001953,
      "learning_rate": 0.00029306399999999994,
      "loss": 0.863,
      "step": 580
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.34290146827697754,
      "learning_rate": 0.00029282399999999996,
      "loss": 0.8917,
      "step": 600
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.432696670293808,
      "learning_rate": 0.000292584,
      "loss": 0.8632,
      "step": 620
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.43046462535858154,
      "learning_rate": 0.000292344,
      "loss": 0.8247,
      "step": 640
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.5412425398826599,
      "learning_rate": 0.00029210399999999995,
      "loss": 0.8284,
      "step": 660
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.37760698795318604,
      "learning_rate": 0.00029186399999999997,
      "loss": 0.8194,
      "step": 680
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.44410866498947144,
      "learning_rate": 0.000291624,
      "loss": 0.7373,
      "step": 700
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.4209699034690857,
      "learning_rate": 0.000291384,
      "loss": 0.7389,
      "step": 720
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.5020973682403564,
      "learning_rate": 0.00029114399999999996,
      "loss": 0.721,
      "step": 740
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.4316393733024597,
      "learning_rate": 0.000290904,
      "loss": 0.7081,
      "step": 760
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.45177415013313293,
      "learning_rate": 0.00029066399999999994,
      "loss": 0.6932,
      "step": 780
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.5218364596366882,
      "learning_rate": 0.000290424,
      "loss": 0.6453,
      "step": 800
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.4438527822494507,
      "learning_rate": 0.00029018399999999997,
      "loss": 0.6482,
      "step": 820
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.4042274057865143,
      "learning_rate": 0.000289944,
      "loss": 0.6001,
      "step": 840
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.37687796354293823,
      "learning_rate": 0.00028970399999999995,
      "loss": 0.5811,
      "step": 860
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.49205246567726135,
      "learning_rate": 0.00028946399999999996,
      "loss": 0.592,
      "step": 880
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.509200394153595,
      "learning_rate": 0.000289224,
      "loss": 0.582,
      "step": 900
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.4879590570926666,
      "learning_rate": 0.000288984,
      "loss": 0.5736,
      "step": 920
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.4637611210346222,
      "learning_rate": 0.00028874399999999996,
      "loss": 0.5413,
      "step": 940
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.40230533480644226,
      "learning_rate": 0.000288504,
      "loss": 0.5335,
      "step": 960
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.5281797051429749,
      "learning_rate": 0.00028826399999999994,
      "loss": 0.4856,
      "step": 980
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4060392379760742,
      "learning_rate": 0.000288024,
      "loss": 0.495,
      "step": 1000
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.5572633147239685,
      "learning_rate": 0.00028778399999999997,
      "loss": 0.4956,
      "step": 1020
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.42046743631362915,
      "learning_rate": 0.000287544,
      "loss": 0.4814,
      "step": 1040
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.4317673146724701,
      "learning_rate": 0.00028730399999999994,
      "loss": 0.4704,
      "step": 1060
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.4320422410964966,
      "learning_rate": 0.00028706399999999996,
      "loss": 0.4324,
      "step": 1080
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.507663369178772,
      "learning_rate": 0.000286824,
      "loss": 0.4462,
      "step": 1100
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.5563276410102844,
      "learning_rate": 0.000286584,
      "loss": 0.4117,
      "step": 1120
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.4509684145450592,
      "learning_rate": 0.00028634399999999995,
      "loss": 0.4119,
      "step": 1140
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.43540799617767334,
      "learning_rate": 0.00028610399999999997,
      "loss": 0.4008,
      "step": 1160
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.4256833791732788,
      "learning_rate": 0.000285864,
      "loss": 0.3986,
      "step": 1180
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.45854389667510986,
      "learning_rate": 0.000285624,
      "loss": 0.3732,
      "step": 1200
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.43382930755615234,
      "learning_rate": 0.00028538399999999996,
      "loss": 0.376,
      "step": 1220
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.5050376653671265,
      "learning_rate": 0.000285144,
      "loss": 0.3467,
      "step": 1240
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.49359363317489624,
      "learning_rate": 0.00028490399999999994,
      "loss": 0.3456,
      "step": 1260
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.47226017713546753,
      "learning_rate": 0.00028466399999999996,
      "loss": 0.3398,
      "step": 1280
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.44177618622779846,
      "learning_rate": 0.00028442399999999997,
      "loss": 0.3316,
      "step": 1300
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.4702262580394745,
      "learning_rate": 0.000284184,
      "loss": 0.3306,
      "step": 1320
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.3512618839740753,
      "learning_rate": 0.00028394399999999995,
      "loss": 0.2945,
      "step": 1340
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.4625534117221832,
      "learning_rate": 0.00028370399999999997,
      "loss": 0.3212,
      "step": 1360
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.5724679231643677,
      "learning_rate": 0.000283464,
      "loss": 0.3202,
      "step": 1380
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.47571849822998047,
      "learning_rate": 0.000283224,
      "loss": 0.2855,
      "step": 1400
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.49706733226776123,
      "learning_rate": 0.00028298399999999996,
      "loss": 0.28,
      "step": 1420
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.5584743618965149,
      "learning_rate": 0.000282744,
      "loss": 0.2842,
      "step": 1440
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.3725062608718872,
      "learning_rate": 0.000282504,
      "loss": 0.268,
      "step": 1460
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.4229063093662262,
      "learning_rate": 0.000282264,
      "loss": 0.2589,
      "step": 1480
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4499320387840271,
      "learning_rate": 0.00028202399999999997,
      "loss": 0.2584,
      "step": 1500
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.5188432931900024,
      "learning_rate": 0.000281784,
      "loss": 0.2515,
      "step": 1520
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.4370036721229553,
      "learning_rate": 0.00028154399999999995,
      "loss": 0.2442,
      "step": 1540
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.3665735423564911,
      "learning_rate": 0.00028130399999999996,
      "loss": 0.2273,
      "step": 1560
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.5074892044067383,
      "learning_rate": 0.000281064,
      "loss": 0.2243,
      "step": 1580
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.45862114429473877,
      "learning_rate": 0.000280824,
      "loss": 0.2368,
      "step": 1600
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.35123908519744873,
      "learning_rate": 0.00028058399999999995,
      "loss": 0.2275,
      "step": 1620
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.4267955422401428,
      "learning_rate": 0.00028034399999999997,
      "loss": 0.2047,
      "step": 1640
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.5170771479606628,
      "learning_rate": 0.000280104,
      "loss": 0.1994,
      "step": 1660
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.4443923234939575,
      "learning_rate": 0.000279864,
      "loss": 0.2017,
      "step": 1680
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.42513370513916016,
      "learning_rate": 0.00027962399999999996,
      "loss": 0.2063,
      "step": 1700
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.45203113555908203,
      "learning_rate": 0.000279384,
      "loss": 0.2014,
      "step": 1720
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.3989846110343933,
      "learning_rate": 0.00027914399999999994,
      "loss": 0.2047,
      "step": 1740
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.48414793610572815,
      "learning_rate": 0.00027890399999999996,
      "loss": 0.1817,
      "step": 1760
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.47065308690071106,
      "learning_rate": 0.000278664,
      "loss": 0.186,
      "step": 1780
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.41539791226387024,
      "learning_rate": 0.000278424,
      "loss": 0.1691,
      "step": 1800
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.38592106103897095,
      "learning_rate": 0.00027818399999999995,
      "loss": 0.184,
      "step": 1820
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.48552587628364563,
      "learning_rate": 0.00027794399999999997,
      "loss": 0.1645,
      "step": 1840
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.40158751606941223,
      "learning_rate": 0.000277704,
      "loss": 0.1644,
      "step": 1860
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.31146520376205444,
      "learning_rate": 0.000277464,
      "loss": 0.1633,
      "step": 1880
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.39706146717071533,
      "learning_rate": 0.00027722399999999996,
      "loss": 0.1604,
      "step": 1900
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.4350220263004303,
      "learning_rate": 0.000276984,
      "loss": 0.1628,
      "step": 1920
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.5339803099632263,
      "learning_rate": 0.000276744,
      "loss": 0.1506,
      "step": 1940
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.35269221663475037,
      "learning_rate": 0.000276504,
      "loss": 0.1531,
      "step": 1960
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.3639998435974121,
      "learning_rate": 0.00027626399999999997,
      "loss": 0.1403,
      "step": 1980
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3416488468647003,
      "learning_rate": 0.000276024,
      "loss": 0.1401,
      "step": 2000
    },
    {
      "epoch": 0.6464,
      "grad_norm": 0.38435161113739014,
      "learning_rate": 0.00027578399999999995,
      "loss": 0.1375,
      "step": 2020
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.39642244577407837,
      "learning_rate": 0.00027554399999999996,
      "loss": 0.1471,
      "step": 2040
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.42305582761764526,
      "learning_rate": 0.000275304,
      "loss": 0.1359,
      "step": 2060
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.41844382882118225,
      "learning_rate": 0.000275064,
      "loss": 0.1379,
      "step": 2080
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.3691486716270447,
      "learning_rate": 0.00027482399999999996,
      "loss": 0.1313,
      "step": 2100
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.4044358730316162,
      "learning_rate": 0.00027458399999999997,
      "loss": 0.1268,
      "step": 2120
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.41197577118873596,
      "learning_rate": 0.000274344,
      "loss": 0.128,
      "step": 2140
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.30333250761032104,
      "learning_rate": 0.000274104,
      "loss": 0.1255,
      "step": 2160
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.3544667065143585,
      "learning_rate": 0.00027386399999999997,
      "loss": 0.1188,
      "step": 2180
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.4486820101737976,
      "learning_rate": 0.000273624,
      "loss": 0.1202,
      "step": 2200
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.4255759119987488,
      "learning_rate": 0.000273384,
      "loss": 0.1193,
      "step": 2220
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.3834487199783325,
      "learning_rate": 0.00027314399999999996,
      "loss": 0.1193,
      "step": 2240
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.3661327362060547,
      "learning_rate": 0.000272904,
      "loss": 0.1183,
      "step": 2260
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.3330318033695221,
      "learning_rate": 0.000272664,
      "loss": 0.1143,
      "step": 2280
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.40760859847068787,
      "learning_rate": 0.00027242399999999995,
      "loss": 0.106,
      "step": 2300
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.38858848810195923,
      "learning_rate": 0.00027218399999999997,
      "loss": 0.1087,
      "step": 2320
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.4430272579193115,
      "learning_rate": 0.000271944,
      "loss": 0.11,
      "step": 2340
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.4615090787410736,
      "learning_rate": 0.000271704,
      "loss": 0.1086,
      "step": 2360
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.35732537508010864,
      "learning_rate": 0.00027146399999999996,
      "loss": 0.1024,
      "step": 2380
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.4213346540927887,
      "learning_rate": 0.000271224,
      "loss": 0.0998,
      "step": 2400
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.24975530803203583,
      "learning_rate": 0.000270984,
      "loss": 0.0945,
      "step": 2420
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.38684433698654175,
      "learning_rate": 0.00027074399999999995,
      "loss": 0.0958,
      "step": 2440
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.3321523368358612,
      "learning_rate": 0.00027050399999999997,
      "loss": 0.0913,
      "step": 2460
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.3585180640220642,
      "learning_rate": 0.000270264,
      "loss": 0.0962,
      "step": 2480
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.2622760236263275,
      "learning_rate": 0.00027002399999999995,
      "loss": 0.0859,
      "step": 2500
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.3693665862083435,
      "learning_rate": 0.00026978399999999996,
      "loss": 0.0906,
      "step": 2520
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.32696565985679626,
      "learning_rate": 0.000269544,
      "loss": 0.0969,
      "step": 2540
    },
    {
      "epoch": 0.8192,
      "grad_norm": 0.28650549054145813,
      "learning_rate": 0.000269304,
      "loss": 0.09,
      "step": 2560
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.3351968228816986,
      "learning_rate": 0.00026906399999999996,
      "loss": 0.0887,
      "step": 2580
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.33587974309921265,
      "learning_rate": 0.00026882399999999997,
      "loss": 0.0869,
      "step": 2600
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.3491334915161133,
      "learning_rate": 0.000268584,
      "loss": 0.0839,
      "step": 2620
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.29806968569755554,
      "learning_rate": 0.000268344,
      "loss": 0.0843,
      "step": 2640
    },
    {
      "epoch": 0.8512,
      "grad_norm": 0.3869370222091675,
      "learning_rate": 0.00026810399999999997,
      "loss": 0.0864,
      "step": 2660
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.29626038670539856,
      "learning_rate": 0.000267864,
      "loss": 0.083,
      "step": 2680
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.29492494463920593,
      "learning_rate": 0.000267624,
      "loss": 0.0748,
      "step": 2700
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.2553424537181854,
      "learning_rate": 0.00026738399999999996,
      "loss": 0.0768,
      "step": 2720
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.33322978019714355,
      "learning_rate": 0.000267144,
      "loss": 0.0788,
      "step": 2740
    },
    {
      "epoch": 0.8832,
      "grad_norm": 0.41431093215942383,
      "learning_rate": 0.000266904,
      "loss": 0.0749,
      "step": 2760
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.3289738893508911,
      "learning_rate": 0.00026666399999999995,
      "loss": 0.0778,
      "step": 2780
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.30173227190971375,
      "learning_rate": 0.00026642399999999997,
      "loss": 0.0777,
      "step": 2800
    },
    {
      "epoch": 0.9024,
      "grad_norm": 0.42416468262672424,
      "learning_rate": 0.000266184,
      "loss": 0.0759,
      "step": 2820
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.3101804256439209,
      "learning_rate": 0.000265944,
      "loss": 0.077,
      "step": 2840
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.32469508051872253,
      "learning_rate": 0.00026570399999999996,
      "loss": 0.0739,
      "step": 2860
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.3679228127002716,
      "learning_rate": 0.000265464,
      "loss": 0.0733,
      "step": 2880
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.29760146141052246,
      "learning_rate": 0.000265224,
      "loss": 0.0754,
      "step": 2900
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.3295266628265381,
      "learning_rate": 0.00026498399999999996,
      "loss": 0.0701,
      "step": 2920
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.39230620861053467,
      "learning_rate": 0.00026474399999999997,
      "loss": 0.0669,
      "step": 2940
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.2786427438259125,
      "learning_rate": 0.000264504,
      "loss": 0.0676,
      "step": 2960
    },
    {
      "epoch": 0.9536,
      "grad_norm": 0.29516133666038513,
      "learning_rate": 0.000264264,
      "loss": 0.0677,
      "step": 2980
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.30863267183303833,
      "learning_rate": 0.00026402399999999996,
      "loss": 0.0688,
      "step": 3000
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.3228791356086731,
      "learning_rate": 0.000263784,
      "loss": 0.0695,
      "step": 3020
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.3261873722076416,
      "learning_rate": 0.000263544,
      "loss": 0.0664,
      "step": 3040
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.32744625210762024,
      "learning_rate": 0.00026330399999999996,
      "loss": 0.066,
      "step": 3060
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.3841989040374756,
      "learning_rate": 0.000263064,
      "loss": 0.069,
      "step": 3080
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.3542599081993103,
      "learning_rate": 0.000262824,
      "loss": 0.0639,
      "step": 3100
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.31976133584976196,
      "learning_rate": 0.00026258399999999995,
      "loss": 0.063,
      "step": 3120
    },
    {
      "epoch": 1.0048,
      "grad_norm": 0.2919621467590332,
      "learning_rate": 0.00026234399999999997,
      "loss": 0.0654,
      "step": 3140
    },
    {
      "epoch": 1.0112,
      "grad_norm": 0.3537956178188324,
      "learning_rate": 0.000262104,
      "loss": 0.0626,
      "step": 3160
    },
    {
      "epoch": 1.0176,
      "grad_norm": 0.3017512559890747,
      "learning_rate": 0.000261864,
      "loss": 0.0603,
      "step": 3180
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.34429553151130676,
      "learning_rate": 0.00026162399999999996,
      "loss": 0.0583,
      "step": 3200
    },
    {
      "epoch": 1.0304,
      "grad_norm": 0.31714215874671936,
      "learning_rate": 0.000261384,
      "loss": 0.0573,
      "step": 3220
    },
    {
      "epoch": 1.0368,
      "grad_norm": 0.3200027644634247,
      "learning_rate": 0.000261144,
      "loss": 0.0629,
      "step": 3240
    },
    {
      "epoch": 1.0432,
      "grad_norm": 0.297684907913208,
      "learning_rate": 0.00026090399999999995,
      "loss": 0.0585,
      "step": 3260
    },
    {
      "epoch": 1.0496,
      "grad_norm": 0.2522341012954712,
      "learning_rate": 0.00026066399999999997,
      "loss": 0.0585,
      "step": 3280
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.26752331852912903,
      "learning_rate": 0.000260424,
      "loss": 0.0554,
      "step": 3300
    },
    {
      "epoch": 1.0624,
      "grad_norm": 0.2817286252975464,
      "learning_rate": 0.000260184,
      "loss": 0.0583,
      "step": 3320
    },
    {
      "epoch": 1.0688,
      "grad_norm": 0.2621428370475769,
      "learning_rate": 0.00025994399999999996,
      "loss": 0.0594,
      "step": 3340
    },
    {
      "epoch": 1.0752,
      "grad_norm": 0.2538585066795349,
      "learning_rate": 0.000259704,
      "loss": 0.0547,
      "step": 3360
    },
    {
      "epoch": 1.0816,
      "grad_norm": 0.30106931924819946,
      "learning_rate": 0.000259464,
      "loss": 0.0574,
      "step": 3380
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.28286150097846985,
      "learning_rate": 0.00025922399999999996,
      "loss": 0.0578,
      "step": 3400
    },
    {
      "epoch": 1.0944,
      "grad_norm": 0.3107590079307556,
      "learning_rate": 0.00025898399999999997,
      "loss": 0.0549,
      "step": 3420
    },
    {
      "epoch": 1.1008,
      "grad_norm": 0.2462007999420166,
      "learning_rate": 0.000258744,
      "loss": 0.053,
      "step": 3440
    },
    {
      "epoch": 1.1072,
      "grad_norm": 0.2776969373226166,
      "learning_rate": 0.000258504,
      "loss": 0.0529,
      "step": 3460
    },
    {
      "epoch": 1.1136,
      "grad_norm": 0.2933751046657562,
      "learning_rate": 0.00025826399999999997,
      "loss": 0.052,
      "step": 3480
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.26668497920036316,
      "learning_rate": 0.000258024,
      "loss": 0.0537,
      "step": 3500
    },
    {
      "epoch": 1.1264,
      "grad_norm": 0.26328134536743164,
      "learning_rate": 0.000257784,
      "loss": 0.0548,
      "step": 3520
    },
    {
      "epoch": 1.1328,
      "grad_norm": 0.2689262330532074,
      "learning_rate": 0.00025754399999999996,
      "loss": 0.053,
      "step": 3540
    },
    {
      "epoch": 1.1392,
      "grad_norm": 0.21817348897457123,
      "learning_rate": 0.000257304,
      "loss": 0.0516,
      "step": 3560
    },
    {
      "epoch": 1.1456,
      "grad_norm": 0.25786536931991577,
      "learning_rate": 0.000257064,
      "loss": 0.0516,
      "step": 3580
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.23104538023471832,
      "learning_rate": 0.00025682399999999995,
      "loss": 0.0506,
      "step": 3600
    },
    {
      "epoch": 1.1584,
      "grad_norm": 0.2933802902698517,
      "learning_rate": 0.00025658399999999997,
      "loss": 0.0507,
      "step": 3620
    },
    {
      "epoch": 1.1648,
      "grad_norm": 0.25142619013786316,
      "learning_rate": 0.000256344,
      "loss": 0.0501,
      "step": 3640
    },
    {
      "epoch": 1.1712,
      "grad_norm": 0.4142959713935852,
      "learning_rate": 0.000256104,
      "loss": 0.0516,
      "step": 3660
    },
    {
      "epoch": 1.1776,
      "grad_norm": 0.3354431986808777,
      "learning_rate": 0.00025586399999999996,
      "loss": 0.0487,
      "step": 3680
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.24073509871959686,
      "learning_rate": 0.000255624,
      "loss": 0.0476,
      "step": 3700
    },
    {
      "epoch": 1.1904,
      "grad_norm": 0.27010616660118103,
      "learning_rate": 0.000255384,
      "loss": 0.0506,
      "step": 3720
    },
    {
      "epoch": 1.1968,
      "grad_norm": 0.31417515873908997,
      "learning_rate": 0.000255144,
      "loss": 0.0483,
      "step": 3740
    },
    {
      "epoch": 1.2032,
      "grad_norm": 0.26127728819847107,
      "learning_rate": 0.00025490399999999997,
      "loss": 0.049,
      "step": 3760
    },
    {
      "epoch": 1.2096,
      "grad_norm": 0.2448798418045044,
      "learning_rate": 0.000254664,
      "loss": 0.0465,
      "step": 3780
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.21831829845905304,
      "learning_rate": 0.00025442399999999995,
      "loss": 0.0471,
      "step": 3800
    },
    {
      "epoch": 1.2224,
      "grad_norm": 0.2548292279243469,
      "learning_rate": 0.00025418399999999996,
      "loss": 0.0443,
      "step": 3820
    },
    {
      "epoch": 1.2288000000000001,
      "grad_norm": 0.29936379194259644,
      "learning_rate": 0.000253944,
      "loss": 0.0462,
      "step": 3840
    },
    {
      "epoch": 1.2352,
      "grad_norm": 0.2803479731082916,
      "learning_rate": 0.000253704,
      "loss": 0.0459,
      "step": 3860
    },
    {
      "epoch": 1.2416,
      "grad_norm": 0.29017162322998047,
      "learning_rate": 0.00025346399999999996,
      "loss": 0.0464,
      "step": 3880
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.25853317975997925,
      "learning_rate": 0.000253224,
      "loss": 0.0439,
      "step": 3900
    },
    {
      "epoch": 1.2544,
      "grad_norm": 0.40529242157936096,
      "learning_rate": 0.000252984,
      "loss": 0.0452,
      "step": 3920
    },
    {
      "epoch": 1.2608,
      "grad_norm": 0.2598601281642914,
      "learning_rate": 0.000252744,
      "loss": 0.0441,
      "step": 3940
    },
    {
      "epoch": 1.2671999999999999,
      "grad_norm": 0.3020227551460266,
      "learning_rate": 0.00025250399999999997,
      "loss": 0.0435,
      "step": 3960
    },
    {
      "epoch": 1.2736,
      "grad_norm": 0.26504966616630554,
      "learning_rate": 0.000252264,
      "loss": 0.0434,
      "step": 3980
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.32125377655029297,
      "learning_rate": 0.000252024,
      "loss": 0.042,
      "step": 4000
    },
    {
      "epoch": 1.2864,
      "grad_norm": 0.25823161005973816,
      "learning_rate": 0.00025178399999999996,
      "loss": 0.0446,
      "step": 4020
    },
    {
      "epoch": 1.2928,
      "grad_norm": 0.20604096353054047,
      "learning_rate": 0.000251544,
      "loss": 0.0438,
      "step": 4040
    },
    {
      "epoch": 1.2992,
      "grad_norm": 0.24580860137939453,
      "learning_rate": 0.000251304,
      "loss": 0.0431,
      "step": 4060
    },
    {
      "epoch": 1.3056,
      "grad_norm": 0.25588199496269226,
      "learning_rate": 0.00025106399999999995,
      "loss": 0.0422,
      "step": 4080
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.28342950344085693,
      "learning_rate": 0.00025082399999999997,
      "loss": 0.0423,
      "step": 4100
    },
    {
      "epoch": 1.3184,
      "grad_norm": 0.28477102518081665,
      "learning_rate": 0.000250584,
      "loss": 0.0416,
      "step": 4120
    },
    {
      "epoch": 1.3248,
      "grad_norm": 0.22977133095264435,
      "learning_rate": 0.000250344,
      "loss": 0.0409,
      "step": 4140
    },
    {
      "epoch": 1.3312,
      "grad_norm": 0.282782644033432,
      "learning_rate": 0.00025010399999999996,
      "loss": 0.0398,
      "step": 4160
    },
    {
      "epoch": 1.3376000000000001,
      "grad_norm": 0.2620178759098053,
      "learning_rate": 0.000249864,
      "loss": 0.0419,
      "step": 4180
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.25280019640922546,
      "learning_rate": 0.000249624,
      "loss": 0.0394,
      "step": 4200
    },
    {
      "epoch": 1.3504,
      "grad_norm": 0.2906453013420105,
      "learning_rate": 0.000249384,
      "loss": 0.0398,
      "step": 4220
    },
    {
      "epoch": 1.3568,
      "grad_norm": 0.19206544756889343,
      "learning_rate": 0.00024914399999999997,
      "loss": 0.039,
      "step": 4240
    },
    {
      "epoch": 1.3632,
      "grad_norm": 0.25180768966674805,
      "learning_rate": 0.000248904,
      "loss": 0.0419,
      "step": 4260
    },
    {
      "epoch": 1.3696,
      "grad_norm": 0.2004217654466629,
      "learning_rate": 0.00024866399999999995,
      "loss": 0.0387,
      "step": 4280
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.23348622024059296,
      "learning_rate": 0.00024842399999999996,
      "loss": 0.0399,
      "step": 4300
    },
    {
      "epoch": 1.3824,
      "grad_norm": 0.2529768645763397,
      "learning_rate": 0.000248184,
      "loss": 0.0404,
      "step": 4320
    },
    {
      "epoch": 1.3888,
      "grad_norm": 0.2709430158138275,
      "learning_rate": 0.000247944,
      "loss": 0.0383,
      "step": 4340
    },
    {
      "epoch": 1.3952,
      "grad_norm": 0.26183485984802246,
      "learning_rate": 0.00024770399999999996,
      "loss": 0.0373,
      "step": 4360
    },
    {
      "epoch": 1.4016,
      "grad_norm": 0.23991374671459198,
      "learning_rate": 0.000247464,
      "loss": 0.0405,
      "step": 4380
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.1602645069360733,
      "learning_rate": 0.000247224,
      "loss": 0.0389,
      "step": 4400
    },
    {
      "epoch": 1.4144,
      "grad_norm": 0.2944088876247406,
      "learning_rate": 0.000246984,
      "loss": 0.04,
      "step": 4420
    },
    {
      "epoch": 1.4208,
      "grad_norm": 0.2367287427186966,
      "learning_rate": 0.00024674399999999997,
      "loss": 0.0385,
      "step": 4440
    },
    {
      "epoch": 1.4272,
      "grad_norm": 0.2660709023475647,
      "learning_rate": 0.000246504,
      "loss": 0.0367,
      "step": 4460
    },
    {
      "epoch": 1.4336,
      "grad_norm": 0.21071751415729523,
      "learning_rate": 0.000246264,
      "loss": 0.0377,
      "step": 4480
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.24223832786083221,
      "learning_rate": 0.000246024,
      "loss": 0.0358,
      "step": 4500
    },
    {
      "epoch": 1.4464000000000001,
      "grad_norm": 0.26249828934669495,
      "learning_rate": 0.000245784,
      "loss": 0.0376,
      "step": 4520
    },
    {
      "epoch": 1.4527999999999999,
      "grad_norm": 0.26370367407798767,
      "learning_rate": 0.000245544,
      "loss": 0.0359,
      "step": 4540
    },
    {
      "epoch": 1.4592,
      "grad_norm": 0.27515244483947754,
      "learning_rate": 0.00024530399999999995,
      "loss": 0.0364,
      "step": 4560
    },
    {
      "epoch": 1.4656,
      "grad_norm": 0.2994830310344696,
      "learning_rate": 0.00024506399999999997,
      "loss": 0.0365,
      "step": 4580
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.2533891499042511,
      "learning_rate": 0.000244824,
      "loss": 0.0345,
      "step": 4600
    },
    {
      "epoch": 1.4784,
      "grad_norm": 0.2521171569824219,
      "learning_rate": 0.000244584,
      "loss": 0.037,
      "step": 4620
    },
    {
      "epoch": 1.4848,
      "grad_norm": 0.21110714972019196,
      "learning_rate": 0.00024434399999999996,
      "loss": 0.036,
      "step": 4640
    },
    {
      "epoch": 1.4912,
      "grad_norm": 0.2748233675956726,
      "learning_rate": 0.00024410399999999998,
      "loss": 0.0366,
      "step": 4660
    },
    {
      "epoch": 1.4976,
      "grad_norm": 0.16329102218151093,
      "learning_rate": 0.000243864,
      "loss": 0.0364,
      "step": 4680
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.2366384118795395,
      "learning_rate": 0.00024362399999999998,
      "loss": 0.0339,
      "step": 4700
    },
    {
      "epoch": 1.5104,
      "grad_norm": 0.2677168548107147,
      "learning_rate": 0.00024338399999999997,
      "loss": 0.0345,
      "step": 4720
    },
    {
      "epoch": 1.5168,
      "grad_norm": 0.3134106695652008,
      "learning_rate": 0.00024314399999999996,
      "loss": 0.0333,
      "step": 4740
    },
    {
      "epoch": 1.5232,
      "grad_norm": 0.23842255771160126,
      "learning_rate": 0.00024290399999999998,
      "loss": 0.0366,
      "step": 4760
    },
    {
      "epoch": 1.5295999999999998,
      "grad_norm": 0.1891559362411499,
      "learning_rate": 0.000242664,
      "loss": 0.0344,
      "step": 4780
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.23227863013744354,
      "learning_rate": 0.00024242399999999998,
      "loss": 0.0349,
      "step": 4800
    },
    {
      "epoch": 1.5424,
      "grad_norm": 0.25736674666404724,
      "learning_rate": 0.00024218399999999997,
      "loss": 0.0357,
      "step": 4820
    },
    {
      "epoch": 1.5488,
      "grad_norm": 0.2683209776878357,
      "learning_rate": 0.00024194399999999996,
      "loss": 0.0339,
      "step": 4840
    },
    {
      "epoch": 1.5552000000000001,
      "grad_norm": 0.22675344347953796,
      "learning_rate": 0.00024170399999999997,
      "loss": 0.0345,
      "step": 4860
    },
    {
      "epoch": 1.5615999999999999,
      "grad_norm": 0.18960362672805786,
      "learning_rate": 0.000241464,
      "loss": 0.0326,
      "step": 4880
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.2508092522621155,
      "learning_rate": 0.00024122399999999998,
      "loss": 0.0339,
      "step": 4900
    },
    {
      "epoch": 1.5744,
      "grad_norm": 0.21156629920005798,
      "learning_rate": 0.00024098399999999997,
      "loss": 0.0326,
      "step": 4920
    },
    {
      "epoch": 1.5808,
      "grad_norm": 0.19841518998146057,
      "learning_rate": 0.00024074399999999996,
      "loss": 0.0314,
      "step": 4940
    },
    {
      "epoch": 1.5872000000000002,
      "grad_norm": 0.2603996992111206,
      "learning_rate": 0.00024050399999999997,
      "loss": 0.0333,
      "step": 4960
    },
    {
      "epoch": 1.5936,
      "grad_norm": 0.26602914929389954,
      "learning_rate": 0.000240264,
      "loss": 0.0328,
      "step": 4980
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.20480205118656158,
      "learning_rate": 0.00024002399999999998,
      "loss": 0.0326,
      "step": 5000
    },
    {
      "epoch": 1.6064,
      "grad_norm": 0.22564545273780823,
      "learning_rate": 0.00023978399999999997,
      "loss": 0.0303,
      "step": 5020
    },
    {
      "epoch": 1.6128,
      "grad_norm": 0.25681376457214355,
      "learning_rate": 0.00023954399999999998,
      "loss": 0.0325,
      "step": 5040
    },
    {
      "epoch": 1.6192,
      "grad_norm": 0.18895404040813446,
      "learning_rate": 0.00023930399999999997,
      "loss": 0.0333,
      "step": 5060
    },
    {
      "epoch": 1.6256,
      "grad_norm": 0.18261843919754028,
      "learning_rate": 0.000239064,
      "loss": 0.0314,
      "step": 5080
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.22368521988391876,
      "learning_rate": 0.00023882399999999998,
      "loss": 0.0318,
      "step": 5100
    },
    {
      "epoch": 1.6383999999999999,
      "grad_norm": 0.26862573623657227,
      "learning_rate": 0.00023858399999999996,
      "loss": 0.0316,
      "step": 5120
    },
    {
      "epoch": 1.6448,
      "grad_norm": 0.23341451585292816,
      "learning_rate": 0.00023834399999999998,
      "loss": 0.0313,
      "step": 5140
    },
    {
      "epoch": 1.6512,
      "grad_norm": 0.23171178996562958,
      "learning_rate": 0.000238104,
      "loss": 0.0313,
      "step": 5160
    },
    {
      "epoch": 1.6576,
      "grad_norm": 0.19608409702777863,
      "learning_rate": 0.00023786399999999998,
      "loss": 0.0317,
      "step": 5180
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.26350975036621094,
      "learning_rate": 0.00023762399999999997,
      "loss": 0.0328,
      "step": 5200
    },
    {
      "epoch": 1.6703999999999999,
      "grad_norm": 0.22097787261009216,
      "learning_rate": 0.00023738399999999996,
      "loss": 0.0315,
      "step": 5220
    },
    {
      "epoch": 1.6768,
      "grad_norm": 0.18711481988430023,
      "learning_rate": 0.00023714399999999998,
      "loss": 0.0283,
      "step": 5240
    },
    {
      "epoch": 1.6832,
      "grad_norm": 0.2212747484445572,
      "learning_rate": 0.000236904,
      "loss": 0.0305,
      "step": 5260
    },
    {
      "epoch": 1.6896,
      "grad_norm": 0.21905508637428284,
      "learning_rate": 0.00023666399999999998,
      "loss": 0.0309,
      "step": 5280
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.21728678047657013,
      "learning_rate": 0.00023642399999999997,
      "loss": 0.0301,
      "step": 5300
    },
    {
      "epoch": 1.7024,
      "grad_norm": 0.19335255026817322,
      "learning_rate": 0.00023618399999999996,
      "loss": 0.0301,
      "step": 5320
    },
    {
      "epoch": 1.7088,
      "grad_norm": 0.23180189728736877,
      "learning_rate": 0.00023594399999999998,
      "loss": 0.0302,
      "step": 5340
    },
    {
      "epoch": 1.7151999999999998,
      "grad_norm": 0.17687773704528809,
      "learning_rate": 0.000235704,
      "loss": 0.0286,
      "step": 5360
    },
    {
      "epoch": 1.7216,
      "grad_norm": 0.24660338461399078,
      "learning_rate": 0.00023546399999999998,
      "loss": 0.0322,
      "step": 5380
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.2552453577518463,
      "learning_rate": 0.00023522399999999997,
      "loss": 0.0288,
      "step": 5400
    },
    {
      "epoch": 1.7344,
      "grad_norm": 0.1651497483253479,
      "learning_rate": 0.00023498399999999998,
      "loss": 0.0307,
      "step": 5420
    },
    {
      "epoch": 1.7408000000000001,
      "grad_norm": 0.2307729721069336,
      "learning_rate": 0.00023474399999999997,
      "loss": 0.0277,
      "step": 5440
    },
    {
      "epoch": 1.7471999999999999,
      "grad_norm": 0.20959815382957458,
      "learning_rate": 0.000234504,
      "loss": 0.0287,
      "step": 5460
    },
    {
      "epoch": 1.7536,
      "grad_norm": 0.22895397245883942,
      "learning_rate": 0.00023426399999999998,
      "loss": 0.028,
      "step": 5480
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.23309960961341858,
      "learning_rate": 0.00023402399999999997,
      "loss": 0.0298,
      "step": 5500
    },
    {
      "epoch": 1.7664,
      "grad_norm": 0.2128545194864273,
      "learning_rate": 0.00023378399999999998,
      "loss": 0.0298,
      "step": 5520
    },
    {
      "epoch": 1.7728000000000002,
      "grad_norm": 0.19250762462615967,
      "learning_rate": 0.00023354399999999997,
      "loss": 0.028,
      "step": 5540
    },
    {
      "epoch": 1.7792,
      "grad_norm": 0.19298642873764038,
      "learning_rate": 0.000233304,
      "loss": 0.0284,
      "step": 5560
    },
    {
      "epoch": 1.7856,
      "grad_norm": 0.16550080478191376,
      "learning_rate": 0.00023306399999999998,
      "loss": 0.0277,
      "step": 5580
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.17536897957324982,
      "learning_rate": 0.00023282399999999997,
      "loss": 0.0282,
      "step": 5600
    },
    {
      "epoch": 1.7984,
      "grad_norm": 0.20350967347621918,
      "learning_rate": 0.00023258399999999998,
      "loss": 0.0268,
      "step": 5620
    },
    {
      "epoch": 1.8048,
      "grad_norm": 0.2834165692329407,
      "learning_rate": 0.00023234399999999997,
      "loss": 0.0282,
      "step": 5640
    },
    {
      "epoch": 1.8112,
      "grad_norm": 0.19714589416980743,
      "learning_rate": 0.00023210399999999999,
      "loss": 0.0277,
      "step": 5660
    },
    {
      "epoch": 1.8176,
      "grad_norm": 0.25597745180130005,
      "learning_rate": 0.00023186399999999997,
      "loss": 0.0281,
      "step": 5680
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.1940745860338211,
      "learning_rate": 0.00023162399999999996,
      "loss": 0.028,
      "step": 5700
    },
    {
      "epoch": 1.8304,
      "grad_norm": 0.19599281251430511,
      "learning_rate": 0.00023138399999999998,
      "loss": 0.0278,
      "step": 5720
    },
    {
      "epoch": 1.8368,
      "grad_norm": 0.18780972063541412,
      "learning_rate": 0.000231144,
      "loss": 0.0263,
      "step": 5740
    },
    {
      "epoch": 1.8432,
      "grad_norm": 0.24252144992351532,
      "learning_rate": 0.00023090399999999998,
      "loss": 0.028,
      "step": 5760
    },
    {
      "epoch": 1.8496000000000001,
      "grad_norm": 0.21932703256607056,
      "learning_rate": 0.00023066399999999997,
      "loss": 0.0286,
      "step": 5780
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.2607325315475464,
      "learning_rate": 0.000230424,
      "loss": 0.0265,
      "step": 5800
    },
    {
      "epoch": 1.8624,
      "grad_norm": 0.187930628657341,
      "learning_rate": 0.00023018399999999998,
      "loss": 0.0269,
      "step": 5820
    },
    {
      "epoch": 1.8688,
      "grad_norm": 0.21045419573783875,
      "learning_rate": 0.000229944,
      "loss": 0.028,
      "step": 5840
    },
    {
      "epoch": 1.8752,
      "grad_norm": 0.19968202710151672,
      "learning_rate": 0.00022970399999999998,
      "loss": 0.0264,
      "step": 5860
    },
    {
      "epoch": 1.8816000000000002,
      "grad_norm": 0.23506207764148712,
      "learning_rate": 0.00022946399999999997,
      "loss": 0.0268,
      "step": 5880
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.2180708944797516,
      "learning_rate": 0.00022922399999999999,
      "loss": 0.0286,
      "step": 5900
    },
    {
      "epoch": 1.8944,
      "grad_norm": 0.19695548713207245,
      "learning_rate": 0.00022898399999999997,
      "loss": 0.0281,
      "step": 5920
    },
    {
      "epoch": 1.9008,
      "grad_norm": 0.21412478387355804,
      "learning_rate": 0.000228744,
      "loss": 0.0274,
      "step": 5940
    },
    {
      "epoch": 1.9072,
      "grad_norm": 0.25422677397727966,
      "learning_rate": 0.00022850399999999998,
      "loss": 0.0276,
      "step": 5960
    },
    {
      "epoch": 1.9136,
      "grad_norm": 0.19224336743354797,
      "learning_rate": 0.00022826399999999997,
      "loss": 0.0289,
      "step": 5980
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.20099881291389465,
      "learning_rate": 0.00022802399999999998,
      "loss": 0.0263,
      "step": 6000
    },
    {
      "epoch": 1.9264000000000001,
      "grad_norm": 0.21684332191944122,
      "learning_rate": 0.00022778399999999997,
      "loss": 0.0259,
      "step": 6020
    },
    {
      "epoch": 1.9327999999999999,
      "grad_norm": 0.19383537769317627,
      "learning_rate": 0.000227544,
      "loss": 0.0259,
      "step": 6040
    },
    {
      "epoch": 1.9392,
      "grad_norm": 0.2525630593299866,
      "learning_rate": 0.00022730399999999998,
      "loss": 0.0273,
      "step": 6060
    },
    {
      "epoch": 1.9456,
      "grad_norm": 0.19344332814216614,
      "learning_rate": 0.00022706399999999997,
      "loss": 0.0259,
      "step": 6080
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.20732487738132477,
      "learning_rate": 0.00022682399999999998,
      "loss": 0.0256,
      "step": 6100
    },
    {
      "epoch": 1.9584000000000001,
      "grad_norm": 0.18726442754268646,
      "learning_rate": 0.00022658399999999997,
      "loss": 0.0266,
      "step": 6120
    },
    {
      "epoch": 1.9647999999999999,
      "grad_norm": 0.23515382409095764,
      "learning_rate": 0.00022634399999999999,
      "loss": 0.0248,
      "step": 6140
    },
    {
      "epoch": 1.9712,
      "grad_norm": 0.19130219519138336,
      "learning_rate": 0.00022610399999999998,
      "loss": 0.0267,
      "step": 6160
    },
    {
      "epoch": 1.9776,
      "grad_norm": 0.1849171370267868,
      "learning_rate": 0.000225864,
      "loss": 0.0275,
      "step": 6180
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.23201824724674225,
      "learning_rate": 0.00022562399999999998,
      "loss": 0.0265,
      "step": 6200
    },
    {
      "epoch": 1.9904,
      "grad_norm": 0.22810542583465576,
      "learning_rate": 0.00022538399999999997,
      "loss": 0.0263,
      "step": 6220
    },
    {
      "epoch": 1.9968,
      "grad_norm": 0.16385996341705322,
      "learning_rate": 0.00022514399999999998,
      "loss": 0.0251,
      "step": 6240
    },
    {
      "epoch": 2.0032,
      "grad_norm": 0.1918218731880188,
      "learning_rate": 0.00022490399999999997,
      "loss": 0.0248,
      "step": 6260
    },
    {
      "epoch": 2.0096,
      "grad_norm": 0.21228621900081635,
      "learning_rate": 0.000224664,
      "loss": 0.0265,
      "step": 6280
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.23781844973564148,
      "learning_rate": 0.00022442399999999998,
      "loss": 0.0258,
      "step": 6300
    },
    {
      "epoch": 2.0224,
      "grad_norm": 0.22056762874126434,
      "learning_rate": 0.000224184,
      "loss": 0.0266,
      "step": 6320
    },
    {
      "epoch": 2.0288,
      "grad_norm": 0.15052065253257751,
      "learning_rate": 0.00022394399999999998,
      "loss": 0.0243,
      "step": 6340
    },
    {
      "epoch": 2.0352,
      "grad_norm": 0.24035726487636566,
      "learning_rate": 0.00022370399999999997,
      "loss": 0.0256,
      "step": 6360
    },
    {
      "epoch": 2.0416,
      "grad_norm": 0.20438463985919952,
      "learning_rate": 0.000223464,
      "loss": 0.0243,
      "step": 6380
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.14975278079509735,
      "learning_rate": 0.00022322399999999998,
      "loss": 0.0249,
      "step": 6400
    },
    {
      "epoch": 2.0544,
      "grad_norm": 0.2696761190891266,
      "learning_rate": 0.000222984,
      "loss": 0.0248,
      "step": 6420
    },
    {
      "epoch": 2.0608,
      "grad_norm": 0.18348287045955658,
      "learning_rate": 0.00022274399999999998,
      "loss": 0.0234,
      "step": 6440
    },
    {
      "epoch": 2.0672,
      "grad_norm": 0.2287796139717102,
      "learning_rate": 0.00022250399999999997,
      "loss": 0.0248,
      "step": 6460
    },
    {
      "epoch": 2.0736,
      "grad_norm": 0.19867652654647827,
      "learning_rate": 0.00022226399999999998,
      "loss": 0.0245,
      "step": 6480
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.24093268811702728,
      "learning_rate": 0.00022202399999999997,
      "loss": 0.0238,
      "step": 6500
    },
    {
      "epoch": 2.0864,
      "grad_norm": 0.1982443481683731,
      "learning_rate": 0.000221784,
      "loss": 0.0254,
      "step": 6520
    },
    {
      "epoch": 2.0928,
      "grad_norm": 0.1902242749929428,
      "learning_rate": 0.00022154399999999998,
      "loss": 0.0233,
      "step": 6540
    },
    {
      "epoch": 2.0992,
      "grad_norm": 0.19533850252628326,
      "learning_rate": 0.000221304,
      "loss": 0.0253,
      "step": 6560
    },
    {
      "epoch": 2.1056,
      "grad_norm": 0.1560564935207367,
      "learning_rate": 0.00022106399999999998,
      "loss": 0.0239,
      "step": 6580
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.1630593240261078,
      "learning_rate": 0.00022082399999999997,
      "loss": 0.0235,
      "step": 6600
    },
    {
      "epoch": 2.1184,
      "grad_norm": 0.19443725049495697,
      "learning_rate": 0.000220584,
      "loss": 0.0239,
      "step": 6620
    },
    {
      "epoch": 2.1248,
      "grad_norm": 0.1955489218235016,
      "learning_rate": 0.00022034399999999998,
      "loss": 0.0245,
      "step": 6640
    },
    {
      "epoch": 2.1312,
      "grad_norm": 0.20541638135910034,
      "learning_rate": 0.000220104,
      "loss": 0.0244,
      "step": 6660
    },
    {
      "epoch": 2.1376,
      "grad_norm": 0.1550033837556839,
      "learning_rate": 0.00021986399999999998,
      "loss": 0.0242,
      "step": 6680
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.18005143105983734,
      "learning_rate": 0.00021962399999999997,
      "loss": 0.0243,
      "step": 6700
    },
    {
      "epoch": 2.1504,
      "grad_norm": 0.1293894499540329,
      "learning_rate": 0.00021938399999999999,
      "loss": 0.0229,
      "step": 6720
    },
    {
      "epoch": 2.1568,
      "grad_norm": 0.15448860824108124,
      "learning_rate": 0.00021914399999999997,
      "loss": 0.0225,
      "step": 6740
    },
    {
      "epoch": 2.1632,
      "grad_norm": 0.22043476998806,
      "learning_rate": 0.000218904,
      "loss": 0.0231,
      "step": 6760
    },
    {
      "epoch": 2.1696,
      "grad_norm": 0.18594807386398315,
      "learning_rate": 0.00021866399999999998,
      "loss": 0.0233,
      "step": 6780
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.24964359402656555,
      "learning_rate": 0.00021842399999999997,
      "loss": 0.0228,
      "step": 6800
    },
    {
      "epoch": 2.1824,
      "grad_norm": 0.18450139462947845,
      "learning_rate": 0.00021818399999999998,
      "loss": 0.0225,
      "step": 6820
    },
    {
      "epoch": 2.1888,
      "grad_norm": 0.22438980638980865,
      "learning_rate": 0.00021794399999999997,
      "loss": 0.0222,
      "step": 6840
    },
    {
      "epoch": 2.1952,
      "grad_norm": 0.15666067600250244,
      "learning_rate": 0.000217704,
      "loss": 0.0235,
      "step": 6860
    },
    {
      "epoch": 2.2016,
      "grad_norm": 0.2284983992576599,
      "learning_rate": 0.00021746399999999998,
      "loss": 0.0235,
      "step": 6880
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.15066157281398773,
      "learning_rate": 0.00021722399999999997,
      "loss": 0.023,
      "step": 6900
    },
    {
      "epoch": 2.2144,
      "grad_norm": 0.1818191558122635,
      "learning_rate": 0.00021698399999999998,
      "loss": 0.0233,
      "step": 6920
    },
    {
      "epoch": 2.2208,
      "grad_norm": 0.1978355199098587,
      "learning_rate": 0.000216744,
      "loss": 0.0244,
      "step": 6940
    },
    {
      "epoch": 2.2272,
      "grad_norm": 0.1883239895105362,
      "learning_rate": 0.00021650399999999999,
      "loss": 0.0232,
      "step": 6960
    },
    {
      "epoch": 2.2336,
      "grad_norm": 0.16939985752105713,
      "learning_rate": 0.00021626399999999997,
      "loss": 0.0245,
      "step": 6980
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.20019009709358215,
      "learning_rate": 0.000216024,
      "loss": 0.0227,
      "step": 7000
    },
    {
      "epoch": 2.2464,
      "grad_norm": 0.21661339700222015,
      "learning_rate": 0.00021578399999999998,
      "loss": 0.0238,
      "step": 7020
    },
    {
      "epoch": 2.2528,
      "grad_norm": 0.22104261815547943,
      "learning_rate": 0.000215544,
      "loss": 0.0226,
      "step": 7040
    },
    {
      "epoch": 2.2592,
      "grad_norm": 0.1648542284965515,
      "learning_rate": 0.00021530399999999998,
      "loss": 0.023,
      "step": 7060
    },
    {
      "epoch": 2.2656,
      "grad_norm": 0.23289048671722412,
      "learning_rate": 0.00021506399999999997,
      "loss": 0.0231,
      "step": 7080
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.18521331250667572,
      "learning_rate": 0.000214824,
      "loss": 0.0244,
      "step": 7100
    },
    {
      "epoch": 2.2784,
      "grad_norm": 0.1822579801082611,
      "learning_rate": 0.00021458399999999998,
      "loss": 0.023,
      "step": 7120
    },
    {
      "epoch": 2.2848,
      "grad_norm": 0.19792304933071136,
      "learning_rate": 0.000214344,
      "loss": 0.0227,
      "step": 7140
    },
    {
      "epoch": 2.2912,
      "grad_norm": 0.15945997834205627,
      "learning_rate": 0.00021410399999999998,
      "loss": 0.022,
      "step": 7160
    },
    {
      "epoch": 2.2976,
      "grad_norm": 0.17132914066314697,
      "learning_rate": 0.00021386399999999997,
      "loss": 0.0223,
      "step": 7180
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.2736147344112396,
      "learning_rate": 0.00021362399999999999,
      "loss": 0.0225,
      "step": 7200
    },
    {
      "epoch": 2.3104,
      "grad_norm": 0.21226316690444946,
      "learning_rate": 0.00021338399999999997,
      "loss": 0.0229,
      "step": 7220
    },
    {
      "epoch": 2.3168,
      "grad_norm": 0.15319304168224335,
      "learning_rate": 0.000213144,
      "loss": 0.0233,
      "step": 7240
    },
    {
      "epoch": 2.3232,
      "grad_norm": 0.19563813507556915,
      "learning_rate": 0.00021290399999999998,
      "loss": 0.0228,
      "step": 7260
    },
    {
      "epoch": 2.3296,
      "grad_norm": 0.13394467532634735,
      "learning_rate": 0.00021266399999999997,
      "loss": 0.022,
      "step": 7280
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.19906051456928253,
      "learning_rate": 0.00021242399999999998,
      "loss": 0.0227,
      "step": 7300
    },
    {
      "epoch": 2.3424,
      "grad_norm": 0.2264624983072281,
      "learning_rate": 0.000212184,
      "loss": 0.0231,
      "step": 7320
    },
    {
      "epoch": 2.3487999999999998,
      "grad_norm": 0.1683742254972458,
      "learning_rate": 0.000211944,
      "loss": 0.0211,
      "step": 7340
    },
    {
      "epoch": 2.3552,
      "grad_norm": 0.15793828666210175,
      "learning_rate": 0.00021170399999999998,
      "loss": 0.0213,
      "step": 7360
    },
    {
      "epoch": 2.3616,
      "grad_norm": 0.1440078318119049,
      "learning_rate": 0.00021146399999999997,
      "loss": 0.0226,
      "step": 7380
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.18069405853748322,
      "learning_rate": 0.00021122399999999998,
      "loss": 0.0229,
      "step": 7400
    },
    {
      "epoch": 2.3744,
      "grad_norm": 0.25116080045700073,
      "learning_rate": 0.000210984,
      "loss": 0.0229,
      "step": 7420
    },
    {
      "epoch": 2.3808,
      "grad_norm": 0.17307217419147491,
      "learning_rate": 0.000210744,
      "loss": 0.0217,
      "step": 7440
    },
    {
      "epoch": 2.3872,
      "grad_norm": 0.1308964490890503,
      "learning_rate": 0.00021050399999999998,
      "loss": 0.0214,
      "step": 7460
    },
    {
      "epoch": 2.3936,
      "grad_norm": 0.23136335611343384,
      "learning_rate": 0.00021026399999999996,
      "loss": 0.0218,
      "step": 7480
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.11485445499420166,
      "learning_rate": 0.00021002399999999998,
      "loss": 0.0217,
      "step": 7500
    },
    {
      "epoch": 2.4064,
      "grad_norm": 0.16901105642318726,
      "learning_rate": 0.000209784,
      "loss": 0.0219,
      "step": 7520
    },
    {
      "epoch": 2.4128,
      "grad_norm": 0.17754040658473969,
      "learning_rate": 0.00020954399999999998,
      "loss": 0.0205,
      "step": 7540
    },
    {
      "epoch": 2.4192,
      "grad_norm": 0.16399595141410828,
      "learning_rate": 0.00020930399999999997,
      "loss": 0.0217,
      "step": 7560
    },
    {
      "epoch": 2.4256,
      "grad_norm": 0.1748351901769638,
      "learning_rate": 0.000209064,
      "loss": 0.0221,
      "step": 7580
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.18886253237724304,
      "learning_rate": 0.00020882399999999998,
      "loss": 0.0209,
      "step": 7600
    },
    {
      "epoch": 2.4384,
      "grad_norm": 0.13997647166252136,
      "learning_rate": 0.000208584,
      "loss": 0.0208,
      "step": 7620
    },
    {
      "epoch": 2.4448,
      "grad_norm": 0.24722693860530853,
      "learning_rate": 0.00020834399999999998,
      "loss": 0.0216,
      "step": 7640
    },
    {
      "epoch": 2.4512,
      "grad_norm": 0.19340522587299347,
      "learning_rate": 0.00020810399999999997,
      "loss": 0.0212,
      "step": 7660
    },
    {
      "epoch": 2.4576000000000002,
      "grad_norm": 0.24751389026641846,
      "learning_rate": 0.000207864,
      "loss": 0.0209,
      "step": 7680
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.24767610430717468,
      "learning_rate": 0.000207624,
      "loss": 0.0216,
      "step": 7700
    },
    {
      "epoch": 2.4704,
      "grad_norm": 0.18583223223686218,
      "learning_rate": 0.000207384,
      "loss": 0.0208,
      "step": 7720
    },
    {
      "epoch": 2.4768,
      "grad_norm": 0.16563351452350616,
      "learning_rate": 0.00020714399999999998,
      "loss": 0.0212,
      "step": 7740
    },
    {
      "epoch": 2.4832,
      "grad_norm": 0.19147755205631256,
      "learning_rate": 0.00020690399999999997,
      "loss": 0.0215,
      "step": 7760
    },
    {
      "epoch": 2.4896,
      "grad_norm": 0.20458576083183289,
      "learning_rate": 0.00020666399999999999,
      "loss": 0.0212,
      "step": 7780
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.16756857931613922,
      "learning_rate": 0.000206424,
      "loss": 0.021,
      "step": 7800
    },
    {
      "epoch": 2.5023999999999997,
      "grad_norm": 0.1861184984445572,
      "learning_rate": 0.000206184,
      "loss": 0.0209,
      "step": 7820
    },
    {
      "epoch": 2.5088,
      "grad_norm": 0.1596573442220688,
      "learning_rate": 0.00020594399999999998,
      "loss": 0.0218,
      "step": 7840
    },
    {
      "epoch": 2.5152,
      "grad_norm": 0.155955970287323,
      "learning_rate": 0.00020570399999999997,
      "loss": 0.0213,
      "step": 7860
    },
    {
      "epoch": 2.5216,
      "grad_norm": 0.1279660016298294,
      "learning_rate": 0.00020546399999999998,
      "loss": 0.0207,
      "step": 7880
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.22193481028079987,
      "learning_rate": 0.000205224,
      "loss": 0.0214,
      "step": 7900
    },
    {
      "epoch": 2.5343999999999998,
      "grad_norm": 0.12749932706356049,
      "learning_rate": 0.000204984,
      "loss": 0.0206,
      "step": 7920
    },
    {
      "epoch": 2.5408,
      "grad_norm": 0.2244364321231842,
      "learning_rate": 0.00020474399999999998,
      "loss": 0.0202,
      "step": 7940
    },
    {
      "epoch": 2.5472,
      "grad_norm": 0.18758156895637512,
      "learning_rate": 0.00020450399999999997,
      "loss": 0.021,
      "step": 7960
    },
    {
      "epoch": 2.5536,
      "grad_norm": 0.19826294481754303,
      "learning_rate": 0.00020426399999999998,
      "loss": 0.021,
      "step": 7980
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.20731320977210999,
      "learning_rate": 0.000204024,
      "loss": 0.02,
      "step": 8000
    },
    {
      "epoch": 2.5664,
      "grad_norm": 0.20912796258926392,
      "learning_rate": 0.00020378399999999999,
      "loss": 0.0206,
      "step": 8020
    },
    {
      "epoch": 2.5728,
      "grad_norm": 0.17527025938034058,
      "learning_rate": 0.00020354399999999997,
      "loss": 0.0214,
      "step": 8040
    },
    {
      "epoch": 2.5792,
      "grad_norm": 0.1401713341474533,
      "learning_rate": 0.00020330399999999996,
      "loss": 0.021,
      "step": 8060
    },
    {
      "epoch": 2.5856,
      "grad_norm": 0.1898951530456543,
      "learning_rate": 0.000203064,
      "loss": 0.02,
      "step": 8080
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.11840350925922394,
      "learning_rate": 0.000202824,
      "loss": 0.0201,
      "step": 8100
    },
    {
      "epoch": 2.5984,
      "grad_norm": 0.22411251068115234,
      "learning_rate": 0.00020258399999999998,
      "loss": 0.022,
      "step": 8120
    },
    {
      "epoch": 2.6048,
      "grad_norm": 0.19107790291309357,
      "learning_rate": 0.00020234399999999997,
      "loss": 0.0204,
      "step": 8140
    },
    {
      "epoch": 2.6112,
      "grad_norm": 0.14673994481563568,
      "learning_rate": 0.00020210399999999996,
      "loss": 0.0205,
      "step": 8160
    },
    {
      "epoch": 2.6176,
      "grad_norm": 0.1570710688829422,
      "learning_rate": 0.000201864,
      "loss": 0.0199,
      "step": 8180
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.2100641429424286,
      "learning_rate": 0.000201624,
      "loss": 0.0209,
      "step": 8200
    },
    {
      "epoch": 2.6304,
      "grad_norm": 0.19430208206176758,
      "learning_rate": 0.00020138399999999998,
      "loss": 0.0201,
      "step": 8220
    },
    {
      "epoch": 2.6368,
      "grad_norm": 0.12445853650569916,
      "learning_rate": 0.00020114399999999997,
      "loss": 0.0201,
      "step": 8240
    },
    {
      "epoch": 2.6432,
      "grad_norm": 0.16907818615436554,
      "learning_rate": 0.00020090399999999999,
      "loss": 0.0204,
      "step": 8260
    },
    {
      "epoch": 2.6496,
      "grad_norm": 0.16061988472938538,
      "learning_rate": 0.000200664,
      "loss": 0.0205,
      "step": 8280
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.13974423706531525,
      "learning_rate": 0.000200424,
      "loss": 0.0198,
      "step": 8300
    },
    {
      "epoch": 2.6624,
      "grad_norm": 0.16068613529205322,
      "learning_rate": 0.00020018399999999998,
      "loss": 0.0197,
      "step": 8320
    },
    {
      "epoch": 2.6688,
      "grad_norm": 0.21050429344177246,
      "learning_rate": 0.00019994399999999997,
      "loss": 0.0197,
      "step": 8340
    },
    {
      "epoch": 2.6752000000000002,
      "grad_norm": 0.1625896841287613,
      "learning_rate": 0.00019970399999999998,
      "loss": 0.0196,
      "step": 8360
    },
    {
      "epoch": 2.6816,
      "grad_norm": 0.15395194292068481,
      "learning_rate": 0.000199464,
      "loss": 0.0192,
      "step": 8380
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.12606501579284668,
      "learning_rate": 0.000199224,
      "loss": 0.0196,
      "step": 8400
    },
    {
      "epoch": 2.6944,
      "grad_norm": 0.151327982544899,
      "learning_rate": 0.00019898399999999998,
      "loss": 0.0188,
      "step": 8420
    },
    {
      "epoch": 2.7008,
      "grad_norm": 0.1639212965965271,
      "learning_rate": 0.00019874399999999997,
      "loss": 0.0195,
      "step": 8440
    },
    {
      "epoch": 2.7072000000000003,
      "grad_norm": 0.15061047673225403,
      "learning_rate": 0.000198504,
      "loss": 0.0193,
      "step": 8460
    },
    {
      "epoch": 2.7136,
      "grad_norm": 0.18478739261627197,
      "learning_rate": 0.000198264,
      "loss": 0.019,
      "step": 8480
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.1752694994211197,
      "learning_rate": 0.000198024,
      "loss": 0.0194,
      "step": 8500
    },
    {
      "epoch": 2.7264,
      "grad_norm": 0.12120170891284943,
      "learning_rate": 0.00019778399999999998,
      "loss": 0.0196,
      "step": 8520
    },
    {
      "epoch": 2.7328,
      "grad_norm": 0.18180504441261292,
      "learning_rate": 0.00019754399999999996,
      "loss": 0.0194,
      "step": 8540
    },
    {
      "epoch": 2.7392,
      "grad_norm": 0.13631881773471832,
      "learning_rate": 0.000197304,
      "loss": 0.0198,
      "step": 8560
    },
    {
      "epoch": 2.7456,
      "grad_norm": 0.13595516979694366,
      "learning_rate": 0.000197064,
      "loss": 0.0197,
      "step": 8580
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.15329661965370178,
      "learning_rate": 0.00019682399999999998,
      "loss": 0.0193,
      "step": 8600
    },
    {
      "epoch": 2.7584,
      "grad_norm": 0.1763812005519867,
      "learning_rate": 0.00019658399999999997,
      "loss": 0.0196,
      "step": 8620
    },
    {
      "epoch": 2.7648,
      "grad_norm": 0.1813119798898697,
      "learning_rate": 0.00019634399999999996,
      "loss": 0.0195,
      "step": 8640
    },
    {
      "epoch": 2.7712,
      "grad_norm": 0.17228804528713226,
      "learning_rate": 0.000196104,
      "loss": 0.0192,
      "step": 8660
    },
    {
      "epoch": 2.7776,
      "grad_norm": 0.1695708930492401,
      "learning_rate": 0.000195864,
      "loss": 0.0184,
      "step": 8680
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.1677452176809311,
      "learning_rate": 0.00019562399999999998,
      "loss": 0.0188,
      "step": 8700
    },
    {
      "epoch": 2.7904,
      "grad_norm": 0.17890694737434387,
      "learning_rate": 0.00019538399999999997,
      "loss": 0.0187,
      "step": 8720
    },
    {
      "epoch": 2.7968,
      "grad_norm": 0.15151965618133545,
      "learning_rate": 0.00019514399999999996,
      "loss": 0.0196,
      "step": 8740
    },
    {
      "epoch": 2.8032,
      "grad_norm": 0.21616601943969727,
      "learning_rate": 0.000194904,
      "loss": 0.0182,
      "step": 8760
    },
    {
      "epoch": 2.8096,
      "grad_norm": 0.20131100714206696,
      "learning_rate": 0.000194664,
      "loss": 0.0201,
      "step": 8780
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.18920212984085083,
      "learning_rate": 0.00019442399999999998,
      "loss": 0.0193,
      "step": 8800
    },
    {
      "epoch": 2.8224,
      "grad_norm": 0.18519066274166107,
      "learning_rate": 0.00019418399999999997,
      "loss": 0.0192,
      "step": 8820
    },
    {
      "epoch": 2.8288,
      "grad_norm": 0.19804933667182922,
      "learning_rate": 0.000193944,
      "loss": 0.0196,
      "step": 8840
    },
    {
      "epoch": 2.8352,
      "grad_norm": 0.17921069264411926,
      "learning_rate": 0.000193704,
      "loss": 0.0188,
      "step": 8860
    },
    {
      "epoch": 2.8416,
      "grad_norm": 0.16389624774456024,
      "learning_rate": 0.000193464,
      "loss": 0.0185,
      "step": 8880
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.1668960452079773,
      "learning_rate": 0.00019322399999999998,
      "loss": 0.0186,
      "step": 8900
    },
    {
      "epoch": 2.8544,
      "grad_norm": 0.21256615221500397,
      "learning_rate": 0.00019298399999999997,
      "loss": 0.0195,
      "step": 8920
    },
    {
      "epoch": 2.8608000000000002,
      "grad_norm": 0.18799424171447754,
      "learning_rate": 0.000192744,
      "loss": 0.0186,
      "step": 8940
    },
    {
      "epoch": 2.8672,
      "grad_norm": 0.17147639393806458,
      "learning_rate": 0.000192504,
      "loss": 0.0201,
      "step": 8960
    },
    {
      "epoch": 2.8736,
      "grad_norm": 0.17964302003383636,
      "learning_rate": 0.000192264,
      "loss": 0.0194,
      "step": 8980
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.12799566984176636,
      "learning_rate": 0.00019202399999999998,
      "loss": 0.0181,
      "step": 9000
    },
    {
      "epoch": 2.8864,
      "grad_norm": 0.1286257952451706,
      "learning_rate": 0.00019178399999999996,
      "loss": 0.0186,
      "step": 9020
    },
    {
      "epoch": 2.8928000000000003,
      "grad_norm": 0.21480104327201843,
      "learning_rate": 0.000191544,
      "loss": 0.0185,
      "step": 9040
    },
    {
      "epoch": 2.8992,
      "grad_norm": 0.15263663232326508,
      "learning_rate": 0.000191304,
      "loss": 0.0186,
      "step": 9060
    },
    {
      "epoch": 2.9055999999999997,
      "grad_norm": 0.11955400556325912,
      "learning_rate": 0.00019106399999999999,
      "loss": 0.0176,
      "step": 9080
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.21739764511585236,
      "learning_rate": 0.00019082399999999997,
      "loss": 0.0187,
      "step": 9100
    },
    {
      "epoch": 2.9184,
      "grad_norm": 0.18624013662338257,
      "learning_rate": 0.00019058399999999996,
      "loss": 0.0182,
      "step": 9120
    },
    {
      "epoch": 2.9248,
      "grad_norm": 0.14738887548446655,
      "learning_rate": 0.000190344,
      "loss": 0.0186,
      "step": 9140
    },
    {
      "epoch": 2.9312,
      "grad_norm": 0.16375663876533508,
      "learning_rate": 0.000190104,
      "loss": 0.0186,
      "step": 9160
    },
    {
      "epoch": 2.9375999999999998,
      "grad_norm": 0.12255125492811203,
      "learning_rate": 0.00018986399999999998,
      "loss": 0.019,
      "step": 9180
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.18827570974826813,
      "learning_rate": 0.00018962399999999997,
      "loss": 0.0185,
      "step": 9200
    },
    {
      "epoch": 2.9504,
      "grad_norm": 0.17573434114456177,
      "learning_rate": 0.00018938399999999996,
      "loss": 0.0195,
      "step": 9220
    },
    {
      "epoch": 2.9568,
      "grad_norm": 0.18997201323509216,
      "learning_rate": 0.000189144,
      "loss": 0.0186,
      "step": 9240
    },
    {
      "epoch": 2.9632,
      "grad_norm": 0.21481332182884216,
      "learning_rate": 0.000188904,
      "loss": 0.0182,
      "step": 9260
    },
    {
      "epoch": 2.9696,
      "grad_norm": 0.21532991528511047,
      "learning_rate": 0.00018866399999999998,
      "loss": 0.0187,
      "step": 9280
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.16931582987308502,
      "learning_rate": 0.00018842399999999997,
      "loss": 0.0194,
      "step": 9300
    },
    {
      "epoch": 2.9824,
      "grad_norm": 0.1303490400314331,
      "learning_rate": 0.00018818399999999996,
      "loss": 0.018,
      "step": 9320
    },
    {
      "epoch": 2.9888,
      "grad_norm": 0.1810729056596756,
      "learning_rate": 0.000187944,
      "loss": 0.0183,
      "step": 9340
    },
    {
      "epoch": 2.9952,
      "grad_norm": 0.163855642080307,
      "learning_rate": 0.000187704,
      "loss": 0.0178,
      "step": 9360
    },
    {
      "epoch": 3.0016,
      "grad_norm": 0.20115727186203003,
      "learning_rate": 0.00018746399999999998,
      "loss": 0.019,
      "step": 9380
    },
    {
      "epoch": 3.008,
      "grad_norm": 0.14577940106391907,
      "learning_rate": 0.00018722399999999997,
      "loss": 0.0194,
      "step": 9400
    },
    {
      "epoch": 3.0144,
      "grad_norm": 0.20434977114200592,
      "learning_rate": 0.00018698399999999996,
      "loss": 0.0185,
      "step": 9420
    },
    {
      "epoch": 3.0208,
      "grad_norm": 0.17168596386909485,
      "learning_rate": 0.000186744,
      "loss": 0.0189,
      "step": 9440
    },
    {
      "epoch": 3.0272,
      "grad_norm": 0.18371674418449402,
      "learning_rate": 0.000186504,
      "loss": 0.0184,
      "step": 9460
    },
    {
      "epoch": 3.0336,
      "grad_norm": 0.20473264157772064,
      "learning_rate": 0.00018626399999999998,
      "loss": 0.0178,
      "step": 9480
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.12668876349925995,
      "learning_rate": 0.00018602399999999997,
      "loss": 0.0182,
      "step": 9500
    },
    {
      "epoch": 3.0464,
      "grad_norm": 0.15336483716964722,
      "learning_rate": 0.000185784,
      "loss": 0.0179,
      "step": 9520
    },
    {
      "epoch": 3.0528,
      "grad_norm": 0.20033611357212067,
      "learning_rate": 0.000185544,
      "loss": 0.0178,
      "step": 9540
    },
    {
      "epoch": 3.0592,
      "grad_norm": 0.14410245418548584,
      "learning_rate": 0.00018530399999999999,
      "loss": 0.0176,
      "step": 9560
    },
    {
      "epoch": 3.0656,
      "grad_norm": 0.2443322241306305,
      "learning_rate": 0.00018506399999999998,
      "loss": 0.0183,
      "step": 9580
    },
    {
      "epoch": 3.072,
      "grad_norm": 0.14947974681854248,
      "learning_rate": 0.00018482399999999996,
      "loss": 0.0175,
      "step": 9600
    },
    {
      "epoch": 3.0784,
      "grad_norm": 0.1883378028869629,
      "learning_rate": 0.000184584,
      "loss": 0.0171,
      "step": 9620
    },
    {
      "epoch": 3.0848,
      "grad_norm": 0.19644783437252045,
      "learning_rate": 0.000184344,
      "loss": 0.0185,
      "step": 9640
    },
    {
      "epoch": 3.0912,
      "grad_norm": 0.17121665179729462,
      "learning_rate": 0.00018410399999999998,
      "loss": 0.0188,
      "step": 9660
    },
    {
      "epoch": 3.0976,
      "grad_norm": 0.14285247027873993,
      "learning_rate": 0.00018386399999999997,
      "loss": 0.0171,
      "step": 9680
    },
    {
      "epoch": 3.104,
      "grad_norm": 0.2103291153907776,
      "learning_rate": 0.00018362399999999996,
      "loss": 0.0183,
      "step": 9700
    },
    {
      "epoch": 3.1104,
      "grad_norm": 0.23774844408035278,
      "learning_rate": 0.000183384,
      "loss": 0.0182,
      "step": 9720
    },
    {
      "epoch": 3.1168,
      "grad_norm": 0.177978977560997,
      "learning_rate": 0.000183144,
      "loss": 0.0187,
      "step": 9740
    },
    {
      "epoch": 3.1232,
      "grad_norm": 0.22584103047847748,
      "learning_rate": 0.00018290399999999998,
      "loss": 0.018,
      "step": 9760
    },
    {
      "epoch": 3.1296,
      "grad_norm": 0.200323686003685,
      "learning_rate": 0.00018266399999999997,
      "loss": 0.0182,
      "step": 9780
    },
    {
      "epoch": 3.136,
      "grad_norm": 0.17488057911396027,
      "learning_rate": 0.00018242399999999996,
      "loss": 0.0174,
      "step": 9800
    },
    {
      "epoch": 3.1424,
      "grad_norm": 0.20109187066555023,
      "learning_rate": 0.000182184,
      "loss": 0.018,
      "step": 9820
    },
    {
      "epoch": 3.1488,
      "grad_norm": 0.16253362596035004,
      "learning_rate": 0.000181944,
      "loss": 0.0179,
      "step": 9840
    },
    {
      "epoch": 3.1552,
      "grad_norm": 0.1897314339876175,
      "learning_rate": 0.00018170399999999998,
      "loss": 0.0183,
      "step": 9860
    },
    {
      "epoch": 3.1616,
      "grad_norm": 0.19950826466083527,
      "learning_rate": 0.00018146399999999997,
      "loss": 0.0179,
      "step": 9880
    },
    {
      "epoch": 3.168,
      "grad_norm": 0.17718681693077087,
      "learning_rate": 0.00018122399999999996,
      "loss": 0.0179,
      "step": 9900
    },
    {
      "epoch": 3.1744,
      "grad_norm": 0.2102949321269989,
      "learning_rate": 0.000180984,
      "loss": 0.018,
      "step": 9920
    },
    {
      "epoch": 3.1808,
      "grad_norm": 0.18050210177898407,
      "learning_rate": 0.000180744,
      "loss": 0.0173,
      "step": 9940
    },
    {
      "epoch": 3.1872,
      "grad_norm": 0.10638415068387985,
      "learning_rate": 0.00018050399999999998,
      "loss": 0.0177,
      "step": 9960
    },
    {
      "epoch": 3.1936,
      "grad_norm": 0.10960017889738083,
      "learning_rate": 0.00018026399999999997,
      "loss": 0.0177,
      "step": 9980
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.11716603487730026,
      "learning_rate": 0.00018002399999999996,
      "loss": 0.0173,
      "step": 10000
    },
    {
      "epoch": 3.2064,
      "grad_norm": 0.16898101568222046,
      "learning_rate": 0.000179784,
      "loss": 0.018,
      "step": 10020
    },
    {
      "epoch": 3.2128,
      "grad_norm": 0.26235368847846985,
      "learning_rate": 0.000179544,
      "loss": 0.0177,
      "step": 10040
    },
    {
      "epoch": 3.2192,
      "grad_norm": 0.16593505442142487,
      "learning_rate": 0.00017930399999999998,
      "loss": 0.0181,
      "step": 10060
    },
    {
      "epoch": 3.2256,
      "grad_norm": 0.1747344583272934,
      "learning_rate": 0.00017906399999999996,
      "loss": 0.0171,
      "step": 10080
    },
    {
      "epoch": 3.232,
      "grad_norm": 0.13431629538536072,
      "learning_rate": 0.000178824,
      "loss": 0.0183,
      "step": 10100
    },
    {
      "epoch": 3.2384,
      "grad_norm": 0.1686791628599167,
      "learning_rate": 0.000178584,
      "loss": 0.0173,
      "step": 10120
    },
    {
      "epoch": 3.2448,
      "grad_norm": 0.21121343970298767,
      "learning_rate": 0.00017834399999999999,
      "loss": 0.0171,
      "step": 10140
    },
    {
      "epoch": 3.2512,
      "grad_norm": 0.14455051720142365,
      "learning_rate": 0.00017810399999999997,
      "loss": 0.0185,
      "step": 10160
    },
    {
      "epoch": 3.2576,
      "grad_norm": 0.18524928390979767,
      "learning_rate": 0.00017786399999999996,
      "loss": 0.0177,
      "step": 10180
    },
    {
      "epoch": 3.2640000000000002,
      "grad_norm": 0.19071321189403534,
      "learning_rate": 0.000177624,
      "loss": 0.0179,
      "step": 10200
    },
    {
      "epoch": 3.2704,
      "grad_norm": 0.1593923568725586,
      "learning_rate": 0.000177384,
      "loss": 0.017,
      "step": 10220
    },
    {
      "epoch": 3.2768,
      "grad_norm": 0.12139275670051575,
      "learning_rate": 0.00017714399999999998,
      "loss": 0.017,
      "step": 10240
    },
    {
      "epoch": 3.2832,
      "grad_norm": 0.1861775517463684,
      "learning_rate": 0.00017690399999999997,
      "loss": 0.0176,
      "step": 10260
    },
    {
      "epoch": 3.2896,
      "grad_norm": 0.13750140368938446,
      "learning_rate": 0.00017666399999999996,
      "loss": 0.017,
      "step": 10280
    },
    {
      "epoch": 3.296,
      "grad_norm": 0.21658124029636383,
      "learning_rate": 0.000176424,
      "loss": 0.0175,
      "step": 10300
    },
    {
      "epoch": 3.3024,
      "grad_norm": 0.11956676095724106,
      "learning_rate": 0.000176184,
      "loss": 0.0167,
      "step": 10320
    },
    {
      "epoch": 3.3088,
      "grad_norm": 0.17225782573223114,
      "learning_rate": 0.00017594399999999998,
      "loss": 0.0183,
      "step": 10340
    },
    {
      "epoch": 3.3152,
      "grad_norm": 0.19738706946372986,
      "learning_rate": 0.00017570399999999997,
      "loss": 0.0171,
      "step": 10360
    },
    {
      "epoch": 3.3216,
      "grad_norm": 0.19793309271335602,
      "learning_rate": 0.00017546399999999996,
      "loss": 0.0174,
      "step": 10380
    },
    {
      "epoch": 3.328,
      "grad_norm": 0.1343274563550949,
      "learning_rate": 0.000175224,
      "loss": 0.0175,
      "step": 10400
    },
    {
      "epoch": 3.3344,
      "grad_norm": 0.15408480167388916,
      "learning_rate": 0.000174984,
      "loss": 0.0166,
      "step": 10420
    },
    {
      "epoch": 3.3407999999999998,
      "grad_norm": 0.22055718302726746,
      "learning_rate": 0.00017474399999999998,
      "loss": 0.017,
      "step": 10440
    },
    {
      "epoch": 3.3472,
      "grad_norm": 0.17522810399532318,
      "learning_rate": 0.00017450399999999997,
      "loss": 0.017,
      "step": 10460
    },
    {
      "epoch": 3.3536,
      "grad_norm": 0.126463383436203,
      "learning_rate": 0.00017426399999999998,
      "loss": 0.0165,
      "step": 10480
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.11790969967842102,
      "learning_rate": 0.000174024,
      "loss": 0.0179,
      "step": 10500
    },
    {
      "epoch": 3.3664,
      "grad_norm": 0.12529200315475464,
      "learning_rate": 0.000173784,
      "loss": 0.0182,
      "step": 10520
    },
    {
      "epoch": 3.3728,
      "grad_norm": 0.1775410920381546,
      "learning_rate": 0.00017354399999999998,
      "loss": 0.0169,
      "step": 10540
    },
    {
      "epoch": 3.3792,
      "grad_norm": 0.15535126626491547,
      "learning_rate": 0.00017330399999999997,
      "loss": 0.0179,
      "step": 10560
    },
    {
      "epoch": 3.3856,
      "grad_norm": 0.1852240264415741,
      "learning_rate": 0.00017306399999999998,
      "loss": 0.0178,
      "step": 10580
    },
    {
      "epoch": 3.392,
      "grad_norm": 0.15123748779296875,
      "learning_rate": 0.000172824,
      "loss": 0.0164,
      "step": 10600
    },
    {
      "epoch": 3.3984,
      "grad_norm": 0.1472911685705185,
      "learning_rate": 0.00017258399999999999,
      "loss": 0.017,
      "step": 10620
    },
    {
      "epoch": 3.4048,
      "grad_norm": 0.18881310522556305,
      "learning_rate": 0.00017234399999999997,
      "loss": 0.0173,
      "step": 10640
    },
    {
      "epoch": 3.4112,
      "grad_norm": 0.15359172224998474,
      "learning_rate": 0.00017210399999999996,
      "loss": 0.017,
      "step": 10660
    },
    {
      "epoch": 3.4176,
      "grad_norm": 0.1392323225736618,
      "learning_rate": 0.00017186399999999998,
      "loss": 0.0168,
      "step": 10680
    },
    {
      "epoch": 3.424,
      "grad_norm": 0.18703222274780273,
      "learning_rate": 0.000171624,
      "loss": 0.0178,
      "step": 10700
    },
    {
      "epoch": 3.4304,
      "grad_norm": 0.1324826180934906,
      "learning_rate": 0.00017138399999999998,
      "loss": 0.0166,
      "step": 10720
    },
    {
      "epoch": 3.4368,
      "grad_norm": 0.17394278943538666,
      "learning_rate": 0.00017114399999999997,
      "loss": 0.0174,
      "step": 10740
    },
    {
      "epoch": 3.4432,
      "grad_norm": 0.1353045105934143,
      "learning_rate": 0.00017090399999999996,
      "loss": 0.0166,
      "step": 10760
    },
    {
      "epoch": 3.4496,
      "grad_norm": 0.12944000959396362,
      "learning_rate": 0.000170664,
      "loss": 0.0165,
      "step": 10780
    },
    {
      "epoch": 3.456,
      "grad_norm": 0.15316443145275116,
      "learning_rate": 0.000170424,
      "loss": 0.0173,
      "step": 10800
    },
    {
      "epoch": 3.4624,
      "grad_norm": 0.16249705851078033,
      "learning_rate": 0.00017018399999999998,
      "loss": 0.0166,
      "step": 10820
    },
    {
      "epoch": 3.4688,
      "grad_norm": 0.11549405753612518,
      "learning_rate": 0.00016994399999999997,
      "loss": 0.017,
      "step": 10840
    },
    {
      "epoch": 3.4752,
      "grad_norm": 0.1469351351261139,
      "learning_rate": 0.000169704,
      "loss": 0.0175,
      "step": 10860
    },
    {
      "epoch": 3.4816,
      "grad_norm": 0.1659346967935562,
      "learning_rate": 0.000169464,
      "loss": 0.0174,
      "step": 10880
    },
    {
      "epoch": 3.488,
      "grad_norm": 0.1360425055027008,
      "learning_rate": 0.000169224,
      "loss": 0.017,
      "step": 10900
    },
    {
      "epoch": 3.4944,
      "grad_norm": 0.19800128042697906,
      "learning_rate": 0.00016898399999999998,
      "loss": 0.0173,
      "step": 10920
    },
    {
      "epoch": 3.5008,
      "grad_norm": 0.17393477261066437,
      "learning_rate": 0.00016874399999999997,
      "loss": 0.0165,
      "step": 10940
    },
    {
      "epoch": 3.5072,
      "grad_norm": 0.16324634850025177,
      "learning_rate": 0.00016850399999999998,
      "loss": 0.0167,
      "step": 10960
    },
    {
      "epoch": 3.5136,
      "grad_norm": 0.1427316814661026,
      "learning_rate": 0.000168264,
      "loss": 0.0174,
      "step": 10980
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.12729565799236298,
      "learning_rate": 0.000168024,
      "loss": 0.0168,
      "step": 11000
    },
    {
      "epoch": 3.5263999999999998,
      "grad_norm": 0.15704257786273956,
      "learning_rate": 0.00016778399999999998,
      "loss": 0.0168,
      "step": 11020
    },
    {
      "epoch": 3.5328,
      "grad_norm": 0.1324521005153656,
      "learning_rate": 0.00016754399999999997,
      "loss": 0.0162,
      "step": 11040
    },
    {
      "epoch": 3.5392,
      "grad_norm": 0.1839308738708496,
      "learning_rate": 0.00016730399999999998,
      "loss": 0.0167,
      "step": 11060
    },
    {
      "epoch": 3.5456,
      "grad_norm": 0.2028232216835022,
      "learning_rate": 0.000167064,
      "loss": 0.0173,
      "step": 11080
    },
    {
      "epoch": 3.552,
      "grad_norm": 0.13791202008724213,
      "learning_rate": 0.000166824,
      "loss": 0.017,
      "step": 11100
    },
    {
      "epoch": 3.5584,
      "grad_norm": 0.15610502660274506,
      "learning_rate": 0.00016658399999999998,
      "loss": 0.017,
      "step": 11120
    },
    {
      "epoch": 3.5648,
      "grad_norm": 0.12803585827350616,
      "learning_rate": 0.00016634399999999996,
      "loss": 0.0174,
      "step": 11140
    },
    {
      "epoch": 3.5712,
      "grad_norm": 0.13232338428497314,
      "learning_rate": 0.00016610399999999998,
      "loss": 0.0166,
      "step": 11160
    },
    {
      "epoch": 3.5776,
      "grad_norm": 0.15743669867515564,
      "learning_rate": 0.000165864,
      "loss": 0.0168,
      "step": 11180
    },
    {
      "epoch": 3.584,
      "grad_norm": 0.13824979960918427,
      "learning_rate": 0.00016562399999999998,
      "loss": 0.0164,
      "step": 11200
    },
    {
      "epoch": 3.5904,
      "grad_norm": 0.1211475357413292,
      "learning_rate": 0.00016538399999999997,
      "loss": 0.0163,
      "step": 11220
    },
    {
      "epoch": 3.5968,
      "grad_norm": 0.18735693395137787,
      "learning_rate": 0.000165144,
      "loss": 0.0167,
      "step": 11240
    },
    {
      "epoch": 3.6032,
      "grad_norm": 0.1943133920431137,
      "learning_rate": 0.00016490399999999998,
      "loss": 0.0167,
      "step": 11260
    },
    {
      "epoch": 3.6096,
      "grad_norm": 0.15492163598537445,
      "learning_rate": 0.000164664,
      "loss": 0.0165,
      "step": 11280
    },
    {
      "epoch": 3.616,
      "grad_norm": 0.1640457808971405,
      "learning_rate": 0.00016442399999999998,
      "loss": 0.0161,
      "step": 11300
    },
    {
      "epoch": 3.6224,
      "grad_norm": 0.1730853021144867,
      "learning_rate": 0.00016418399999999997,
      "loss": 0.0166,
      "step": 11320
    },
    {
      "epoch": 3.6288,
      "grad_norm": 0.1436018943786621,
      "learning_rate": 0.000163944,
      "loss": 0.0159,
      "step": 11340
    },
    {
      "epoch": 3.6352,
      "grad_norm": 0.17252086102962494,
      "learning_rate": 0.000163704,
      "loss": 0.017,
      "step": 11360
    },
    {
      "epoch": 3.6416,
      "grad_norm": 0.15699104964733124,
      "learning_rate": 0.000163464,
      "loss": 0.017,
      "step": 11380
    },
    {
      "epoch": 3.648,
      "grad_norm": 0.1430090367794037,
      "learning_rate": 0.00016322399999999998,
      "loss": 0.0161,
      "step": 11400
    },
    {
      "epoch": 3.6544,
      "grad_norm": 0.12015420943498611,
      "learning_rate": 0.00016298399999999997,
      "loss": 0.0158,
      "step": 11420
    },
    {
      "epoch": 3.6608,
      "grad_norm": 0.18337541818618774,
      "learning_rate": 0.00016274399999999999,
      "loss": 0.0168,
      "step": 11440
    },
    {
      "epoch": 3.6672000000000002,
      "grad_norm": 0.1325007528066635,
      "learning_rate": 0.000162504,
      "loss": 0.0164,
      "step": 11460
    },
    {
      "epoch": 3.6736,
      "grad_norm": 0.16910779476165771,
      "learning_rate": 0.000162264,
      "loss": 0.0167,
      "step": 11480
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.16601061820983887,
      "learning_rate": 0.00016202399999999998,
      "loss": 0.0163,
      "step": 11500
    },
    {
      "epoch": 3.6864,
      "grad_norm": 0.14628517627716064,
      "learning_rate": 0.00016178399999999997,
      "loss": 0.0154,
      "step": 11520
    },
    {
      "epoch": 3.6928,
      "grad_norm": 0.1560414880514145,
      "learning_rate": 0.00016154399999999998,
      "loss": 0.0162,
      "step": 11540
    },
    {
      "epoch": 3.6992000000000003,
      "grad_norm": 0.16266225278377533,
      "learning_rate": 0.000161304,
      "loss": 0.0161,
      "step": 11560
    },
    {
      "epoch": 3.7056,
      "grad_norm": 0.14873093366622925,
      "learning_rate": 0.000161064,
      "loss": 0.0167,
      "step": 11580
    },
    {
      "epoch": 3.7119999999999997,
      "grad_norm": 0.1517292857170105,
      "learning_rate": 0.00016082399999999998,
      "loss": 0.0162,
      "step": 11600
    },
    {
      "epoch": 3.7184,
      "grad_norm": 0.14017921686172485,
      "learning_rate": 0.000160584,
      "loss": 0.0164,
      "step": 11620
    },
    {
      "epoch": 3.7248,
      "grad_norm": 0.1484096795320511,
      "learning_rate": 0.00016034399999999998,
      "loss": 0.0164,
      "step": 11640
    },
    {
      "epoch": 3.7312,
      "grad_norm": 0.13670766353607178,
      "learning_rate": 0.000160104,
      "loss": 0.0165,
      "step": 11660
    },
    {
      "epoch": 3.7376,
      "grad_norm": 0.13670021295547485,
      "learning_rate": 0.00015986399999999999,
      "loss": 0.0166,
      "step": 11680
    },
    {
      "epoch": 3.7439999999999998,
      "grad_norm": 0.11571638286113739,
      "learning_rate": 0.00015962399999999997,
      "loss": 0.0163,
      "step": 11700
    },
    {
      "epoch": 3.7504,
      "grad_norm": 0.21226991713047028,
      "learning_rate": 0.000159384,
      "loss": 0.0159,
      "step": 11720
    },
    {
      "epoch": 3.7568,
      "grad_norm": 0.17578856647014618,
      "learning_rate": 0.00015914399999999998,
      "loss": 0.0166,
      "step": 11740
    },
    {
      "epoch": 3.7632,
      "grad_norm": 0.12280674278736115,
      "learning_rate": 0.000158904,
      "loss": 0.0168,
      "step": 11760
    },
    {
      "epoch": 3.7696,
      "grad_norm": 0.1474521905183792,
      "learning_rate": 0.00015866399999999998,
      "loss": 0.0164,
      "step": 11780
    },
    {
      "epoch": 3.776,
      "grad_norm": 0.11220785975456238,
      "learning_rate": 0.00015842399999999997,
      "loss": 0.0165,
      "step": 11800
    },
    {
      "epoch": 3.7824,
      "grad_norm": 0.12289733439683914,
      "learning_rate": 0.000158184,
      "loss": 0.0157,
      "step": 11820
    },
    {
      "epoch": 3.7888,
      "grad_norm": 0.10424670577049255,
      "learning_rate": 0.00015794399999999998,
      "loss": 0.0158,
      "step": 11840
    },
    {
      "epoch": 3.7952,
      "grad_norm": 0.11685308814048767,
      "learning_rate": 0.000157704,
      "loss": 0.0162,
      "step": 11860
    },
    {
      "epoch": 3.8016,
      "grad_norm": 0.09740667045116425,
      "learning_rate": 0.00015746399999999998,
      "loss": 0.0169,
      "step": 11880
    },
    {
      "epoch": 3.808,
      "grad_norm": 0.13990719616413116,
      "learning_rate": 0.00015722399999999997,
      "loss": 0.0162,
      "step": 11900
    },
    {
      "epoch": 3.8144,
      "grad_norm": 0.25254690647125244,
      "learning_rate": 0.00015698399999999999,
      "loss": 0.016,
      "step": 11920
    },
    {
      "epoch": 3.8208,
      "grad_norm": 0.1708296835422516,
      "learning_rate": 0.000156744,
      "loss": 0.0159,
      "step": 11940
    },
    {
      "epoch": 3.8272,
      "grad_norm": 0.13468796014785767,
      "learning_rate": 0.000156504,
      "loss": 0.0158,
      "step": 11960
    },
    {
      "epoch": 3.8336,
      "grad_norm": 0.11833629012107849,
      "learning_rate": 0.00015626399999999998,
      "loss": 0.0169,
      "step": 11980
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.14874839782714844,
      "learning_rate": 0.000156024,
      "loss": 0.0166,
      "step": 12000
    },
    {
      "epoch": 3.8464,
      "grad_norm": 0.1790212243795395,
      "learning_rate": 0.00015578399999999998,
      "loss": 0.0167,
      "step": 12020
    },
    {
      "epoch": 3.8528000000000002,
      "grad_norm": 0.16106325387954712,
      "learning_rate": 0.000155544,
      "loss": 0.0161,
      "step": 12040
    },
    {
      "epoch": 3.8592,
      "grad_norm": 0.11541952937841415,
      "learning_rate": 0.000155304,
      "loss": 0.017,
      "step": 12060
    },
    {
      "epoch": 3.8656,
      "grad_norm": 0.20791903138160706,
      "learning_rate": 0.00015506399999999998,
      "loss": 0.0161,
      "step": 12080
    },
    {
      "epoch": 3.872,
      "grad_norm": 0.07938449829816818,
      "learning_rate": 0.000154824,
      "loss": 0.0161,
      "step": 12100
    },
    {
      "epoch": 3.8784,
      "grad_norm": 0.14565715193748474,
      "learning_rate": 0.00015458399999999998,
      "loss": 0.0152,
      "step": 12120
    },
    {
      "epoch": 3.8848000000000003,
      "grad_norm": 0.15989060699939728,
      "learning_rate": 0.000154344,
      "loss": 0.0161,
      "step": 12140
    },
    {
      "epoch": 3.8912,
      "grad_norm": 0.14131098985671997,
      "learning_rate": 0.000154104,
      "loss": 0.0167,
      "step": 12160
    },
    {
      "epoch": 3.8975999999999997,
      "grad_norm": 0.17331433296203613,
      "learning_rate": 0.00015386399999999998,
      "loss": 0.0162,
      "step": 12180
    },
    {
      "epoch": 3.904,
      "grad_norm": 0.18367941677570343,
      "learning_rate": 0.000153624,
      "loss": 0.0168,
      "step": 12200
    },
    {
      "epoch": 3.9104,
      "grad_norm": 0.10192111879587173,
      "learning_rate": 0.00015338399999999998,
      "loss": 0.0166,
      "step": 12220
    },
    {
      "epoch": 3.9168,
      "grad_norm": 0.17027990520000458,
      "learning_rate": 0.000153144,
      "loss": 0.0158,
      "step": 12240
    },
    {
      "epoch": 3.9232,
      "grad_norm": 0.21797186136245728,
      "learning_rate": 0.00015290399999999998,
      "loss": 0.0159,
      "step": 12260
    },
    {
      "epoch": 3.9295999999999998,
      "grad_norm": 0.1275303214788437,
      "learning_rate": 0.00015266399999999997,
      "loss": 0.0156,
      "step": 12280
    },
    {
      "epoch": 3.936,
      "grad_norm": 0.2019839882850647,
      "learning_rate": 0.000152424,
      "loss": 0.0158,
      "step": 12300
    },
    {
      "epoch": 3.9424,
      "grad_norm": 0.09168657660484314,
      "learning_rate": 0.00015218399999999998,
      "loss": 0.0162,
      "step": 12320
    },
    {
      "epoch": 3.9488,
      "grad_norm": 0.12367616593837738,
      "learning_rate": 0.000151944,
      "loss": 0.0164,
      "step": 12340
    },
    {
      "epoch": 3.9552,
      "grad_norm": 0.1345946043729782,
      "learning_rate": 0.00015170399999999998,
      "loss": 0.0153,
      "step": 12360
    },
    {
      "epoch": 3.9616,
      "grad_norm": 0.18745431303977966,
      "learning_rate": 0.000151464,
      "loss": 0.0164,
      "step": 12380
    },
    {
      "epoch": 3.968,
      "grad_norm": 0.1412905901670456,
      "learning_rate": 0.000151224,
      "loss": 0.0155,
      "step": 12400
    },
    {
      "epoch": 3.9744,
      "grad_norm": 0.12346842139959335,
      "learning_rate": 0.00015098399999999998,
      "loss": 0.0154,
      "step": 12420
    },
    {
      "epoch": 3.9808,
      "grad_norm": 0.13611635565757751,
      "learning_rate": 0.000150744,
      "loss": 0.0151,
      "step": 12440
    },
    {
      "epoch": 3.9872,
      "grad_norm": 0.14013253152370453,
      "learning_rate": 0.00015050399999999998,
      "loss": 0.0162,
      "step": 12460
    },
    {
      "epoch": 3.9936,
      "grad_norm": 0.12606744468212128,
      "learning_rate": 0.000150264,
      "loss": 0.0165,
      "step": 12480
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.11947334557771683,
      "learning_rate": 0.00015002399999999999,
      "loss": 0.0151,
      "step": 12500
    },
    {
      "epoch": 4.0064,
      "grad_norm": 0.1159047782421112,
      "learning_rate": 0.00014978399999999997,
      "loss": 0.0158,
      "step": 12520
    },
    {
      "epoch": 4.0128,
      "grad_norm": 0.15238319337368011,
      "learning_rate": 0.000149544,
      "loss": 0.0163,
      "step": 12540
    },
    {
      "epoch": 4.0192,
      "grad_norm": 0.1737363636493683,
      "learning_rate": 0.00014930399999999998,
      "loss": 0.0154,
      "step": 12560
    },
    {
      "epoch": 4.0256,
      "grad_norm": 0.147875115275383,
      "learning_rate": 0.000149064,
      "loss": 0.0153,
      "step": 12580
    },
    {
      "epoch": 4.032,
      "grad_norm": 0.10183556377887726,
      "learning_rate": 0.00014882399999999998,
      "loss": 0.0161,
      "step": 12600
    },
    {
      "epoch": 4.0384,
      "grad_norm": 0.16569389402866364,
      "learning_rate": 0.000148584,
      "loss": 0.0157,
      "step": 12620
    },
    {
      "epoch": 4.0448,
      "grad_norm": 0.11506570875644684,
      "learning_rate": 0.000148344,
      "loss": 0.0157,
      "step": 12640
    },
    {
      "epoch": 4.0512,
      "grad_norm": 0.1806686818599701,
      "learning_rate": 0.00014810399999999998,
      "loss": 0.0161,
      "step": 12660
    },
    {
      "epoch": 4.0576,
      "grad_norm": 0.1547369509935379,
      "learning_rate": 0.000147864,
      "loss": 0.0156,
      "step": 12680
    },
    {
      "epoch": 4.064,
      "grad_norm": 0.16236612200737,
      "learning_rate": 0.00014762399999999998,
      "loss": 0.0164,
      "step": 12700
    },
    {
      "epoch": 4.0704,
      "grad_norm": 0.10381191968917847,
      "learning_rate": 0.000147384,
      "loss": 0.0155,
      "step": 12720
    },
    {
      "epoch": 4.0768,
      "grad_norm": 0.1414351612329483,
      "learning_rate": 0.00014714399999999999,
      "loss": 0.016,
      "step": 12740
    },
    {
      "epoch": 4.0832,
      "grad_norm": 0.1541648805141449,
      "learning_rate": 0.000146904,
      "loss": 0.0163,
      "step": 12760
    },
    {
      "epoch": 4.0896,
      "grad_norm": 0.10533612221479416,
      "learning_rate": 0.000146664,
      "loss": 0.0158,
      "step": 12780
    },
    {
      "epoch": 4.096,
      "grad_norm": 0.16952714323997498,
      "learning_rate": 0.00014642399999999998,
      "loss": 0.0155,
      "step": 12800
    },
    {
      "epoch": 4.1024,
      "grad_norm": 0.15183651447296143,
      "learning_rate": 0.000146184,
      "loss": 0.0162,
      "step": 12820
    },
    {
      "epoch": 4.1088,
      "grad_norm": 0.18267154693603516,
      "learning_rate": 0.00014594399999999998,
      "loss": 0.0156,
      "step": 12840
    },
    {
      "epoch": 4.1152,
      "grad_norm": 0.17627094686031342,
      "learning_rate": 0.000145704,
      "loss": 0.0151,
      "step": 12860
    },
    {
      "epoch": 4.1216,
      "grad_norm": 0.15547281503677368,
      "learning_rate": 0.000145464,
      "loss": 0.0161,
      "step": 12880
    },
    {
      "epoch": 4.128,
      "grad_norm": 0.19844070076942444,
      "learning_rate": 0.00014522399999999998,
      "loss": 0.0167,
      "step": 12900
    },
    {
      "epoch": 4.1344,
      "grad_norm": 0.11409889906644821,
      "learning_rate": 0.000144984,
      "loss": 0.0149,
      "step": 12920
    },
    {
      "epoch": 4.1408,
      "grad_norm": 0.13268601894378662,
      "learning_rate": 0.00014474399999999998,
      "loss": 0.0159,
      "step": 12940
    },
    {
      "epoch": 4.1472,
      "grad_norm": 0.15300291776657104,
      "learning_rate": 0.000144504,
      "loss": 0.0151,
      "step": 12960
    },
    {
      "epoch": 4.1536,
      "grad_norm": 0.12958194315433502,
      "learning_rate": 0.00014426399999999999,
      "loss": 0.0153,
      "step": 12980
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.15831594169139862,
      "learning_rate": 0.000144024,
      "loss": 0.0163,
      "step": 13000
    },
    {
      "epoch": 4.1664,
      "grad_norm": 0.1359211504459381,
      "learning_rate": 0.000143784,
      "loss": 0.0164,
      "step": 13020
    },
    {
      "epoch": 4.1728,
      "grad_norm": 0.10524240881204605,
      "learning_rate": 0.00014354399999999998,
      "loss": 0.0156,
      "step": 13040
    },
    {
      "epoch": 4.1792,
      "grad_norm": 0.15913283824920654,
      "learning_rate": 0.000143304,
      "loss": 0.0164,
      "step": 13060
    },
    {
      "epoch": 4.1856,
      "grad_norm": 0.16715581715106964,
      "learning_rate": 0.00014306399999999998,
      "loss": 0.0159,
      "step": 13080
    },
    {
      "epoch": 4.192,
      "grad_norm": 0.14516638219356537,
      "learning_rate": 0.000142824,
      "loss": 0.0154,
      "step": 13100
    },
    {
      "epoch": 4.1984,
      "grad_norm": 0.14890527725219727,
      "learning_rate": 0.000142584,
      "loss": 0.0162,
      "step": 13120
    },
    {
      "epoch": 4.2048,
      "grad_norm": 0.18605713546276093,
      "learning_rate": 0.000142344,
      "loss": 0.015,
      "step": 13140
    },
    {
      "epoch": 4.2112,
      "grad_norm": 0.13374164700508118,
      "learning_rate": 0.000142104,
      "loss": 0.0157,
      "step": 13160
    },
    {
      "epoch": 4.2176,
      "grad_norm": 0.17003919184207916,
      "learning_rate": 0.00014186399999999998,
      "loss": 0.0157,
      "step": 13180
    },
    {
      "epoch": 4.224,
      "grad_norm": 0.14791128039360046,
      "learning_rate": 0.000141624,
      "loss": 0.0159,
      "step": 13200
    },
    {
      "epoch": 4.2304,
      "grad_norm": 0.18803058564662933,
      "learning_rate": 0.000141384,
      "loss": 0.015,
      "step": 13220
    },
    {
      "epoch": 4.2368,
      "grad_norm": 0.15921829640865326,
      "learning_rate": 0.000141144,
      "loss": 0.0157,
      "step": 13240
    },
    {
      "epoch": 4.2432,
      "grad_norm": 0.1048293486237526,
      "learning_rate": 0.000140904,
      "loss": 0.0156,
      "step": 13260
    },
    {
      "epoch": 4.2496,
      "grad_norm": 0.13698746263980865,
      "learning_rate": 0.00014066399999999998,
      "loss": 0.0155,
      "step": 13280
    },
    {
      "epoch": 4.256,
      "grad_norm": 0.2675475478172302,
      "learning_rate": 0.000140424,
      "loss": 0.0156,
      "step": 13300
    },
    {
      "epoch": 4.2624,
      "grad_norm": 0.18285445868968964,
      "learning_rate": 0.00014018399999999998,
      "loss": 0.0153,
      "step": 13320
    },
    {
      "epoch": 4.2688,
      "grad_norm": 0.10990478843450546,
      "learning_rate": 0.000139944,
      "loss": 0.015,
      "step": 13340
    },
    {
      "epoch": 4.2752,
      "grad_norm": 0.1409095674753189,
      "learning_rate": 0.000139704,
      "loss": 0.0154,
      "step": 13360
    },
    {
      "epoch": 4.2816,
      "grad_norm": 0.14709629118442535,
      "learning_rate": 0.000139464,
      "loss": 0.0161,
      "step": 13380
    },
    {
      "epoch": 4.288,
      "grad_norm": 0.107537642121315,
      "learning_rate": 0.000139224,
      "loss": 0.0156,
      "step": 13400
    },
    {
      "epoch": 4.2943999999999996,
      "grad_norm": 0.14599867165088654,
      "learning_rate": 0.00013898399999999998,
      "loss": 0.0158,
      "step": 13420
    },
    {
      "epoch": 4.3008,
      "grad_norm": 0.15712711215019226,
      "learning_rate": 0.000138744,
      "loss": 0.015,
      "step": 13440
    },
    {
      "epoch": 4.3072,
      "grad_norm": 0.1555936634540558,
      "learning_rate": 0.000138504,
      "loss": 0.0157,
      "step": 13460
    },
    {
      "epoch": 4.3136,
      "grad_norm": 0.1342683583498001,
      "learning_rate": 0.000138264,
      "loss": 0.0159,
      "step": 13480
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.16117705404758453,
      "learning_rate": 0.000138024,
      "loss": 0.0158,
      "step": 13500
    },
    {
      "epoch": 4.3264,
      "grad_norm": 0.13104785978794098,
      "learning_rate": 0.000137784,
      "loss": 0.0155,
      "step": 13520
    },
    {
      "epoch": 4.3328,
      "grad_norm": 0.08442829549312592,
      "learning_rate": 0.000137544,
      "loss": 0.0165,
      "step": 13540
    },
    {
      "epoch": 4.3392,
      "grad_norm": 0.17221038043498993,
      "learning_rate": 0.00013730399999999999,
      "loss": 0.0154,
      "step": 13560
    },
    {
      "epoch": 4.3456,
      "grad_norm": 0.11990721523761749,
      "learning_rate": 0.000137064,
      "loss": 0.0158,
      "step": 13580
    },
    {
      "epoch": 4.352,
      "grad_norm": 0.13245779275894165,
      "learning_rate": 0.000136824,
      "loss": 0.0159,
      "step": 13600
    },
    {
      "epoch": 4.3584,
      "grad_norm": 0.12633994221687317,
      "learning_rate": 0.000136584,
      "loss": 0.0155,
      "step": 13620
    },
    {
      "epoch": 4.3648,
      "grad_norm": 0.12137547135353088,
      "learning_rate": 0.000136344,
      "loss": 0.0151,
      "step": 13640
    },
    {
      "epoch": 4.3712,
      "grad_norm": 0.1723645031452179,
      "learning_rate": 0.00013610399999999998,
      "loss": 0.0152,
      "step": 13660
    },
    {
      "epoch": 4.3776,
      "grad_norm": 0.1743028163909912,
      "learning_rate": 0.000135864,
      "loss": 0.0153,
      "step": 13680
    },
    {
      "epoch": 4.384,
      "grad_norm": 0.2060813307762146,
      "learning_rate": 0.000135624,
      "loss": 0.0155,
      "step": 13700
    },
    {
      "epoch": 4.3904,
      "grad_norm": 0.18417151272296906,
      "learning_rate": 0.000135384,
      "loss": 0.0159,
      "step": 13720
    },
    {
      "epoch": 4.3968,
      "grad_norm": 0.173112154006958,
      "learning_rate": 0.000135144,
      "loss": 0.0155,
      "step": 13740
    },
    {
      "epoch": 4.4032,
      "grad_norm": 0.13410349190235138,
      "learning_rate": 0.000134904,
      "loss": 0.0155,
      "step": 13760
    },
    {
      "epoch": 4.4096,
      "grad_norm": 0.136113703250885,
      "learning_rate": 0.000134664,
      "loss": 0.0154,
      "step": 13780
    },
    {
      "epoch": 4.416,
      "grad_norm": 0.1592625081539154,
      "learning_rate": 0.00013442399999999999,
      "loss": 0.0156,
      "step": 13800
    },
    {
      "epoch": 4.4224,
      "grad_norm": 0.1880747228860855,
      "learning_rate": 0.000134184,
      "loss": 0.016,
      "step": 13820
    },
    {
      "epoch": 4.4288,
      "grad_norm": 0.09317972511053085,
      "learning_rate": 0.000133944,
      "loss": 0.0151,
      "step": 13840
    },
    {
      "epoch": 4.4352,
      "grad_norm": 0.1047978550195694,
      "learning_rate": 0.000133704,
      "loss": 0.0152,
      "step": 13860
    },
    {
      "epoch": 4.4416,
      "grad_norm": 0.216812402009964,
      "learning_rate": 0.000133464,
      "loss": 0.0146,
      "step": 13880
    },
    {
      "epoch": 4.448,
      "grad_norm": 0.13266192376613617,
      "learning_rate": 0.00013322399999999998,
      "loss": 0.0154,
      "step": 13900
    },
    {
      "epoch": 4.4544,
      "grad_norm": 0.10126237571239471,
      "learning_rate": 0.000132984,
      "loss": 0.0153,
      "step": 13920
    },
    {
      "epoch": 4.4608,
      "grad_norm": 0.14059917628765106,
      "learning_rate": 0.000132744,
      "loss": 0.0145,
      "step": 13940
    },
    {
      "epoch": 4.4672,
      "grad_norm": 0.138133242726326,
      "learning_rate": 0.000132504,
      "loss": 0.015,
      "step": 13960
    },
    {
      "epoch": 4.4736,
      "grad_norm": 0.0943160429596901,
      "learning_rate": 0.000132264,
      "loss": 0.0157,
      "step": 13980
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.12268750369548798,
      "learning_rate": 0.000132024,
      "loss": 0.0153,
      "step": 14000
    },
    {
      "epoch": 4.4864,
      "grad_norm": 0.09113284200429916,
      "learning_rate": 0.000131784,
      "loss": 0.0151,
      "step": 14020
    },
    {
      "epoch": 4.4928,
      "grad_norm": 0.13238148391246796,
      "learning_rate": 0.00013155599999999999,
      "loss": 0.0149,
      "step": 14040
    },
    {
      "epoch": 4.4992,
      "grad_norm": 0.17732420563697815,
      "learning_rate": 0.000131316,
      "loss": 0.0149,
      "step": 14060
    },
    {
      "epoch": 4.5056,
      "grad_norm": 0.13330502808094025,
      "learning_rate": 0.000131076,
      "loss": 0.0151,
      "step": 14080
    },
    {
      "epoch": 4.5120000000000005,
      "grad_norm": 0.15587329864501953,
      "learning_rate": 0.00013083599999999998,
      "loss": 0.0148,
      "step": 14100
    },
    {
      "epoch": 4.5184,
      "grad_norm": 0.08653812110424042,
      "learning_rate": 0.000130596,
      "loss": 0.0145,
      "step": 14120
    },
    {
      "epoch": 4.5248,
      "grad_norm": 0.0870891883969307,
      "learning_rate": 0.00013035599999999998,
      "loss": 0.0159,
      "step": 14140
    },
    {
      "epoch": 4.5312,
      "grad_norm": 0.15184153616428375,
      "learning_rate": 0.000130116,
      "loss": 0.0154,
      "step": 14160
    },
    {
      "epoch": 4.5376,
      "grad_norm": 0.13730482757091522,
      "learning_rate": 0.000129876,
      "loss": 0.0156,
      "step": 14180
    },
    {
      "epoch": 4.5440000000000005,
      "grad_norm": 0.07690159976482391,
      "learning_rate": 0.00012963599999999998,
      "loss": 0.0152,
      "step": 14200
    },
    {
      "epoch": 4.5504,
      "grad_norm": 0.11444249749183655,
      "learning_rate": 0.000129396,
      "loss": 0.0149,
      "step": 14220
    },
    {
      "epoch": 4.5568,
      "grad_norm": 0.10964212566614151,
      "learning_rate": 0.00012915599999999998,
      "loss": 0.0151,
      "step": 14240
    },
    {
      "epoch": 4.5632,
      "grad_norm": 0.11532165855169296,
      "learning_rate": 0.000128916,
      "loss": 0.0147,
      "step": 14260
    },
    {
      "epoch": 4.5696,
      "grad_norm": 0.14359505474567413,
      "learning_rate": 0.00012867599999999999,
      "loss": 0.0154,
      "step": 14280
    },
    {
      "epoch": 4.576,
      "grad_norm": 0.1469782590866089,
      "learning_rate": 0.000128436,
      "loss": 0.0159,
      "step": 14300
    },
    {
      "epoch": 4.5824,
      "grad_norm": 0.1157170757651329,
      "learning_rate": 0.000128196,
      "loss": 0.0146,
      "step": 14320
    },
    {
      "epoch": 4.5888,
      "grad_norm": 0.11191117763519287,
      "learning_rate": 0.00012795599999999998,
      "loss": 0.0151,
      "step": 14340
    },
    {
      "epoch": 4.5952,
      "grad_norm": 0.1689593493938446,
      "learning_rate": 0.000127716,
      "loss": 0.0154,
      "step": 14360
    },
    {
      "epoch": 4.6016,
      "grad_norm": 0.13903792202472687,
      "learning_rate": 0.00012747599999999998,
      "loss": 0.0146,
      "step": 14380
    },
    {
      "epoch": 4.608,
      "grad_norm": 0.16034796833992004,
      "learning_rate": 0.000127236,
      "loss": 0.0153,
      "step": 14400
    },
    {
      "epoch": 4.6144,
      "grad_norm": 0.13852578401565552,
      "learning_rate": 0.000126996,
      "loss": 0.0158,
      "step": 14420
    },
    {
      "epoch": 4.6208,
      "grad_norm": 0.12847240269184113,
      "learning_rate": 0.000126756,
      "loss": 0.0153,
      "step": 14440
    },
    {
      "epoch": 4.6272,
      "grad_norm": 0.08600157499313354,
      "learning_rate": 0.000126516,
      "loss": 0.0149,
      "step": 14460
    },
    {
      "epoch": 4.6336,
      "grad_norm": 0.15953035652637482,
      "learning_rate": 0.00012627599999999998,
      "loss": 0.0151,
      "step": 14480
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.1481482833623886,
      "learning_rate": 0.000126036,
      "loss": 0.0145,
      "step": 14500
    },
    {
      "epoch": 4.6464,
      "grad_norm": 0.14553888142108917,
      "learning_rate": 0.00012579599999999999,
      "loss": 0.0149,
      "step": 14520
    },
    {
      "epoch": 4.6528,
      "grad_norm": 0.14187464118003845,
      "learning_rate": 0.000125556,
      "loss": 0.0147,
      "step": 14540
    },
    {
      "epoch": 4.6592,
      "grad_norm": 0.12211369723081589,
      "learning_rate": 0.000125316,
      "loss": 0.015,
      "step": 14560
    },
    {
      "epoch": 4.6655999999999995,
      "grad_norm": 0.17732487618923187,
      "learning_rate": 0.00012507599999999998,
      "loss": 0.0152,
      "step": 14580
    },
    {
      "epoch": 4.672,
      "grad_norm": 0.1645750105381012,
      "learning_rate": 0.000124836,
      "loss": 0.015,
      "step": 14600
    },
    {
      "epoch": 4.6784,
      "grad_norm": 0.13356995582580566,
      "learning_rate": 0.00012459599999999998,
      "loss": 0.0146,
      "step": 14620
    },
    {
      "epoch": 4.6848,
      "grad_norm": 0.13158126175403595,
      "learning_rate": 0.000124356,
      "loss": 0.0145,
      "step": 14640
    },
    {
      "epoch": 4.6912,
      "grad_norm": 0.19577361643314362,
      "learning_rate": 0.000124116,
      "loss": 0.0154,
      "step": 14660
    },
    {
      "epoch": 4.6975999999999996,
      "grad_norm": 0.22014927864074707,
      "learning_rate": 0.000123876,
      "loss": 0.0155,
      "step": 14680
    },
    {
      "epoch": 4.704,
      "grad_norm": 0.10719700902700424,
      "learning_rate": 0.000123636,
      "loss": 0.0154,
      "step": 14700
    },
    {
      "epoch": 4.7104,
      "grad_norm": 0.17476528882980347,
      "learning_rate": 0.00012339599999999998,
      "loss": 0.0152,
      "step": 14720
    },
    {
      "epoch": 4.7168,
      "grad_norm": 0.07734508067369461,
      "learning_rate": 0.000123156,
      "loss": 0.0156,
      "step": 14740
    },
    {
      "epoch": 4.7232,
      "grad_norm": 0.12508156895637512,
      "learning_rate": 0.000122916,
      "loss": 0.0147,
      "step": 14760
    },
    {
      "epoch": 4.7296,
      "grad_norm": 0.20419485867023468,
      "learning_rate": 0.000122676,
      "loss": 0.0149,
      "step": 14780
    },
    {
      "epoch": 4.736,
      "grad_norm": 0.13675670325756073,
      "learning_rate": 0.000122436,
      "loss": 0.0145,
      "step": 14800
    },
    {
      "epoch": 4.7424,
      "grad_norm": 0.11774583905935287,
      "learning_rate": 0.000122196,
      "loss": 0.0144,
      "step": 14820
    },
    {
      "epoch": 4.7488,
      "grad_norm": 0.10432728379964828,
      "learning_rate": 0.00012195599999999998,
      "loss": 0.0151,
      "step": 14840
    },
    {
      "epoch": 4.7552,
      "grad_norm": 0.18499788641929626,
      "learning_rate": 0.000121716,
      "loss": 0.0147,
      "step": 14860
    },
    {
      "epoch": 4.7616,
      "grad_norm": 0.15289995074272156,
      "learning_rate": 0.00012147599999999999,
      "loss": 0.0156,
      "step": 14880
    },
    {
      "epoch": 4.768,
      "grad_norm": 0.1940380036830902,
      "learning_rate": 0.00012123599999999999,
      "loss": 0.0151,
      "step": 14900
    },
    {
      "epoch": 4.7744,
      "grad_norm": 0.1559230089187622,
      "learning_rate": 0.00012099599999999999,
      "loss": 0.0152,
      "step": 14920
    },
    {
      "epoch": 4.7808,
      "grad_norm": 0.14242121577262878,
      "learning_rate": 0.00012075599999999998,
      "loss": 0.0148,
      "step": 14940
    },
    {
      "epoch": 4.7872,
      "grad_norm": 0.08682268857955933,
      "learning_rate": 0.000120516,
      "loss": 0.0148,
      "step": 14960
    },
    {
      "epoch": 4.7936,
      "grad_norm": 0.10701410472393036,
      "learning_rate": 0.00012027599999999998,
      "loss": 0.0152,
      "step": 14980
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.1587185263633728,
      "learning_rate": 0.00012003599999999999,
      "loss": 0.0151,
      "step": 15000
    },
    {
      "epoch": 4.8064,
      "grad_norm": 0.1826251894235611,
      "learning_rate": 0.00011979599999999999,
      "loss": 0.0152,
      "step": 15020
    },
    {
      "epoch": 4.8128,
      "grad_norm": 0.21201923489570618,
      "learning_rate": 0.00011955599999999999,
      "loss": 0.0146,
      "step": 15040
    },
    {
      "epoch": 4.8192,
      "grad_norm": 0.10956317186355591,
      "learning_rate": 0.000119316,
      "loss": 0.0144,
      "step": 15060
    },
    {
      "epoch": 4.8256,
      "grad_norm": 0.10844763368368149,
      "learning_rate": 0.00011907599999999998,
      "loss": 0.015,
      "step": 15080
    },
    {
      "epoch": 4.832,
      "grad_norm": 0.17009970545768738,
      "learning_rate": 0.000118836,
      "loss": 0.0149,
      "step": 15100
    },
    {
      "epoch": 4.8384,
      "grad_norm": 0.12938980758190155,
      "learning_rate": 0.00011859599999999999,
      "loss": 0.014,
      "step": 15120
    },
    {
      "epoch": 4.8448,
      "grad_norm": 0.239644855260849,
      "learning_rate": 0.00011835599999999999,
      "loss": 0.0147,
      "step": 15140
    },
    {
      "epoch": 4.8512,
      "grad_norm": 0.09611508995294571,
      "learning_rate": 0.00011811599999999999,
      "loss": 0.015,
      "step": 15160
    },
    {
      "epoch": 4.8576,
      "grad_norm": 0.14855685830116272,
      "learning_rate": 0.00011787599999999998,
      "loss": 0.0151,
      "step": 15180
    },
    {
      "epoch": 4.864,
      "grad_norm": 0.14803412556648254,
      "learning_rate": 0.000117636,
      "loss": 0.0157,
      "step": 15200
    },
    {
      "epoch": 4.8704,
      "grad_norm": 0.14076149463653564,
      "learning_rate": 0.00011739599999999999,
      "loss": 0.0151,
      "step": 15220
    },
    {
      "epoch": 4.8768,
      "grad_norm": 0.13586722314357758,
      "learning_rate": 0.00011715599999999999,
      "loss": 0.0152,
      "step": 15240
    },
    {
      "epoch": 4.8832,
      "grad_norm": 0.1328635960817337,
      "learning_rate": 0.00011691599999999999,
      "loss": 0.0151,
      "step": 15260
    },
    {
      "epoch": 4.8896,
      "grad_norm": 0.09717490524053574,
      "learning_rate": 0.00011667599999999999,
      "loss": 0.0145,
      "step": 15280
    },
    {
      "epoch": 4.896,
      "grad_norm": 0.1766335517168045,
      "learning_rate": 0.000116436,
      "loss": 0.0154,
      "step": 15300
    },
    {
      "epoch": 4.9024,
      "grad_norm": 0.1423056274652481,
      "learning_rate": 0.00011619599999999998,
      "loss": 0.0152,
      "step": 15320
    },
    {
      "epoch": 4.9088,
      "grad_norm": 0.11044637113809586,
      "learning_rate": 0.00011595599999999999,
      "loss": 0.0143,
      "step": 15340
    },
    {
      "epoch": 4.9152000000000005,
      "grad_norm": 0.1207415983080864,
      "learning_rate": 0.00011571599999999999,
      "loss": 0.0146,
      "step": 15360
    },
    {
      "epoch": 4.9216,
      "grad_norm": 0.15616324543952942,
      "learning_rate": 0.00011547599999999999,
      "loss": 0.015,
      "step": 15380
    },
    {
      "epoch": 4.928,
      "grad_norm": 0.12215698510408401,
      "learning_rate": 0.00011523599999999999,
      "loss": 0.0145,
      "step": 15400
    },
    {
      "epoch": 4.9344,
      "grad_norm": 0.10625723004341125,
      "learning_rate": 0.000114996,
      "loss": 0.0144,
      "step": 15420
    },
    {
      "epoch": 4.9408,
      "grad_norm": 0.14540943503379822,
      "learning_rate": 0.000114756,
      "loss": 0.0145,
      "step": 15440
    },
    {
      "epoch": 4.9472000000000005,
      "grad_norm": 0.16954836249351501,
      "learning_rate": 0.00011451599999999999,
      "loss": 0.0144,
      "step": 15460
    },
    {
      "epoch": 4.9536,
      "grad_norm": 0.11624731868505478,
      "learning_rate": 0.00011427599999999999,
      "loss": 0.0149,
      "step": 15480
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.13543328642845154,
      "learning_rate": 0.00011403599999999999,
      "loss": 0.0146,
      "step": 15500
    },
    {
      "epoch": 4.9664,
      "grad_norm": 0.1289646476507187,
      "learning_rate": 0.00011379599999999999,
      "loss": 0.0151,
      "step": 15520
    },
    {
      "epoch": 4.9728,
      "grad_norm": 0.12394306808710098,
      "learning_rate": 0.000113556,
      "loss": 0.0151,
      "step": 15540
    },
    {
      "epoch": 4.9792,
      "grad_norm": 0.11667934060096741,
      "learning_rate": 0.00011331599999999998,
      "loss": 0.0146,
      "step": 15560
    },
    {
      "epoch": 4.9856,
      "grad_norm": 0.08744315057992935,
      "learning_rate": 0.00011307599999999999,
      "loss": 0.0141,
      "step": 15580
    },
    {
      "epoch": 4.992,
      "grad_norm": 0.11493127048015594,
      "learning_rate": 0.00011283599999999999,
      "loss": 0.0142,
      "step": 15600
    },
    {
      "epoch": 4.9984,
      "grad_norm": 0.15293966233730316,
      "learning_rate": 0.00011259599999999999,
      "loss": 0.0152,
      "step": 15620
    },
    {
      "epoch": 5.0048,
      "grad_norm": 0.171797975897789,
      "learning_rate": 0.00011235599999999999,
      "loss": 0.0147,
      "step": 15640
    },
    {
      "epoch": 5.0112,
      "grad_norm": 0.14988768100738525,
      "learning_rate": 0.000112116,
      "loss": 0.0145,
      "step": 15660
    },
    {
      "epoch": 5.0176,
      "grad_norm": 0.09559328109025955,
      "learning_rate": 0.00011187599999999998,
      "loss": 0.0145,
      "step": 15680
    },
    {
      "epoch": 5.024,
      "grad_norm": 0.13761217892169952,
      "learning_rate": 0.00011163599999999999,
      "loss": 0.0142,
      "step": 15700
    },
    {
      "epoch": 5.0304,
      "grad_norm": 0.12900130450725555,
      "learning_rate": 0.00011139599999999999,
      "loss": 0.0142,
      "step": 15720
    },
    {
      "epoch": 5.0368,
      "grad_norm": 0.1866103559732437,
      "learning_rate": 0.00011115599999999999,
      "loss": 0.0146,
      "step": 15740
    },
    {
      "epoch": 5.0432,
      "grad_norm": 0.1851031333208084,
      "learning_rate": 0.00011091599999999999,
      "loss": 0.0154,
      "step": 15760
    },
    {
      "epoch": 5.0496,
      "grad_norm": 0.13604086637496948,
      "learning_rate": 0.000110676,
      "loss": 0.015,
      "step": 15780
    },
    {
      "epoch": 5.056,
      "grad_norm": 0.13907037675380707,
      "learning_rate": 0.000110436,
      "loss": 0.0146,
      "step": 15800
    },
    {
      "epoch": 5.0624,
      "grad_norm": 0.1443830132484436,
      "learning_rate": 0.00011019599999999999,
      "loss": 0.0144,
      "step": 15820
    },
    {
      "epoch": 5.0688,
      "grad_norm": 0.1146245002746582,
      "learning_rate": 0.00010995599999999999,
      "loss": 0.0143,
      "step": 15840
    },
    {
      "epoch": 5.0752,
      "grad_norm": 0.1198115423321724,
      "learning_rate": 0.00010971599999999999,
      "loss": 0.0149,
      "step": 15860
    },
    {
      "epoch": 5.0816,
      "grad_norm": 0.10229980200529099,
      "learning_rate": 0.000109476,
      "loss": 0.0149,
      "step": 15880
    },
    {
      "epoch": 5.088,
      "grad_norm": 0.1441129595041275,
      "learning_rate": 0.000109236,
      "loss": 0.0148,
      "step": 15900
    },
    {
      "epoch": 5.0944,
      "grad_norm": 0.12019021064043045,
      "learning_rate": 0.00010899599999999998,
      "loss": 0.0147,
      "step": 15920
    },
    {
      "epoch": 5.1008,
      "grad_norm": 0.11459271609783173,
      "learning_rate": 0.00010875599999999999,
      "loss": 0.0145,
      "step": 15940
    },
    {
      "epoch": 5.1072,
      "grad_norm": 0.12258321791887283,
      "learning_rate": 0.00010851599999999999,
      "loss": 0.0143,
      "step": 15960
    },
    {
      "epoch": 5.1136,
      "grad_norm": 0.1298445612192154,
      "learning_rate": 0.00010827599999999999,
      "loss": 0.0149,
      "step": 15980
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.13695493340492249,
      "learning_rate": 0.000108036,
      "loss": 0.0143,
      "step": 16000
    },
    {
      "epoch": 5.1264,
      "grad_norm": 0.11817068606615067,
      "learning_rate": 0.00010779599999999998,
      "loss": 0.0145,
      "step": 16020
    },
    {
      "epoch": 5.1328,
      "grad_norm": 0.11184157431125641,
      "learning_rate": 0.000107556,
      "loss": 0.0144,
      "step": 16040
    },
    {
      "epoch": 5.1392,
      "grad_norm": 0.10444144159555435,
      "learning_rate": 0.00010731599999999999,
      "loss": 0.0145,
      "step": 16060
    },
    {
      "epoch": 5.1456,
      "grad_norm": 0.18349672853946686,
      "learning_rate": 0.00010707599999999999,
      "loss": 0.0147,
      "step": 16080
    },
    {
      "epoch": 5.152,
      "grad_norm": 0.12775751948356628,
      "learning_rate": 0.00010683599999999999,
      "loss": 0.0146,
      "step": 16100
    },
    {
      "epoch": 5.1584,
      "grad_norm": 0.09191768616437912,
      "learning_rate": 0.00010660799999999999,
      "loss": 0.0144,
      "step": 16120
    },
    {
      "epoch": 5.1648,
      "grad_norm": 0.09267831593751907,
      "learning_rate": 0.00010636799999999998,
      "loss": 0.0147,
      "step": 16140
    },
    {
      "epoch": 5.1712,
      "grad_norm": 0.12631838023662567,
      "learning_rate": 0.000106128,
      "loss": 0.0151,
      "step": 16160
    },
    {
      "epoch": 5.1776,
      "grad_norm": 0.09628186374902725,
      "learning_rate": 0.00010588799999999999,
      "loss": 0.0149,
      "step": 16180
    },
    {
      "epoch": 5.184,
      "grad_norm": 0.10960641503334045,
      "learning_rate": 0.00010564799999999999,
      "loss": 0.0145,
      "step": 16200
    },
    {
      "epoch": 5.1904,
      "grad_norm": 0.09054409712553024,
      "learning_rate": 0.00010540799999999999,
      "loss": 0.0144,
      "step": 16220
    },
    {
      "epoch": 5.1968,
      "grad_norm": 0.10318014770746231,
      "learning_rate": 0.00010516799999999998,
      "loss": 0.0146,
      "step": 16240
    },
    {
      "epoch": 5.2032,
      "grad_norm": 0.17424191534519196,
      "learning_rate": 0.000104928,
      "loss": 0.0143,
      "step": 16260
    },
    {
      "epoch": 5.2096,
      "grad_norm": 0.14522626996040344,
      "learning_rate": 0.00010468799999999998,
      "loss": 0.0147,
      "step": 16280
    },
    {
      "epoch": 5.216,
      "grad_norm": 0.10732533037662506,
      "learning_rate": 0.000104448,
      "loss": 0.0137,
      "step": 16300
    },
    {
      "epoch": 5.2224,
      "grad_norm": 0.18941982090473175,
      "learning_rate": 0.00010420799999999999,
      "loss": 0.0143,
      "step": 16320
    },
    {
      "epoch": 5.2288,
      "grad_norm": 0.12918135523796082,
      "learning_rate": 0.00010396799999999999,
      "loss": 0.0142,
      "step": 16340
    },
    {
      "epoch": 5.2352,
      "grad_norm": 0.14402228593826294,
      "learning_rate": 0.000103728,
      "loss": 0.0148,
      "step": 16360
    },
    {
      "epoch": 5.2416,
      "grad_norm": 0.15221890807151794,
      "learning_rate": 0.00010348799999999998,
      "loss": 0.015,
      "step": 16380
    },
    {
      "epoch": 5.248,
      "grad_norm": 0.09500768780708313,
      "learning_rate": 0.000103248,
      "loss": 0.0139,
      "step": 16400
    },
    {
      "epoch": 5.2544,
      "grad_norm": 0.11696755886077881,
      "learning_rate": 0.00010300799999999999,
      "loss": 0.0142,
      "step": 16420
    },
    {
      "epoch": 5.2608,
      "grad_norm": 0.15020932257175446,
      "learning_rate": 0.00010276799999999999,
      "loss": 0.0144,
      "step": 16440
    },
    {
      "epoch": 5.2672,
      "grad_norm": 0.17818652093410492,
      "learning_rate": 0.00010252799999999999,
      "loss": 0.0155,
      "step": 16460
    },
    {
      "epoch": 5.2736,
      "grad_norm": 0.15721294283866882,
      "learning_rate": 0.00010228799999999998,
      "loss": 0.0141,
      "step": 16480
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.07888144254684448,
      "learning_rate": 0.000102048,
      "loss": 0.0155,
      "step": 16500
    },
    {
      "epoch": 5.2864,
      "grad_norm": 0.08961086720228195,
      "learning_rate": 0.00010180799999999998,
      "loss": 0.0147,
      "step": 16520
    },
    {
      "epoch": 5.2928,
      "grad_norm": 0.10611031949520111,
      "learning_rate": 0.000101568,
      "loss": 0.0148,
      "step": 16540
    },
    {
      "epoch": 5.2992,
      "grad_norm": 0.1251429319381714,
      "learning_rate": 0.00010132799999999999,
      "loss": 0.0148,
      "step": 16560
    },
    {
      "epoch": 5.3056,
      "grad_norm": 0.11182885617017746,
      "learning_rate": 0.00010108799999999999,
      "loss": 0.0144,
      "step": 16580
    },
    {
      "epoch": 5.312,
      "grad_norm": 0.11061140894889832,
      "learning_rate": 0.000100848,
      "loss": 0.0155,
      "step": 16600
    },
    {
      "epoch": 5.3184000000000005,
      "grad_norm": 0.15937072038650513,
      "learning_rate": 0.00010060799999999998,
      "loss": 0.0149,
      "step": 16620
    },
    {
      "epoch": 5.3248,
      "grad_norm": 0.10627544671297073,
      "learning_rate": 0.000100368,
      "loss": 0.0142,
      "step": 16640
    },
    {
      "epoch": 5.3312,
      "grad_norm": 0.11013069748878479,
      "learning_rate": 0.00010012799999999999,
      "loss": 0.0142,
      "step": 16660
    },
    {
      "epoch": 5.3376,
      "grad_norm": 0.13647788763046265,
      "learning_rate": 9.988799999999999e-05,
      "loss": 0.0143,
      "step": 16680
    },
    {
      "epoch": 5.344,
      "grad_norm": 0.12202148884534836,
      "learning_rate": 9.964799999999999e-05,
      "loss": 0.0146,
      "step": 16700
    },
    {
      "epoch": 5.3504,
      "grad_norm": 0.16138237714767456,
      "learning_rate": 9.9408e-05,
      "loss": 0.0151,
      "step": 16720
    },
    {
      "epoch": 5.3568,
      "grad_norm": 0.18302200734615326,
      "learning_rate": 9.9168e-05,
      "loss": 0.0142,
      "step": 16740
    },
    {
      "epoch": 5.3632,
      "grad_norm": 0.15160569548606873,
      "learning_rate": 9.892799999999999e-05,
      "loss": 0.0148,
      "step": 16760
    },
    {
      "epoch": 5.3696,
      "grad_norm": 0.11698492616415024,
      "learning_rate": 9.868799999999999e-05,
      "loss": 0.0148,
      "step": 16780
    },
    {
      "epoch": 5.376,
      "grad_norm": 0.16333000361919403,
      "learning_rate": 9.844799999999999e-05,
      "loss": 0.0146,
      "step": 16800
    },
    {
      "epoch": 5.3824,
      "grad_norm": 0.11770429462194443,
      "learning_rate": 9.820799999999999e-05,
      "loss": 0.0148,
      "step": 16820
    },
    {
      "epoch": 5.3888,
      "grad_norm": 0.13724328577518463,
      "learning_rate": 9.7968e-05,
      "loss": 0.0145,
      "step": 16840
    },
    {
      "epoch": 5.3952,
      "grad_norm": 0.09247834980487823,
      "learning_rate": 9.772799999999998e-05,
      "loss": 0.0154,
      "step": 16860
    },
    {
      "epoch": 5.4016,
      "grad_norm": 0.16120967268943787,
      "learning_rate": 9.7488e-05,
      "loss": 0.0153,
      "step": 16880
    },
    {
      "epoch": 5.408,
      "grad_norm": 0.16993039846420288,
      "learning_rate": 9.724799999999999e-05,
      "loss": 0.0143,
      "step": 16900
    },
    {
      "epoch": 5.4144,
      "grad_norm": 0.15911458432674408,
      "learning_rate": 9.700799999999999e-05,
      "loss": 0.0147,
      "step": 16920
    },
    {
      "epoch": 5.4208,
      "grad_norm": 0.14822019636631012,
      "learning_rate": 9.676799999999999e-05,
      "loss": 0.0149,
      "step": 16940
    },
    {
      "epoch": 5.4272,
      "grad_norm": 0.14049454033374786,
      "learning_rate": 9.6528e-05,
      "loss": 0.014,
      "step": 16960
    },
    {
      "epoch": 5.4336,
      "grad_norm": 0.07593588531017303,
      "learning_rate": 9.6288e-05,
      "loss": 0.0138,
      "step": 16980
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.15857575833797455,
      "learning_rate": 9.604799999999999e-05,
      "loss": 0.0138,
      "step": 17000
    },
    {
      "epoch": 5.4464,
      "grad_norm": 0.08639827370643616,
      "learning_rate": 9.580799999999999e-05,
      "loss": 0.0145,
      "step": 17020
    },
    {
      "epoch": 5.4528,
      "grad_norm": 0.16256758570671082,
      "learning_rate": 9.556799999999999e-05,
      "loss": 0.0146,
      "step": 17040
    },
    {
      "epoch": 5.4592,
      "grad_norm": 0.09652281552553177,
      "learning_rate": 9.532799999999999e-05,
      "loss": 0.0141,
      "step": 17060
    },
    {
      "epoch": 5.4656,
      "grad_norm": 0.1910010278224945,
      "learning_rate": 9.5088e-05,
      "loss": 0.0151,
      "step": 17080
    },
    {
      "epoch": 5.4719999999999995,
      "grad_norm": 0.14310410618782043,
      "learning_rate": 9.4848e-05,
      "loss": 0.0147,
      "step": 17100
    },
    {
      "epoch": 5.4784,
      "grad_norm": 0.07858811318874359,
      "learning_rate": 9.460799999999999e-05,
      "loss": 0.0141,
      "step": 17120
    },
    {
      "epoch": 5.4848,
      "grad_norm": 0.14411847293376923,
      "learning_rate": 9.436799999999999e-05,
      "loss": 0.0148,
      "step": 17140
    },
    {
      "epoch": 5.4912,
      "grad_norm": 0.13010156154632568,
      "learning_rate": 9.412799999999999e-05,
      "loss": 0.0145,
      "step": 17160
    },
    {
      "epoch": 5.4976,
      "grad_norm": 0.1369609832763672,
      "learning_rate": 9.388799999999999e-05,
      "loss": 0.0146,
      "step": 17180
    },
    {
      "epoch": 5.504,
      "grad_norm": 0.16602611541748047,
      "learning_rate": 9.3648e-05,
      "loss": 0.0143,
      "step": 17200
    },
    {
      "epoch": 5.5104,
      "grad_norm": 0.16624434292316437,
      "learning_rate": 9.3408e-05,
      "loss": 0.0142,
      "step": 17220
    },
    {
      "epoch": 5.5168,
      "grad_norm": 0.13966669142246246,
      "learning_rate": 9.316799999999999e-05,
      "loss": 0.0147,
      "step": 17240
    },
    {
      "epoch": 5.5232,
      "grad_norm": 0.17253883183002472,
      "learning_rate": 9.292799999999999e-05,
      "loss": 0.0149,
      "step": 17260
    },
    {
      "epoch": 5.5296,
      "grad_norm": 0.10951541364192963,
      "learning_rate": 9.268799999999999e-05,
      "loss": 0.0135,
      "step": 17280
    },
    {
      "epoch": 5.536,
      "grad_norm": 0.09635079652070999,
      "learning_rate": 9.244799999999999e-05,
      "loss": 0.014,
      "step": 17300
    },
    {
      "epoch": 5.5424,
      "grad_norm": 0.11146172881126404,
      "learning_rate": 9.2208e-05,
      "loss": 0.0136,
      "step": 17320
    },
    {
      "epoch": 5.5488,
      "grad_norm": 0.14136718213558197,
      "learning_rate": 9.1968e-05,
      "loss": 0.0142,
      "step": 17340
    },
    {
      "epoch": 5.5552,
      "grad_norm": 0.19822607934474945,
      "learning_rate": 9.172799999999999e-05,
      "loss": 0.0148,
      "step": 17360
    },
    {
      "epoch": 5.5616,
      "grad_norm": 0.1360502541065216,
      "learning_rate": 9.148799999999999e-05,
      "loss": 0.0141,
      "step": 17380
    },
    {
      "epoch": 5.568,
      "grad_norm": 0.13884319365024567,
      "learning_rate": 9.124799999999999e-05,
      "loss": 0.0151,
      "step": 17400
    },
    {
      "epoch": 5.5744,
      "grad_norm": 0.11212444305419922,
      "learning_rate": 9.1008e-05,
      "loss": 0.0149,
      "step": 17420
    },
    {
      "epoch": 5.5808,
      "grad_norm": 0.11818349361419678,
      "learning_rate": 9.0768e-05,
      "loss": 0.0143,
      "step": 17440
    },
    {
      "epoch": 5.5872,
      "grad_norm": 0.16094279289245605,
      "learning_rate": 9.052799999999998e-05,
      "loss": 0.0145,
      "step": 17460
    },
    {
      "epoch": 5.5936,
      "grad_norm": 0.1706245243549347,
      "learning_rate": 9.0288e-05,
      "loss": 0.0148,
      "step": 17480
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.13081850111484528,
      "learning_rate": 9.004799999999999e-05,
      "loss": 0.0141,
      "step": 17500
    },
    {
      "epoch": 5.6064,
      "grad_norm": 0.14426515996456146,
      "learning_rate": 8.980799999999999e-05,
      "loss": 0.0151,
      "step": 17520
    },
    {
      "epoch": 5.6128,
      "grad_norm": 0.12040382623672485,
      "learning_rate": 8.9568e-05,
      "loss": 0.0142,
      "step": 17540
    },
    {
      "epoch": 5.6192,
      "grad_norm": 0.08242964744567871,
      "learning_rate": 8.9328e-05,
      "loss": 0.0142,
      "step": 17560
    },
    {
      "epoch": 5.6256,
      "grad_norm": 0.20634537935256958,
      "learning_rate": 8.9088e-05,
      "loss": 0.0141,
      "step": 17580
    },
    {
      "epoch": 5.632,
      "grad_norm": 0.20265355706214905,
      "learning_rate": 8.884799999999999e-05,
      "loss": 0.0141,
      "step": 17600
    },
    {
      "epoch": 5.6384,
      "grad_norm": 0.10153597593307495,
      "learning_rate": 8.860799999999999e-05,
      "loss": 0.0137,
      "step": 17620
    },
    {
      "epoch": 5.6448,
      "grad_norm": 0.1346961408853531,
      "learning_rate": 8.836799999999999e-05,
      "loss": 0.0145,
      "step": 17640
    },
    {
      "epoch": 5.6512,
      "grad_norm": 0.16769006848335266,
      "learning_rate": 8.8128e-05,
      "loss": 0.0142,
      "step": 17660
    },
    {
      "epoch": 5.6576,
      "grad_norm": 0.13784250617027283,
      "learning_rate": 8.7888e-05,
      "loss": 0.0139,
      "step": 17680
    },
    {
      "epoch": 5.664,
      "grad_norm": 0.18439719080924988,
      "learning_rate": 8.764799999999998e-05,
      "loss": 0.0147,
      "step": 17700
    },
    {
      "epoch": 5.6704,
      "grad_norm": 0.0977441743016243,
      "learning_rate": 8.7408e-05,
      "loss": 0.0139,
      "step": 17720
    },
    {
      "epoch": 5.6768,
      "grad_norm": 0.1508263647556305,
      "learning_rate": 8.716799999999999e-05,
      "loss": 0.0146,
      "step": 17740
    },
    {
      "epoch": 5.6832,
      "grad_norm": 0.1699802428483963,
      "learning_rate": 8.692799999999999e-05,
      "loss": 0.0152,
      "step": 17760
    },
    {
      "epoch": 5.6896,
      "grad_norm": 0.10514221340417862,
      "learning_rate": 8.6688e-05,
      "loss": 0.0144,
      "step": 17780
    },
    {
      "epoch": 5.696,
      "grad_norm": 0.0949002057313919,
      "learning_rate": 8.6448e-05,
      "loss": 0.0145,
      "step": 17800
    },
    {
      "epoch": 5.7024,
      "grad_norm": 0.10877208411693573,
      "learning_rate": 8.6208e-05,
      "loss": 0.0142,
      "step": 17820
    },
    {
      "epoch": 5.7088,
      "grad_norm": 0.13836637139320374,
      "learning_rate": 8.596799999999999e-05,
      "loss": 0.0138,
      "step": 17840
    },
    {
      "epoch": 5.7152,
      "grad_norm": 0.10969095677137375,
      "learning_rate": 8.5728e-05,
      "loss": 0.0144,
      "step": 17860
    },
    {
      "epoch": 5.7216000000000005,
      "grad_norm": 0.10264100134372711,
      "learning_rate": 8.548799999999999e-05,
      "loss": 0.0142,
      "step": 17880
    },
    {
      "epoch": 5.728,
      "grad_norm": 0.07988971471786499,
      "learning_rate": 8.5248e-05,
      "loss": 0.0142,
      "step": 17900
    },
    {
      "epoch": 5.7344,
      "grad_norm": 0.1564139872789383,
      "learning_rate": 8.5008e-05,
      "loss": 0.0141,
      "step": 17920
    },
    {
      "epoch": 5.7408,
      "grad_norm": 0.1332969218492508,
      "learning_rate": 8.476799999999999e-05,
      "loss": 0.0139,
      "step": 17940
    },
    {
      "epoch": 5.7472,
      "grad_norm": 0.14203600585460663,
      "learning_rate": 8.4528e-05,
      "loss": 0.0145,
      "step": 17960
    },
    {
      "epoch": 5.7536000000000005,
      "grad_norm": 0.09406431764364243,
      "learning_rate": 8.428799999999999e-05,
      "loss": 0.0144,
      "step": 17980
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.14691287279129028,
      "learning_rate": 8.404799999999999e-05,
      "loss": 0.0141,
      "step": 18000
    },
    {
      "epoch": 5.7664,
      "grad_norm": 0.10147310048341751,
      "learning_rate": 8.3808e-05,
      "loss": 0.014,
      "step": 18020
    },
    {
      "epoch": 5.7728,
      "grad_norm": 0.1719498485326767,
      "learning_rate": 8.356799999999998e-05,
      "loss": 0.0144,
      "step": 18040
    },
    {
      "epoch": 5.7792,
      "grad_norm": 0.16585050523281097,
      "learning_rate": 8.3328e-05,
      "loss": 0.0148,
      "step": 18060
    },
    {
      "epoch": 5.7856,
      "grad_norm": 0.09442467242479324,
      "learning_rate": 8.308799999999999e-05,
      "loss": 0.0143,
      "step": 18080
    },
    {
      "epoch": 5.792,
      "grad_norm": 0.19142399728298187,
      "learning_rate": 8.2848e-05,
      "loss": 0.0142,
      "step": 18100
    },
    {
      "epoch": 5.7984,
      "grad_norm": 0.16443045437335968,
      "learning_rate": 8.260799999999999e-05,
      "loss": 0.0146,
      "step": 18120
    },
    {
      "epoch": 5.8048,
      "grad_norm": 0.10489783436059952,
      "learning_rate": 8.2368e-05,
      "loss": 0.0137,
      "step": 18140
    },
    {
      "epoch": 5.8112,
      "grad_norm": 0.18450801074504852,
      "learning_rate": 8.2128e-05,
      "loss": 0.0137,
      "step": 18160
    },
    {
      "epoch": 5.8176,
      "grad_norm": 0.12374439835548401,
      "learning_rate": 8.188799999999999e-05,
      "loss": 0.014,
      "step": 18180
    },
    {
      "epoch": 5.824,
      "grad_norm": 0.14234629273414612,
      "learning_rate": 8.1648e-05,
      "loss": 0.0143,
      "step": 18200
    },
    {
      "epoch": 5.8304,
      "grad_norm": 0.09982135146856308,
      "learning_rate": 8.140799999999999e-05,
      "loss": 0.0135,
      "step": 18220
    },
    {
      "epoch": 5.8368,
      "grad_norm": 0.12227369844913483,
      "learning_rate": 8.1168e-05,
      "loss": 0.014,
      "step": 18240
    },
    {
      "epoch": 5.8431999999999995,
      "grad_norm": 0.17369437217712402,
      "learning_rate": 8.0928e-05,
      "loss": 0.0142,
      "step": 18260
    },
    {
      "epoch": 5.8496,
      "grad_norm": 0.09814093261957169,
      "learning_rate": 8.068799999999998e-05,
      "loss": 0.0142,
      "step": 18280
    },
    {
      "epoch": 5.856,
      "grad_norm": 0.16341620683670044,
      "learning_rate": 8.0448e-05,
      "loss": 0.0144,
      "step": 18300
    },
    {
      "epoch": 5.8624,
      "grad_norm": 0.10796815156936646,
      "learning_rate": 8.020799999999999e-05,
      "loss": 0.0142,
      "step": 18320
    },
    {
      "epoch": 5.8688,
      "grad_norm": 0.13238359987735748,
      "learning_rate": 7.9968e-05,
      "loss": 0.0137,
      "step": 18340
    },
    {
      "epoch": 5.8751999999999995,
      "grad_norm": 0.09633487462997437,
      "learning_rate": 7.972799999999999e-05,
      "loss": 0.014,
      "step": 18360
    },
    {
      "epoch": 5.8816,
      "grad_norm": 0.10021019726991653,
      "learning_rate": 7.948799999999998e-05,
      "loss": 0.014,
      "step": 18380
    },
    {
      "epoch": 5.888,
      "grad_norm": 0.15714062750339508,
      "learning_rate": 7.926e-05,
      "loss": 0.0145,
      "step": 18400
    },
    {
      "epoch": 5.8944,
      "grad_norm": 0.14852991700172424,
      "learning_rate": 7.902e-05,
      "loss": 0.0144,
      "step": 18420
    },
    {
      "epoch": 5.9008,
      "grad_norm": 0.08387087285518646,
      "learning_rate": 7.877999999999999e-05,
      "loss": 0.0139,
      "step": 18440
    },
    {
      "epoch": 5.9072,
      "grad_norm": 0.13869427144527435,
      "learning_rate": 7.853999999999999e-05,
      "loss": 0.0141,
      "step": 18460
    },
    {
      "epoch": 5.9136,
      "grad_norm": 0.074346162378788,
      "learning_rate": 7.829999999999999e-05,
      "loss": 0.0136,
      "step": 18480
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.08905158936977386,
      "learning_rate": 7.806e-05,
      "loss": 0.014,
      "step": 18500
    },
    {
      "epoch": 5.9264,
      "grad_norm": 0.11753189563751221,
      "learning_rate": 7.782e-05,
      "loss": 0.0137,
      "step": 18520
    },
    {
      "epoch": 5.9328,
      "grad_norm": 0.11535682529211044,
      "learning_rate": 7.757999999999999e-05,
      "loss": 0.0134,
      "step": 18540
    },
    {
      "epoch": 5.9392,
      "grad_norm": 0.09082072228193283,
      "learning_rate": 7.733999999999999e-05,
      "loss": 0.0146,
      "step": 18560
    },
    {
      "epoch": 5.9456,
      "grad_norm": 0.17259591817855835,
      "learning_rate": 7.709999999999999e-05,
      "loss": 0.0137,
      "step": 18580
    },
    {
      "epoch": 5.952,
      "grad_norm": 0.1063837930560112,
      "learning_rate": 7.685999999999999e-05,
      "loss": 0.0138,
      "step": 18600
    },
    {
      "epoch": 5.9584,
      "grad_norm": 0.09714232385158539,
      "learning_rate": 7.662e-05,
      "loss": 0.0145,
      "step": 18620
    },
    {
      "epoch": 5.9648,
      "grad_norm": 0.12411247193813324,
      "learning_rate": 7.638e-05,
      "loss": 0.0149,
      "step": 18640
    },
    {
      "epoch": 5.9712,
      "grad_norm": 0.13391703367233276,
      "learning_rate": 7.614e-05,
      "loss": 0.014,
      "step": 18660
    },
    {
      "epoch": 5.9776,
      "grad_norm": 0.09199503809213638,
      "learning_rate": 7.589999999999999e-05,
      "loss": 0.0134,
      "step": 18680
    },
    {
      "epoch": 5.984,
      "grad_norm": 0.1541910469532013,
      "learning_rate": 7.565999999999999e-05,
      "loss": 0.0139,
      "step": 18700
    },
    {
      "epoch": 5.9904,
      "grad_norm": 0.1039971187710762,
      "learning_rate": 7.541999999999999e-05,
      "loss": 0.0138,
      "step": 18720
    },
    {
      "epoch": 5.9968,
      "grad_norm": 0.12616966664791107,
      "learning_rate": 7.518e-05,
      "loss": 0.014,
      "step": 18740
    },
    {
      "epoch": 6.0032,
      "grad_norm": 0.11860375851392746,
      "learning_rate": 7.494e-05,
      "loss": 0.0145,
      "step": 18760
    },
    {
      "epoch": 6.0096,
      "grad_norm": 0.10377251356840134,
      "learning_rate": 7.47e-05,
      "loss": 0.0135,
      "step": 18780
    },
    {
      "epoch": 6.016,
      "grad_norm": 0.14138731360435486,
      "learning_rate": 7.445999999999999e-05,
      "loss": 0.0137,
      "step": 18800
    },
    {
      "epoch": 6.0224,
      "grad_norm": 0.11056722700595856,
      "learning_rate": 7.421999999999999e-05,
      "loss": 0.0141,
      "step": 18820
    },
    {
      "epoch": 6.0288,
      "grad_norm": 0.14056065678596497,
      "learning_rate": 7.397999999999999e-05,
      "loss": 0.014,
      "step": 18840
    },
    {
      "epoch": 6.0352,
      "grad_norm": 0.16274695098400116,
      "learning_rate": 7.374e-05,
      "loss": 0.0148,
      "step": 18860
    },
    {
      "epoch": 6.0416,
      "grad_norm": 0.0979992002248764,
      "learning_rate": 7.35e-05,
      "loss": 0.0131,
      "step": 18880
    },
    {
      "epoch": 6.048,
      "grad_norm": 0.13858038187026978,
      "learning_rate": 7.326e-05,
      "loss": 0.0136,
      "step": 18900
    },
    {
      "epoch": 6.0544,
      "grad_norm": 0.11752409487962723,
      "learning_rate": 7.301999999999999e-05,
      "loss": 0.0139,
      "step": 18920
    },
    {
      "epoch": 6.0608,
      "grad_norm": 0.1282678097486496,
      "learning_rate": 7.277999999999999e-05,
      "loss": 0.0135,
      "step": 18940
    },
    {
      "epoch": 6.0672,
      "grad_norm": 0.157267764210701,
      "learning_rate": 7.254e-05,
      "loss": 0.0142,
      "step": 18960
    },
    {
      "epoch": 6.0736,
      "grad_norm": 0.09159135818481445,
      "learning_rate": 7.23e-05,
      "loss": 0.0136,
      "step": 18980
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.14151550829410553,
      "learning_rate": 7.206e-05,
      "loss": 0.0144,
      "step": 19000
    },
    {
      "epoch": 6.0864,
      "grad_norm": 0.1400422304868698,
      "learning_rate": 7.182e-05,
      "loss": 0.0146,
      "step": 19020
    },
    {
      "epoch": 6.0928,
      "grad_norm": 0.10694760829210281,
      "learning_rate": 7.158e-05,
      "loss": 0.0139,
      "step": 19040
    },
    {
      "epoch": 6.0992,
      "grad_norm": 0.10081642866134644,
      "learning_rate": 7.133999999999999e-05,
      "loss": 0.0139,
      "step": 19060
    },
    {
      "epoch": 6.1056,
      "grad_norm": 0.11815804243087769,
      "learning_rate": 7.11e-05,
      "loss": 0.0136,
      "step": 19080
    },
    {
      "epoch": 6.112,
      "grad_norm": 0.1190936416387558,
      "learning_rate": 7.086e-05,
      "loss": 0.014,
      "step": 19100
    },
    {
      "epoch": 6.1184,
      "grad_norm": 0.10236202925443649,
      "learning_rate": 7.062e-05,
      "loss": 0.0143,
      "step": 19120
    },
    {
      "epoch": 6.1248,
      "grad_norm": 0.1535188853740692,
      "learning_rate": 7.038e-05,
      "loss": 0.0139,
      "step": 19140
    },
    {
      "epoch": 6.1312,
      "grad_norm": 0.12455080449581146,
      "learning_rate": 7.014e-05,
      "loss": 0.0138,
      "step": 19160
    },
    {
      "epoch": 6.1376,
      "grad_norm": 0.05482856556773186,
      "learning_rate": 6.989999999999999e-05,
      "loss": 0.0134,
      "step": 19180
    },
    {
      "epoch": 6.144,
      "grad_norm": 0.1507928967475891,
      "learning_rate": 6.966e-05,
      "loss": 0.0138,
      "step": 19200
    },
    {
      "epoch": 6.1504,
      "grad_norm": 0.07411529868841171,
      "learning_rate": 6.942e-05,
      "loss": 0.0143,
      "step": 19220
    },
    {
      "epoch": 6.1568,
      "grad_norm": 0.09193132072687149,
      "learning_rate": 6.918e-05,
      "loss": 0.0138,
      "step": 19240
    },
    {
      "epoch": 6.1632,
      "grad_norm": 0.17272593080997467,
      "learning_rate": 6.894e-05,
      "loss": 0.0137,
      "step": 19260
    },
    {
      "epoch": 6.1696,
      "grad_norm": 0.09247203916311264,
      "learning_rate": 6.87e-05,
      "loss": 0.0136,
      "step": 19280
    },
    {
      "epoch": 6.176,
      "grad_norm": 0.11837389320135117,
      "learning_rate": 6.845999999999999e-05,
      "loss": 0.0141,
      "step": 19300
    },
    {
      "epoch": 6.1824,
      "grad_norm": 0.11987795680761337,
      "learning_rate": 6.822e-05,
      "loss": 0.0141,
      "step": 19320
    },
    {
      "epoch": 6.1888,
      "grad_norm": 0.09332748502492905,
      "learning_rate": 6.798e-05,
      "loss": 0.014,
      "step": 19340
    },
    {
      "epoch": 6.1952,
      "grad_norm": 0.09400196373462677,
      "learning_rate": 6.774e-05,
      "loss": 0.0143,
      "step": 19360
    },
    {
      "epoch": 6.2016,
      "grad_norm": 0.10384821146726608,
      "learning_rate": 6.75e-05,
      "loss": 0.0135,
      "step": 19380
    },
    {
      "epoch": 6.208,
      "grad_norm": 0.13085268437862396,
      "learning_rate": 6.726e-05,
      "loss": 0.0134,
      "step": 19400
    },
    {
      "epoch": 6.2144,
      "grad_norm": 0.12369576841592789,
      "learning_rate": 6.701999999999999e-05,
      "loss": 0.0136,
      "step": 19420
    },
    {
      "epoch": 6.2208,
      "grad_norm": 0.13205642998218536,
      "learning_rate": 6.678e-05,
      "loss": 0.0144,
      "step": 19440
    },
    {
      "epoch": 6.2272,
      "grad_norm": 0.2461804300546646,
      "learning_rate": 6.654e-05,
      "loss": 0.0139,
      "step": 19460
    },
    {
      "epoch": 6.2336,
      "grad_norm": 0.1017550453543663,
      "learning_rate": 6.63e-05,
      "loss": 0.014,
      "step": 19480
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.1072973757982254,
      "learning_rate": 6.606e-05,
      "loss": 0.0136,
      "step": 19500
    },
    {
      "epoch": 6.2464,
      "grad_norm": 0.10427530854940414,
      "learning_rate": 6.582e-05,
      "loss": 0.014,
      "step": 19520
    },
    {
      "epoch": 6.2528,
      "grad_norm": 0.12904053926467896,
      "learning_rate": 6.557999999999999e-05,
      "loss": 0.0133,
      "step": 19540
    },
    {
      "epoch": 6.2592,
      "grad_norm": 0.10546521097421646,
      "learning_rate": 6.534e-05,
      "loss": 0.0136,
      "step": 19560
    },
    {
      "epoch": 6.2656,
      "grad_norm": 0.09773364663124084,
      "learning_rate": 6.51e-05,
      "loss": 0.0142,
      "step": 19580
    },
    {
      "epoch": 6.272,
      "grad_norm": 0.08923453092575073,
      "learning_rate": 6.486e-05,
      "loss": 0.0139,
      "step": 19600
    },
    {
      "epoch": 6.2783999999999995,
      "grad_norm": 0.1216215267777443,
      "learning_rate": 6.462e-05,
      "loss": 0.0137,
      "step": 19620
    },
    {
      "epoch": 6.2848,
      "grad_norm": 0.13756711781024933,
      "learning_rate": 6.438e-05,
      "loss": 0.0142,
      "step": 19640
    },
    {
      "epoch": 6.2912,
      "grad_norm": 0.11586420983076096,
      "learning_rate": 6.413999999999999e-05,
      "loss": 0.0144,
      "step": 19660
    },
    {
      "epoch": 6.2976,
      "grad_norm": 0.11171021312475204,
      "learning_rate": 6.39e-05,
      "loss": 0.0146,
      "step": 19680
    },
    {
      "epoch": 6.304,
      "grad_norm": 0.10912482440471649,
      "learning_rate": 6.366e-05,
      "loss": 0.0137,
      "step": 19700
    },
    {
      "epoch": 6.3104,
      "grad_norm": 0.15138384699821472,
      "learning_rate": 6.342e-05,
      "loss": 0.0149,
      "step": 19720
    },
    {
      "epoch": 6.3168,
      "grad_norm": 0.1057821586728096,
      "learning_rate": 6.318e-05,
      "loss": 0.0139,
      "step": 19740
    },
    {
      "epoch": 6.3232,
      "grad_norm": 0.12312867492437363,
      "learning_rate": 6.293999999999999e-05,
      "loss": 0.0143,
      "step": 19760
    },
    {
      "epoch": 6.3296,
      "grad_norm": 0.09124379605054855,
      "learning_rate": 6.269999999999999e-05,
      "loss": 0.0142,
      "step": 19780
    },
    {
      "epoch": 6.336,
      "grad_norm": 0.06064268946647644,
      "learning_rate": 6.246e-05,
      "loss": 0.0133,
      "step": 19800
    },
    {
      "epoch": 6.3424,
      "grad_norm": 0.1464826762676239,
      "learning_rate": 6.222e-05,
      "loss": 0.014,
      "step": 19820
    },
    {
      "epoch": 6.3488,
      "grad_norm": 0.16046836972236633,
      "learning_rate": 6.198e-05,
      "loss": 0.014,
      "step": 19840
    },
    {
      "epoch": 6.3552,
      "grad_norm": 0.13731667399406433,
      "learning_rate": 6.174e-05,
      "loss": 0.0145,
      "step": 19860
    },
    {
      "epoch": 6.3616,
      "grad_norm": 0.14139191806316376,
      "learning_rate": 6.149999999999999e-05,
      "loss": 0.0141,
      "step": 19880
    },
    {
      "epoch": 6.368,
      "grad_norm": 0.11499015241861343,
      "learning_rate": 6.125999999999999e-05,
      "loss": 0.0147,
      "step": 19900
    },
    {
      "epoch": 6.3744,
      "grad_norm": 0.17829649150371552,
      "learning_rate": 6.1019999999999995e-05,
      "loss": 0.0139,
      "step": 19920
    },
    {
      "epoch": 6.3808,
      "grad_norm": 0.10611885786056519,
      "learning_rate": 6.078e-05,
      "loss": 0.0137,
      "step": 19940
    },
    {
      "epoch": 6.3872,
      "grad_norm": 0.14204734563827515,
      "learning_rate": 6.054e-05,
      "loss": 0.0135,
      "step": 19960
    },
    {
      "epoch": 6.3936,
      "grad_norm": 0.0755462795495987,
      "learning_rate": 6.0299999999999995e-05,
      "loss": 0.0137,
      "step": 19980
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.07885447889566422,
      "learning_rate": 6.005999999999999e-05,
      "loss": 0.0142,
      "step": 20000
    },
    {
      "epoch": 6.4064,
      "grad_norm": 0.12656383216381073,
      "learning_rate": 5.981999999999999e-05,
      "loss": 0.0139,
      "step": 20020
    },
    {
      "epoch": 6.4128,
      "grad_norm": 0.1004348024725914,
      "learning_rate": 5.9579999999999995e-05,
      "loss": 0.0142,
      "step": 20040
    },
    {
      "epoch": 6.4192,
      "grad_norm": 0.17605432868003845,
      "learning_rate": 5.934e-05,
      "loss": 0.0135,
      "step": 20060
    },
    {
      "epoch": 6.4256,
      "grad_norm": 0.14976836740970612,
      "learning_rate": 5.91e-05,
      "loss": 0.0143,
      "step": 20080
    },
    {
      "epoch": 6.432,
      "grad_norm": 0.10649985074996948,
      "learning_rate": 5.8859999999999995e-05,
      "loss": 0.0139,
      "step": 20100
    },
    {
      "epoch": 6.4384,
      "grad_norm": 0.09224550426006317,
      "learning_rate": 5.861999999999999e-05,
      "loss": 0.0137,
      "step": 20120
    },
    {
      "epoch": 6.4448,
      "grad_norm": 0.146394744515419,
      "learning_rate": 5.837999999999999e-05,
      "loss": 0.014,
      "step": 20140
    },
    {
      "epoch": 6.4512,
      "grad_norm": 0.1001749336719513,
      "learning_rate": 5.8139999999999996e-05,
      "loss": 0.014,
      "step": 20160
    },
    {
      "epoch": 6.4576,
      "grad_norm": 0.1831815391778946,
      "learning_rate": 5.79e-05,
      "loss": 0.014,
      "step": 20180
    },
    {
      "epoch": 6.464,
      "grad_norm": 0.1717015951871872,
      "learning_rate": 5.766e-05,
      "loss": 0.0142,
      "step": 20200
    },
    {
      "epoch": 6.4704,
      "grad_norm": 0.08448388427495956,
      "learning_rate": 5.741999999999999e-05,
      "loss": 0.0136,
      "step": 20220
    },
    {
      "epoch": 6.4768,
      "grad_norm": 0.07837819308042526,
      "learning_rate": 5.717999999999999e-05,
      "loss": 0.014,
      "step": 20240
    },
    {
      "epoch": 6.4832,
      "grad_norm": 0.056629281491041183,
      "learning_rate": 5.6939999999999994e-05,
      "loss": 0.0134,
      "step": 20260
    },
    {
      "epoch": 6.4896,
      "grad_norm": 0.08206187933683395,
      "learning_rate": 5.6699999999999996e-05,
      "loss": 0.0134,
      "step": 20280
    },
    {
      "epoch": 6.496,
      "grad_norm": 0.1500316709280014,
      "learning_rate": 5.646e-05,
      "loss": 0.0143,
      "step": 20300
    },
    {
      "epoch": 6.5024,
      "grad_norm": 0.16374251246452332,
      "learning_rate": 5.622e-05,
      "loss": 0.0138,
      "step": 20320
    },
    {
      "epoch": 6.5088,
      "grad_norm": 0.12766852974891663,
      "learning_rate": 5.597999999999999e-05,
      "loss": 0.0143,
      "step": 20340
    },
    {
      "epoch": 6.5152,
      "grad_norm": 0.1678803563117981,
      "learning_rate": 5.573999999999999e-05,
      "loss": 0.0141,
      "step": 20360
    },
    {
      "epoch": 6.5216,
      "grad_norm": 0.0983361303806305,
      "learning_rate": 5.5499999999999994e-05,
      "loss": 0.0136,
      "step": 20380
    },
    {
      "epoch": 6.5280000000000005,
      "grad_norm": 0.15062423050403595,
      "learning_rate": 5.5259999999999996e-05,
      "loss": 0.0133,
      "step": 20400
    },
    {
      "epoch": 6.5344,
      "grad_norm": 0.14098654687404633,
      "learning_rate": 5.502e-05,
      "loss": 0.0137,
      "step": 20420
    },
    {
      "epoch": 6.5408,
      "grad_norm": 0.11795366555452347,
      "learning_rate": 5.478e-05,
      "loss": 0.0135,
      "step": 20440
    },
    {
      "epoch": 6.5472,
      "grad_norm": 0.10431049019098282,
      "learning_rate": 5.453999999999999e-05,
      "loss": 0.0136,
      "step": 20460
    },
    {
      "epoch": 6.5536,
      "grad_norm": 0.11597826331853867,
      "learning_rate": 5.429999999999999e-05,
      "loss": 0.0135,
      "step": 20480
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.11726360768079758,
      "learning_rate": 5.4059999999999994e-05,
      "loss": 0.0138,
      "step": 20500
    },
    {
      "epoch": 6.5664,
      "grad_norm": 0.15107019245624542,
      "learning_rate": 5.3819999999999996e-05,
      "loss": 0.0136,
      "step": 20520
    },
    {
      "epoch": 6.5728,
      "grad_norm": 0.10742062330245972,
      "learning_rate": 5.358e-05,
      "loss": 0.0138,
      "step": 20540
    },
    {
      "epoch": 6.5792,
      "grad_norm": 0.0830683633685112,
      "learning_rate": 5.334e-05,
      "loss": 0.0134,
      "step": 20560
    },
    {
      "epoch": 6.5856,
      "grad_norm": 0.1591387540102005,
      "learning_rate": 5.309999999999999e-05,
      "loss": 0.0133,
      "step": 20580
    },
    {
      "epoch": 6.592,
      "grad_norm": 0.15394450724124908,
      "learning_rate": 5.285999999999999e-05,
      "loss": 0.0143,
      "step": 20600
    },
    {
      "epoch": 6.5984,
      "grad_norm": 0.0947754755616188,
      "learning_rate": 5.2619999999999994e-05,
      "loss": 0.0138,
      "step": 20620
    },
    {
      "epoch": 6.6048,
      "grad_norm": 0.09075956791639328,
      "learning_rate": 5.2379999999999997e-05,
      "loss": 0.0138,
      "step": 20640
    },
    {
      "epoch": 6.6112,
      "grad_norm": 0.17136253416538239,
      "learning_rate": 5.214e-05,
      "loss": 0.0136,
      "step": 20660
    },
    {
      "epoch": 6.6176,
      "grad_norm": 0.1522052139043808,
      "learning_rate": 5.1899999999999994e-05,
      "loss": 0.0141,
      "step": 20680
    },
    {
      "epoch": 6.624,
      "grad_norm": 0.14119943976402283,
      "learning_rate": 5.165999999999999e-05,
      "loss": 0.0134,
      "step": 20700
    },
    {
      "epoch": 6.6304,
      "grad_norm": 0.11741479486227036,
      "learning_rate": 5.141999999999999e-05,
      "loss": 0.0141,
      "step": 20720
    },
    {
      "epoch": 6.6368,
      "grad_norm": 0.11139655113220215,
      "learning_rate": 5.1179999999999994e-05,
      "loss": 0.0129,
      "step": 20740
    },
    {
      "epoch": 6.6432,
      "grad_norm": 0.16021506488323212,
      "learning_rate": 5.094e-05,
      "loss": 0.0138,
      "step": 20760
    },
    {
      "epoch": 6.6495999999999995,
      "grad_norm": 0.1047205775976181,
      "learning_rate": 5.07e-05,
      "loss": 0.013,
      "step": 20780
    },
    {
      "epoch": 6.656,
      "grad_norm": 0.09546935558319092,
      "learning_rate": 5.0459999999999995e-05,
      "loss": 0.0133,
      "step": 20800
    },
    {
      "epoch": 6.6624,
      "grad_norm": 0.1268729418516159,
      "learning_rate": 5.022e-05,
      "loss": 0.013,
      "step": 20820
    },
    {
      "epoch": 6.6688,
      "grad_norm": 0.09478412568569183,
      "learning_rate": 4.997999999999999e-05,
      "loss": 0.0141,
      "step": 20840
    },
    {
      "epoch": 6.6752,
      "grad_norm": 0.12305480241775513,
      "learning_rate": 4.9739999999999995e-05,
      "loss": 0.0131,
      "step": 20860
    },
    {
      "epoch": 6.6815999999999995,
      "grad_norm": Infinity,
      "learning_rate": 4.95e-05,
      "loss": 0.0139,
      "step": 20880
    },
    {
      "epoch": 6.688,
      "grad_norm": 0.1275719702243805,
      "learning_rate": 4.927199999999999e-05,
      "loss": 0.0141,
      "step": 20900
    },
    {
      "epoch": 6.6944,
      "grad_norm": 0.1081547811627388,
      "learning_rate": 4.9031999999999994e-05,
      "loss": 0.0139,
      "step": 20920
    },
    {
      "epoch": 6.7008,
      "grad_norm": 0.10720942169427872,
      "learning_rate": 4.8791999999999996e-05,
      "loss": 0.0139,
      "step": 20940
    },
    {
      "epoch": 6.7072,
      "grad_norm": 0.10168763995170593,
      "learning_rate": 4.8552e-05,
      "loss": 0.0141,
      "step": 20960
    },
    {
      "epoch": 6.7136,
      "grad_norm": 0.11339159309864044,
      "learning_rate": 4.8311999999999994e-05,
      "loss": 0.0132,
      "step": 20980
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.11429291218519211,
      "learning_rate": 4.8071999999999996e-05,
      "loss": 0.0134,
      "step": 21000
    },
    {
      "epoch": 6.7264,
      "grad_norm": 0.12321651726961136,
      "learning_rate": 4.783199999999999e-05,
      "loss": 0.0137,
      "step": 21020
    },
    {
      "epoch": 6.7328,
      "grad_norm": 0.09933191537857056,
      "learning_rate": 4.7591999999999994e-05,
      "loss": 0.0139,
      "step": 21040
    },
    {
      "epoch": 6.7392,
      "grad_norm": 0.14313967525959015,
      "learning_rate": 4.7351999999999997e-05,
      "loss": 0.0137,
      "step": 21060
    },
    {
      "epoch": 6.7456,
      "grad_norm": 0.08640217036008835,
      "learning_rate": 4.7112e-05,
      "loss": 0.0135,
      "step": 21080
    },
    {
      "epoch": 6.752,
      "grad_norm": 0.12748348712921143,
      "learning_rate": 4.6871999999999994e-05,
      "loss": 0.0131,
      "step": 21100
    },
    {
      "epoch": 6.7584,
      "grad_norm": 0.09339623153209686,
      "learning_rate": 4.6632e-05,
      "loss": 0.0141,
      "step": 21120
    },
    {
      "epoch": 6.7648,
      "grad_norm": 0.09923992305994034,
      "learning_rate": 4.6392e-05,
      "loss": 0.0135,
      "step": 21140
    },
    {
      "epoch": 6.7712,
      "grad_norm": 0.16402751207351685,
      "learning_rate": 4.6151999999999995e-05,
      "loss": 0.014,
      "step": 21160
    },
    {
      "epoch": 6.7776,
      "grad_norm": 0.24680852890014648,
      "learning_rate": 4.5912e-05,
      "loss": 0.0138,
      "step": 21180
    },
    {
      "epoch": 6.784,
      "grad_norm": 0.14381985366344452,
      "learning_rate": 4.567199999999999e-05,
      "loss": 0.0134,
      "step": 21200
    },
    {
      "epoch": 6.7904,
      "grad_norm": 0.14842021465301514,
      "learning_rate": 4.5431999999999995e-05,
      "loss": 0.014,
      "step": 21220
    },
    {
      "epoch": 6.7968,
      "grad_norm": 0.10411791503429413,
      "learning_rate": 4.5192e-05,
      "loss": 0.0139,
      "step": 21240
    },
    {
      "epoch": 6.8032,
      "grad_norm": 0.11141706258058548,
      "learning_rate": 4.4952e-05,
      "loss": 0.014,
      "step": 21260
    },
    {
      "epoch": 6.8096,
      "grad_norm": 0.1275152713060379,
      "learning_rate": 4.4711999999999995e-05,
      "loss": 0.0135,
      "step": 21280
    },
    {
      "epoch": 6.816,
      "grad_norm": 0.11508294939994812,
      "learning_rate": 4.4472e-05,
      "loss": 0.0139,
      "step": 21300
    },
    {
      "epoch": 6.8224,
      "grad_norm": 0.10418976843357086,
      "learning_rate": 4.423199999999999e-05,
      "loss": 0.0132,
      "step": 21320
    },
    {
      "epoch": 6.8288,
      "grad_norm": 0.15960031747817993,
      "learning_rate": 4.3991999999999995e-05,
      "loss": 0.0136,
      "step": 21340
    },
    {
      "epoch": 6.8352,
      "grad_norm": 0.11204535514116287,
      "learning_rate": 4.3752e-05,
      "loss": 0.0142,
      "step": 21360
    },
    {
      "epoch": 6.8416,
      "grad_norm": 0.06103166937828064,
      "learning_rate": 4.3512e-05,
      "loss": 0.0133,
      "step": 21380
    },
    {
      "epoch": 6.848,
      "grad_norm": 0.08629470318555832,
      "learning_rate": 4.3271999999999995e-05,
      "loss": 0.0137,
      "step": 21400
    },
    {
      "epoch": 6.8544,
      "grad_norm": 0.1764460802078247,
      "learning_rate": 4.3032e-05,
      "loss": 0.014,
      "step": 21420
    },
    {
      "epoch": 6.8608,
      "grad_norm": 0.18068304657936096,
      "learning_rate": 4.279199999999999e-05,
      "loss": 0.0142,
      "step": 21440
    },
    {
      "epoch": 6.8672,
      "grad_norm": 0.11473480612039566,
      "learning_rate": 4.2551999999999995e-05,
      "loss": 0.0135,
      "step": 21460
    },
    {
      "epoch": 6.8736,
      "grad_norm": 0.13483233749866486,
      "learning_rate": 4.2312e-05,
      "loss": 0.0143,
      "step": 21480
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.14962199330329895,
      "learning_rate": 4.2072e-05,
      "loss": 0.0141,
      "step": 21500
    },
    {
      "epoch": 6.8864,
      "grad_norm": 0.06943682581186295,
      "learning_rate": 4.1832e-05,
      "loss": 0.0137,
      "step": 21520
    },
    {
      "epoch": 6.8928,
      "grad_norm": 0.14771774411201477,
      "learning_rate": 4.1592e-05,
      "loss": 0.0138,
      "step": 21540
    },
    {
      "epoch": 6.8992,
      "grad_norm": 0.13111019134521484,
      "learning_rate": 4.135199999999999e-05,
      "loss": 0.0128,
      "step": 21560
    },
    {
      "epoch": 6.9056,
      "grad_norm": 0.12112294137477875,
      "learning_rate": 4.1111999999999995e-05,
      "loss": 0.0137,
      "step": 21580
    },
    {
      "epoch": 6.912,
      "grad_norm": 0.14389880001544952,
      "learning_rate": 4.0872e-05,
      "loss": 0.0138,
      "step": 21600
    },
    {
      "epoch": 6.9184,
      "grad_norm": 0.15372426807880402,
      "learning_rate": 4.0632e-05,
      "loss": 0.0138,
      "step": 21620
    },
    {
      "epoch": 6.9248,
      "grad_norm": 0.18720673024654388,
      "learning_rate": 4.0392e-05,
      "loss": 0.0136,
      "step": 21640
    },
    {
      "epoch": 6.9312000000000005,
      "grad_norm": 0.0891742929816246,
      "learning_rate": 4.015199999999999e-05,
      "loss": 0.0129,
      "step": 21660
    },
    {
      "epoch": 6.9376,
      "grad_norm": 0.1166941374540329,
      "learning_rate": 3.991199999999999e-05,
      "loss": 0.0128,
      "step": 21680
    },
    {
      "epoch": 6.944,
      "grad_norm": 0.10894899070262909,
      "learning_rate": 3.9671999999999996e-05,
      "loss": 0.0138,
      "step": 21700
    },
    {
      "epoch": 6.9504,
      "grad_norm": 0.1171240508556366,
      "learning_rate": 3.9432e-05,
      "loss": 0.0133,
      "step": 21720
    },
    {
      "epoch": 6.9568,
      "grad_norm": 0.09877632558345795,
      "learning_rate": 3.9192e-05,
      "loss": 0.0137,
      "step": 21740
    },
    {
      "epoch": 6.9632,
      "grad_norm": 0.10450015217065811,
      "learning_rate": 3.8952e-05,
      "loss": 0.0137,
      "step": 21760
    },
    {
      "epoch": 6.9696,
      "grad_norm": 0.169956773519516,
      "learning_rate": 3.871199999999999e-05,
      "loss": 0.0137,
      "step": 21780
    },
    {
      "epoch": 6.976,
      "grad_norm": 0.12589164078235626,
      "learning_rate": 3.8471999999999994e-05,
      "loss": 0.0137,
      "step": 21800
    },
    {
      "epoch": 6.9824,
      "grad_norm": 0.06951633840799332,
      "learning_rate": 3.8231999999999996e-05,
      "loss": 0.0131,
      "step": 21820
    },
    {
      "epoch": 6.9888,
      "grad_norm": 0.07360626012086868,
      "learning_rate": 3.7992e-05,
      "loss": 0.0133,
      "step": 21840
    },
    {
      "epoch": 6.9952,
      "grad_norm": 0.10973231494426727,
      "learning_rate": 3.7752e-05,
      "loss": 0.0133,
      "step": 21860
    },
    {
      "epoch": 7.0016,
      "grad_norm": 0.07244843244552612,
      "learning_rate": 3.7512e-05,
      "loss": 0.0135,
      "step": 21880
    },
    {
      "epoch": 7.008,
      "grad_norm": 0.13875754177570343,
      "learning_rate": 3.7272e-05,
      "loss": 0.0136,
      "step": 21900
    },
    {
      "epoch": 7.0144,
      "grad_norm": 0.14488627016544342,
      "learning_rate": 3.7031999999999994e-05,
      "loss": 0.0134,
      "step": 21920
    },
    {
      "epoch": 7.0208,
      "grad_norm": 0.11974161863327026,
      "learning_rate": 3.6791999999999996e-05,
      "loss": 0.0134,
      "step": 21940
    },
    {
      "epoch": 7.0272,
      "grad_norm": 0.09975983202457428,
      "learning_rate": 3.6552e-05,
      "loss": 0.0135,
      "step": 21960
    },
    {
      "epoch": 7.0336,
      "grad_norm": 0.1287238448858261,
      "learning_rate": 3.6311999999999994e-05,
      "loss": 0.0132,
      "step": 21980
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.1416066437959671,
      "learning_rate": 3.6071999999999996e-05,
      "loss": 0.0135,
      "step": 22000
    },
    {
      "epoch": 7.0464,
      "grad_norm": 0.1233639344573021,
      "learning_rate": 3.5832e-05,
      "loss": 0.0142,
      "step": 22020
    },
    {
      "epoch": 7.0528,
      "grad_norm": 0.15097790956497192,
      "learning_rate": 3.5591999999999994e-05,
      "loss": 0.0132,
      "step": 22040
    },
    {
      "epoch": 7.0592,
      "grad_norm": 0.12130185961723328,
      "learning_rate": 3.5351999999999996e-05,
      "loss": 0.0135,
      "step": 22060
    },
    {
      "epoch": 7.0656,
      "grad_norm": 0.21090997755527496,
      "learning_rate": 3.5112e-05,
      "loss": 0.014,
      "step": 22080
    },
    {
      "epoch": 7.072,
      "grad_norm": 0.11519771814346313,
      "learning_rate": 3.4871999999999994e-05,
      "loss": 0.0133,
      "step": 22100
    },
    {
      "epoch": 7.0784,
      "grad_norm": 0.12873798608779907,
      "learning_rate": 3.4631999999999996e-05,
      "loss": 0.0136,
      "step": 22120
    },
    {
      "epoch": 7.0848,
      "grad_norm": 0.10463770478963852,
      "learning_rate": 3.4392e-05,
      "loss": 0.0137,
      "step": 22140
    },
    {
      "epoch": 7.0912,
      "grad_norm": 0.10674607008695602,
      "learning_rate": 3.4151999999999994e-05,
      "loss": 0.0133,
      "step": 22160
    },
    {
      "epoch": 7.0976,
      "grad_norm": 0.08879343420267105,
      "learning_rate": 3.3911999999999997e-05,
      "loss": 0.0137,
      "step": 22180
    },
    {
      "epoch": 7.104,
      "grad_norm": 0.07554900646209717,
      "learning_rate": 3.3672e-05,
      "loss": 0.0133,
      "step": 22200
    },
    {
      "epoch": 7.1104,
      "grad_norm": 0.11350139230489731,
      "learning_rate": 3.3431999999999994e-05,
      "loss": 0.0136,
      "step": 22220
    },
    {
      "epoch": 7.1168,
      "grad_norm": 0.11259081214666367,
      "learning_rate": 3.3192e-05,
      "loss": 0.0138,
      "step": 22240
    },
    {
      "epoch": 7.1232,
      "grad_norm": 0.12811371684074402,
      "learning_rate": 3.295199999999999e-05,
      "loss": 0.0134,
      "step": 22260
    },
    {
      "epoch": 7.1296,
      "grad_norm": 0.12523150444030762,
      "learning_rate": 3.2711999999999994e-05,
      "loss": 0.0143,
      "step": 22280
    },
    {
      "epoch": 7.136,
      "grad_norm": 0.1253233402967453,
      "learning_rate": 3.2472e-05,
      "loss": 0.0142,
      "step": 22300
    },
    {
      "epoch": 7.1424,
      "grad_norm": 0.08505692332983017,
      "learning_rate": 3.223199999999999e-05,
      "loss": 0.0131,
      "step": 22320
    },
    {
      "epoch": 7.1488,
      "grad_norm": 0.08231619745492935,
      "learning_rate": 3.1991999999999995e-05,
      "loss": 0.0141,
      "step": 22340
    },
    {
      "epoch": 7.1552,
      "grad_norm": 0.09392179548740387,
      "learning_rate": 3.1752e-05,
      "loss": 0.0139,
      "step": 22360
    },
    {
      "epoch": 7.1616,
      "grad_norm": 0.1211666613817215,
      "learning_rate": 3.151199999999999e-05,
      "loss": 0.013,
      "step": 22380
    },
    {
      "epoch": 7.168,
      "grad_norm": 0.11963294446468353,
      "learning_rate": 3.1271999999999995e-05,
      "loss": 0.0139,
      "step": 22400
    },
    {
      "epoch": 7.1744,
      "grad_norm": 0.13742035627365112,
      "learning_rate": 3.1032e-05,
      "loss": 0.0136,
      "step": 22420
    },
    {
      "epoch": 7.1808,
      "grad_norm": 0.13370023667812347,
      "learning_rate": 3.079199999999999e-05,
      "loss": 0.0137,
      "step": 22440
    },
    {
      "epoch": 7.1872,
      "grad_norm": 0.09256191551685333,
      "learning_rate": 3.0551999999999995e-05,
      "loss": 0.0134,
      "step": 22460
    },
    {
      "epoch": 7.1936,
      "grad_norm": 0.07827461510896683,
      "learning_rate": 3.0311999999999997e-05,
      "loss": 0.0131,
      "step": 22480
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.11879820376634598,
      "learning_rate": 3.0071999999999996e-05,
      "loss": 0.0137,
      "step": 22500
    },
    {
      "epoch": 7.2064,
      "grad_norm": 0.12836576998233795,
      "learning_rate": 2.9831999999999998e-05,
      "loss": 0.0134,
      "step": 22520
    },
    {
      "epoch": 7.2128,
      "grad_norm": 0.12900499999523163,
      "learning_rate": 2.9592e-05,
      "loss": 0.0136,
      "step": 22540
    },
    {
      "epoch": 7.2192,
      "grad_norm": 0.1294114887714386,
      "learning_rate": 2.9351999999999996e-05,
      "loss": 0.013,
      "step": 22560
    },
    {
      "epoch": 7.2256,
      "grad_norm": 0.142324760556221,
      "learning_rate": 2.9112e-05,
      "loss": 0.0135,
      "step": 22580
    },
    {
      "epoch": 7.232,
      "grad_norm": 0.15491457283496857,
      "learning_rate": 2.8872e-05,
      "loss": 0.0137,
      "step": 22600
    },
    {
      "epoch": 7.2384,
      "grad_norm": 0.13545438647270203,
      "learning_rate": 2.8631999999999996e-05,
      "loss": 0.0146,
      "step": 22620
    },
    {
      "epoch": 7.2448,
      "grad_norm": 0.16222472488880157,
      "learning_rate": 2.8392e-05,
      "loss": 0.014,
      "step": 22640
    },
    {
      "epoch": 7.2512,
      "grad_norm": 0.20005348324775696,
      "learning_rate": 2.8152e-05,
      "loss": 0.014,
      "step": 22660
    },
    {
      "epoch": 7.2576,
      "grad_norm": 0.12308620661497116,
      "learning_rate": 2.7911999999999996e-05,
      "loss": 0.0133,
      "step": 22680
    },
    {
      "epoch": 7.264,
      "grad_norm": 0.10514701157808304,
      "learning_rate": 2.7672e-05,
      "loss": 0.0133,
      "step": 22700
    },
    {
      "epoch": 7.2704,
      "grad_norm": 0.12961874902248383,
      "learning_rate": 2.7431999999999994e-05,
      "loss": 0.0132,
      "step": 22720
    },
    {
      "epoch": 7.2768,
      "grad_norm": 0.14178720116615295,
      "learning_rate": 2.7191999999999996e-05,
      "loss": 0.0138,
      "step": 22740
    },
    {
      "epoch": 7.2832,
      "grad_norm": 0.1294662207365036,
      "learning_rate": 2.6952e-05,
      "loss": 0.0137,
      "step": 22760
    },
    {
      "epoch": 7.2896,
      "grad_norm": 0.09533149003982544,
      "learning_rate": 2.6711999999999994e-05,
      "loss": 0.0132,
      "step": 22780
    },
    {
      "epoch": 7.296,
      "grad_norm": 0.06493016332387924,
      "learning_rate": 2.6471999999999997e-05,
      "loss": 0.0132,
      "step": 22800
    },
    {
      "epoch": 7.3024000000000004,
      "grad_norm": 0.08811145275831223,
      "learning_rate": 2.6232e-05,
      "loss": 0.0136,
      "step": 22820
    },
    {
      "epoch": 7.3088,
      "grad_norm": 0.15884257853031158,
      "learning_rate": 2.5991999999999998e-05,
      "loss": 0.0137,
      "step": 22840
    },
    {
      "epoch": 7.3152,
      "grad_norm": 0.14117403328418732,
      "learning_rate": 2.5751999999999997e-05,
      "loss": 0.0131,
      "step": 22860
    },
    {
      "epoch": 7.3216,
      "grad_norm": 0.1552790105342865,
      "learning_rate": 2.5512e-05,
      "loss": 0.0135,
      "step": 22880
    },
    {
      "epoch": 7.328,
      "grad_norm": 0.1376885026693344,
      "learning_rate": 2.5271999999999998e-05,
      "loss": 0.0137,
      "step": 22900
    },
    {
      "epoch": 7.3344,
      "grad_norm": 0.10730098932981491,
      "learning_rate": 2.5031999999999997e-05,
      "loss": 0.0134,
      "step": 22920
    },
    {
      "epoch": 7.3408,
      "grad_norm": 0.10776139050722122,
      "learning_rate": 2.4792e-05,
      "loss": 0.0133,
      "step": 22940
    },
    {
      "epoch": 7.3472,
      "grad_norm": 0.19516105949878693,
      "learning_rate": 2.4551999999999998e-05,
      "loss": 0.0131,
      "step": 22960
    },
    {
      "epoch": 7.3536,
      "grad_norm": 0.11820100992918015,
      "learning_rate": 2.4311999999999997e-05,
      "loss": 0.0132,
      "step": 22980
    },
    {
      "epoch": 7.36,
      "grad_norm": 0.08267935365438461,
      "learning_rate": 2.4072e-05,
      "loss": 0.0137,
      "step": 23000
    },
    {
      "epoch": 7.3664,
      "grad_norm": 0.09311294555664062,
      "learning_rate": 2.3831999999999998e-05,
      "loss": 0.0136,
      "step": 23020
    },
    {
      "epoch": 7.3728,
      "grad_norm": 0.09443021565675735,
      "learning_rate": 2.3591999999999997e-05,
      "loss": 0.0135,
      "step": 23040
    },
    {
      "epoch": 7.3792,
      "grad_norm": 0.07985521107912064,
      "learning_rate": 2.3352e-05,
      "loss": 0.0137,
      "step": 23060
    },
    {
      "epoch": 7.3856,
      "grad_norm": 0.08729629963636398,
      "learning_rate": 2.3111999999999998e-05,
      "loss": 0.0138,
      "step": 23080
    },
    {
      "epoch": 7.392,
      "grad_norm": 0.11034698784351349,
      "learning_rate": 2.2871999999999997e-05,
      "loss": 0.0132,
      "step": 23100
    },
    {
      "epoch": 7.3984,
      "grad_norm": 0.13113053143024445,
      "learning_rate": 2.2631999999999996e-05,
      "loss": 0.0144,
      "step": 23120
    },
    {
      "epoch": 7.4048,
      "grad_norm": 0.10140665620565414,
      "learning_rate": 2.2392e-05,
      "loss": 0.0141,
      "step": 23140
    },
    {
      "epoch": 7.4112,
      "grad_norm": 0.1212206780910492,
      "learning_rate": 2.2151999999999997e-05,
      "loss": 0.0135,
      "step": 23160
    },
    {
      "epoch": 7.4176,
      "grad_norm": 0.11739517748355865,
      "learning_rate": 2.1924e-05,
      "loss": 0.0135,
      "step": 23180
    },
    {
      "epoch": 7.424,
      "grad_norm": 0.11659056693315506,
      "learning_rate": 2.1683999999999998e-05,
      "loss": 0.0131,
      "step": 23200
    },
    {
      "epoch": 7.4304,
      "grad_norm": 0.12805454432964325,
      "learning_rate": 2.1444e-05,
      "loss": 0.0133,
      "step": 23220
    },
    {
      "epoch": 7.4368,
      "grad_norm": 0.15353170037269592,
      "learning_rate": 2.1204e-05,
      "loss": 0.0139,
      "step": 23240
    },
    {
      "epoch": 7.4432,
      "grad_norm": 0.09690508246421814,
      "learning_rate": 2.0963999999999998e-05,
      "loss": 0.0132,
      "step": 23260
    },
    {
      "epoch": 7.4496,
      "grad_norm": 0.09066127240657806,
      "learning_rate": 2.0724e-05,
      "loss": 0.014,
      "step": 23280
    },
    {
      "epoch": 7.456,
      "grad_norm": 0.08099675178527832,
      "learning_rate": 2.0483999999999996e-05,
      "loss": 0.0131,
      "step": 23300
    },
    {
      "epoch": 7.4624,
      "grad_norm": 0.1329900026321411,
      "learning_rate": 2.0243999999999998e-05,
      "loss": 0.0134,
      "step": 23320
    },
    {
      "epoch": 7.4688,
      "grad_norm": 0.13496078550815582,
      "learning_rate": 2.0004e-05,
      "loss": 0.0133,
      "step": 23340
    },
    {
      "epoch": 7.4752,
      "grad_norm": 0.1408112347126007,
      "learning_rate": 1.9763999999999996e-05,
      "loss": 0.0133,
      "step": 23360
    },
    {
      "epoch": 7.4816,
      "grad_norm": 0.10787922888994217,
      "learning_rate": 1.9523999999999998e-05,
      "loss": 0.0135,
      "step": 23380
    },
    {
      "epoch": 7.4879999999999995,
      "grad_norm": 0.17157135903835297,
      "learning_rate": 1.9284e-05,
      "loss": 0.0137,
      "step": 23400
    },
    {
      "epoch": 7.4944,
      "grad_norm": 0.0805191844701767,
      "learning_rate": 1.9043999999999996e-05,
      "loss": 0.0132,
      "step": 23420
    },
    {
      "epoch": 7.5008,
      "grad_norm": 0.07075642794370651,
      "learning_rate": 1.8803999999999998e-05,
      "loss": 0.0127,
      "step": 23440
    },
    {
      "epoch": 7.5072,
      "grad_norm": 0.08374916762113571,
      "learning_rate": 1.8563999999999997e-05,
      "loss": 0.0135,
      "step": 23460
    },
    {
      "epoch": 7.5136,
      "grad_norm": 0.1395425945520401,
      "learning_rate": 1.8324e-05,
      "loss": 0.0134,
      "step": 23480
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.0876280888915062,
      "learning_rate": 1.8083999999999998e-05,
      "loss": 0.014,
      "step": 23500
    },
    {
      "epoch": 7.5264,
      "grad_norm": 0.12833598256111145,
      "learning_rate": 1.7843999999999997e-05,
      "loss": 0.0131,
      "step": 23520
    },
    {
      "epoch": 7.5328,
      "grad_norm": 0.16750890016555786,
      "learning_rate": 1.7604e-05,
      "loss": 0.0137,
      "step": 23540
    },
    {
      "epoch": 7.5392,
      "grad_norm": 0.2171017974615097,
      "learning_rate": 1.7364e-05,
      "loss": 0.0138,
      "step": 23560
    },
    {
      "epoch": 7.5456,
      "grad_norm": 0.06654636561870575,
      "learning_rate": 1.7123999999999997e-05,
      "loss": 0.0134,
      "step": 23580
    },
    {
      "epoch": 7.552,
      "grad_norm": 0.08254584670066833,
      "learning_rate": 1.6883999999999996e-05,
      "loss": 0.0134,
      "step": 23600
    },
    {
      "epoch": 7.5584,
      "grad_norm": 0.1545911282300949,
      "learning_rate": 1.6644e-05,
      "loss": 0.0137,
      "step": 23620
    },
    {
      "epoch": 7.5648,
      "grad_norm": 0.09829439222812653,
      "learning_rate": 1.6403999999999997e-05,
      "loss": 0.0138,
      "step": 23640
    },
    {
      "epoch": 7.5712,
      "grad_norm": 0.09656976908445358,
      "learning_rate": 1.6163999999999996e-05,
      "loss": 0.0138,
      "step": 23660
    },
    {
      "epoch": 7.5776,
      "grad_norm": 0.10306353867053986,
      "learning_rate": 1.5924e-05,
      "loss": 0.0142,
      "step": 23680
    },
    {
      "epoch": 7.584,
      "grad_norm": 0.14353260397911072,
      "learning_rate": 1.5683999999999998e-05,
      "loss": 0.0131,
      "step": 23700
    },
    {
      "epoch": 7.5904,
      "grad_norm": 0.13441936671733856,
      "learning_rate": 1.5443999999999996e-05,
      "loss": 0.0131,
      "step": 23720
    },
    {
      "epoch": 7.5968,
      "grad_norm": 0.05684441328048706,
      "learning_rate": 1.5203999999999999e-05,
      "loss": 0.0135,
      "step": 23740
    },
    {
      "epoch": 7.6032,
      "grad_norm": 0.1381123960018158,
      "learning_rate": 1.4964e-05,
      "loss": 0.0139,
      "step": 23760
    },
    {
      "epoch": 7.6096,
      "grad_norm": 0.16691377758979797,
      "learning_rate": 1.4723999999999998e-05,
      "loss": 0.0135,
      "step": 23780
    },
    {
      "epoch": 7.616,
      "grad_norm": 0.1400778442621231,
      "learning_rate": 1.4484e-05,
      "loss": 0.0131,
      "step": 23800
    },
    {
      "epoch": 7.6224,
      "grad_norm": 0.11704498529434204,
      "learning_rate": 1.4244e-05,
      "loss": 0.0133,
      "step": 23820
    },
    {
      "epoch": 7.6288,
      "grad_norm": 0.12657155096530914,
      "learning_rate": 1.4003999999999998e-05,
      "loss": 0.0136,
      "step": 23840
    },
    {
      "epoch": 7.6352,
      "grad_norm": 0.13781172037124634,
      "learning_rate": 1.3763999999999997e-05,
      "loss": 0.0135,
      "step": 23860
    },
    {
      "epoch": 7.6416,
      "grad_norm": 0.11339103430509567,
      "learning_rate": 1.3524e-05,
      "loss": 0.0138,
      "step": 23880
    },
    {
      "epoch": 7.648,
      "grad_norm": 0.12373317778110504,
      "learning_rate": 1.3283999999999999e-05,
      "loss": 0.0131,
      "step": 23900
    },
    {
      "epoch": 7.6544,
      "grad_norm": 0.08610403537750244,
      "learning_rate": 1.3043999999999997e-05,
      "loss": 0.0136,
      "step": 23920
    },
    {
      "epoch": 7.6608,
      "grad_norm": 0.09383068978786469,
      "learning_rate": 1.2804e-05,
      "loss": 0.0133,
      "step": 23940
    },
    {
      "epoch": 7.6672,
      "grad_norm": 0.11431668698787689,
      "learning_rate": 1.2563999999999999e-05,
      "loss": 0.0132,
      "step": 23960
    },
    {
      "epoch": 7.6736,
      "grad_norm": 0.09233295172452927,
      "learning_rate": 1.2324e-05,
      "loss": 0.013,
      "step": 23980
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.15407449007034302,
      "learning_rate": 1.2084e-05,
      "loss": 0.0135,
      "step": 24000
    },
    {
      "epoch": 7.6864,
      "grad_norm": 0.17848001420497894,
      "learning_rate": 1.1843999999999999e-05,
      "loss": 0.0133,
      "step": 24020
    },
    {
      "epoch": 7.6928,
      "grad_norm": 0.12101227045059204,
      "learning_rate": 1.1604e-05,
      "loss": 0.0141,
      "step": 24040
    },
    {
      "epoch": 7.6992,
      "grad_norm": 0.09466645866632462,
      "learning_rate": 1.1363999999999998e-05,
      "loss": 0.0135,
      "step": 24060
    },
    {
      "epoch": 7.7056000000000004,
      "grad_norm": 0.08009596914052963,
      "learning_rate": 1.1123999999999999e-05,
      "loss": 0.0136,
      "step": 24080
    },
    {
      "epoch": 7.712,
      "grad_norm": 0.09499915689229965,
      "learning_rate": 1.0884e-05,
      "loss": 0.0128,
      "step": 24100
    },
    {
      "epoch": 7.7184,
      "grad_norm": 0.08000971376895905,
      "learning_rate": 1.0643999999999998e-05,
      "loss": 0.0131,
      "step": 24120
    },
    {
      "epoch": 7.7248,
      "grad_norm": 0.11942494660615921,
      "learning_rate": 1.0404e-05,
      "loss": 0.0132,
      "step": 24140
    },
    {
      "epoch": 7.7312,
      "grad_norm": 0.1811472475528717,
      "learning_rate": 1.0164e-05,
      "loss": 0.0135,
      "step": 24160
    },
    {
      "epoch": 7.7376000000000005,
      "grad_norm": 0.09676049649715424,
      "learning_rate": 9.923999999999998e-06,
      "loss": 0.0137,
      "step": 24180
    },
    {
      "epoch": 7.744,
      "grad_norm": 0.1229252964258194,
      "learning_rate": 9.684e-06,
      "loss": 0.0133,
      "step": 24200
    },
    {
      "epoch": 7.7504,
      "grad_norm": 0.11417454481124878,
      "learning_rate": 9.444e-06,
      "loss": 0.0135,
      "step": 24220
    },
    {
      "epoch": 7.7568,
      "grad_norm": 0.13412834703922272,
      "learning_rate": 9.203999999999999e-06,
      "loss": 0.014,
      "step": 24240
    },
    {
      "epoch": 7.7632,
      "grad_norm": 0.09218916296958923,
      "learning_rate": 8.964e-06,
      "loss": 0.0127,
      "step": 24260
    },
    {
      "epoch": 7.7696,
      "grad_norm": 0.10381223261356354,
      "learning_rate": 8.724e-06,
      "loss": 0.0136,
      "step": 24280
    },
    {
      "epoch": 7.776,
      "grad_norm": 0.11440572142601013,
      "learning_rate": 8.483999999999999e-06,
      "loss": 0.0134,
      "step": 24300
    },
    {
      "epoch": 7.7824,
      "grad_norm": 0.12166905403137207,
      "learning_rate": 8.244e-06,
      "loss": 0.0134,
      "step": 24320
    },
    {
      "epoch": 7.7888,
      "grad_norm": 0.09684951603412628,
      "learning_rate": 8.003999999999998e-06,
      "loss": 0.013,
      "step": 24340
    },
    {
      "epoch": 7.7952,
      "grad_norm": 0.1404530107975006,
      "learning_rate": 7.763999999999999e-06,
      "loss": 0.0136,
      "step": 24360
    },
    {
      "epoch": 7.8016,
      "grad_norm": 0.1341012716293335,
      "learning_rate": 7.5239999999999995e-06,
      "loss": 0.0134,
      "step": 24380
    },
    {
      "epoch": 7.808,
      "grad_norm": 0.10053057968616486,
      "learning_rate": 7.283999999999999e-06,
      "loss": 0.0137,
      "step": 24400
    },
    {
      "epoch": 7.8144,
      "grad_norm": 0.07986601442098618,
      "learning_rate": 7.044e-06,
      "loss": 0.0136,
      "step": 24420
    },
    {
      "epoch": 7.8208,
      "grad_norm": 0.11663832515478134,
      "learning_rate": 6.803999999999999e-06,
      "loss": 0.013,
      "step": 24440
    },
    {
      "epoch": 7.8272,
      "grad_norm": 0.06180492043495178,
      "learning_rate": 6.563999999999999e-06,
      "loss": 0.0134,
      "step": 24460
    },
    {
      "epoch": 7.8336,
      "grad_norm": 0.11923171579837799,
      "learning_rate": 6.324e-06,
      "loss": 0.0131,
      "step": 24480
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.1307065635919571,
      "learning_rate": 6.084e-06,
      "loss": 0.0133,
      "step": 24500
    },
    {
      "epoch": 7.8464,
      "grad_norm": 0.13876225054264069,
      "learning_rate": 5.8439999999999994e-06,
      "loss": 0.0133,
      "step": 24520
    },
    {
      "epoch": 7.8528,
      "grad_norm": 0.10873398929834366,
      "learning_rate": 5.603999999999999e-06,
      "loss": 0.0129,
      "step": 24540
    },
    {
      "epoch": 7.8591999999999995,
      "grad_norm": 0.13273799419403076,
      "learning_rate": 5.364e-06,
      "loss": 0.0134,
      "step": 24560
    },
    {
      "epoch": 7.8656,
      "grad_norm": 0.15226051211357117,
      "learning_rate": 5.1239999999999996e-06,
      "loss": 0.0134,
      "step": 24580
    },
    {
      "epoch": 7.872,
      "grad_norm": 0.15576089918613434,
      "learning_rate": 4.883999999999999e-06,
      "loss": 0.0132,
      "step": 24600
    },
    {
      "epoch": 7.8784,
      "grad_norm": 0.1553131341934204,
      "learning_rate": 4.644e-06,
      "loss": 0.0128,
      "step": 24620
    },
    {
      "epoch": 7.8848,
      "grad_norm": 0.13128536939620972,
      "learning_rate": 4.404e-06,
      "loss": 0.013,
      "step": 24640
    },
    {
      "epoch": 7.8911999999999995,
      "grad_norm": 0.08229406923055649,
      "learning_rate": 4.1639999999999994e-06,
      "loss": 0.0131,
      "step": 24660
    },
    {
      "epoch": 7.8976,
      "grad_norm": 0.09608056396245956,
      "learning_rate": 3.923999999999999e-06,
      "loss": 0.0134,
      "step": 24680
    },
    {
      "epoch": 7.904,
      "grad_norm": 0.08450799435377121,
      "learning_rate": 3.6839999999999994e-06,
      "loss": 0.0137,
      "step": 24700
    },
    {
      "epoch": 7.9104,
      "grad_norm": 0.09818736463785172,
      "learning_rate": 3.444e-06,
      "loss": 0.0137,
      "step": 24720
    },
    {
      "epoch": 7.9168,
      "grad_norm": 0.10983067005872726,
      "learning_rate": 3.2039999999999997e-06,
      "loss": 0.0131,
      "step": 24740
    },
    {
      "epoch": 7.9232,
      "grad_norm": 0.1415960043668747,
      "learning_rate": 2.964e-06,
      "loss": 0.0135,
      "step": 24760
    },
    {
      "epoch": 7.9296,
      "grad_norm": 0.08166951686143875,
      "learning_rate": 2.7239999999999997e-06,
      "loss": 0.0136,
      "step": 24780
    },
    {
      "epoch": 7.936,
      "grad_norm": 0.10548938810825348,
      "learning_rate": 2.4839999999999994e-06,
      "loss": 0.0133,
      "step": 24800
    }
  ],
  "logging_steps": 20,
  "max_steps": 25000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 40879364505600.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
